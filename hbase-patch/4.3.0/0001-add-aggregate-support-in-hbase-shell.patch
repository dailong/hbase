From e4c4eadeb318ac289d1533ad2f7ed35ef696b751 Mon Sep 17 00:00:00 2001
From: javachen <june.chan@foxmail.com>
Date: Thu, 16 Jan 2014 13:25:59 +0800
Subject: [PATCH 1/8] add-aggregate-support-in-hbase-shell

---
 .../AbstractDoubleColumnInterpreter.java           |  80 ++++++++++++++
 .../coprocessor/AbstractLongColumnInterpreter.java |  80 ++++++++++++++
 .../CompositeDoubleStrColumnInterpreter.java       | 106 +++++++++++++++++++
 .../CompositeLongStrColumnInterpreter.java         | 102 ++++++++++++++++++
 .../coprocessor/DoubleColumnInterpreter.java       |  37 +++++++
 .../coprocessor/DoubleStrColumnInterpreter.java    |  44 ++++++++
 .../client/coprocessor/LongColumnInterpreter.java  |  85 ++-------------
 .../coprocessor/LongStrColumnInterpreter.java      |  44 ++++++++
 src/main/ruby/hbase.rb                             |   2 +
 src/main/ruby/hbase/coprocessor.rb                 | 117 +++++++++++++++++++++
 src/main/ruby/hbase/hbase.rb                       |   5 +
 src/main/ruby/shell.rb                             |  12 +++
 src/main/ruby/shell/commands.rb                    |   4 +
 src/main/ruby/shell/commands/aggregate.rb          |  78 ++++++++++++++
 14 files changed, 719 insertions(+), 77 deletions(-)
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractDoubleColumnInterpreter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractLongColumnInterpreter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeDoubleStrColumnInterpreter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeLongStrColumnInterpreter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleColumnInterpreter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleStrColumnInterpreter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongStrColumnInterpreter.java
 create mode 100644 src/main/ruby/hbase/coprocessor.rb
 create mode 100644 src/main/ruby/shell/commands/aggregate.rb

diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractDoubleColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractDoubleColumnInterpreter.java
new file mode 100644
index 0000000..1f4dbfc
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractDoubleColumnInterpreter.java
@@ -0,0 +1,80 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import org.apache.hadoop.hbase.coprocessor.ColumnInterpreter;
+
+public abstract class AbstractDoubleColumnInterpreter implements
+    ColumnInterpreter<Double, Double> {
+  public Double add(Double d1, Double d2) {
+    if (((d1 == null ? 1 : 0) ^ (d2 == null ? 1 : 0)) != 0) {
+      return d1 == null ? d2 : d1;
+    }
+    if (d1 == null) {
+      return null;
+    }
+    return Double.valueOf(d1.doubleValue() + d2.doubleValue());
+  }
+
+  public Double getMaxValue() {
+    return Double.valueOf(1.7976931348623157E+308D);
+  }
+
+  public Double getMinValue() {
+    return Double.valueOf(4.9E-324D);
+  }
+
+  public Double multiply(Double d1, Double d2) {
+    return (d1 == null) || (d2 == null) ? null : Double.valueOf(d1
+        .doubleValue() * d2.doubleValue());
+  }
+
+  public Double increment(Double o) {
+    return null;
+  }
+
+  public Double castToReturnType(Double o) {
+    return o;
+  }
+
+  public int compare(Double d1, Double d2) {
+    if (((d1 == null ? 1 : 0) ^ (d2 == null ? 1 : 0)) != 0) {
+      return d1 == null ? -1 : 1;
+    }
+    if (d1 == null) {
+      return 0;
+    }
+    return d1.compareTo(d2);
+  }
+
+  public double divideForAvg(Double d, Long l) {
+    return (l == null) || (d == null) ? (0.0D / 0.0D) : d.doubleValue()
+        / l.doubleValue();
+  }
+
+  public void readFields(DataInput arg0) throws IOException {
+  }
+
+  public void write(DataOutput arg0) throws IOException {
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractLongColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractLongColumnInterpreter.java
new file mode 100644
index 0000000..b95ce69
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AbstractLongColumnInterpreter.java
@@ -0,0 +1,80 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import org.apache.hadoop.hbase.coprocessor.ColumnInterpreter;
+
+public abstract class AbstractLongColumnInterpreter implements
+    ColumnInterpreter<Long, Long> {
+  public Long add(Long l1, Long l2) {
+    if (((l1 == null ? 1 : 0) ^ (l2 == null ? 1 : 0)) != 0) {
+      return l1 == null ? l2 : l1;
+    }
+    if (l1 == null) {
+      return null;
+    }
+    return Long.valueOf(l1.longValue() + l2.longValue());
+  }
+
+  public int compare(Long l1, Long l2) {
+    if (((l1 == null ? 1 : 0) ^ (l2 == null ? 1 : 0)) != 0) {
+      return l1 == null ? -1 : 1;
+    }
+    if (l1 == null) {
+      return 0;
+    }
+    return l1.compareTo(l2);
+  }
+
+  public Long getMaxValue() {
+    return Long.valueOf(9223372036854775807L);
+  }
+
+  public Long increment(Long o) {
+    return o == null ? null : Long.valueOf(o.longValue() + 1L);
+  }
+
+  public Long multiply(Long l1, Long l2) {
+    return (l1 == null) || (l2 == null) ? null : Long.valueOf(l1.longValue()
+        * l2.longValue());
+  }
+
+  public Long getMinValue() {
+    return Long.valueOf(-9223372036854775808L);
+  }
+
+  public void readFields(DataInput arg0) throws IOException {
+  }
+
+  public void write(DataOutput arg0) throws IOException {
+  }
+
+  public double divideForAvg(Long l1, Long l2) {
+    return (l2 == null) || (l1 == null) ? (0.0D / 0.0D) : l1.doubleValue()
+        / l2.doubleValue();
+  }
+
+  public Long castToReturnType(Long o) {
+    return o;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeDoubleStrColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeDoubleStrColumnInterpreter.java
new file mode 100644
index 0000000..489816a
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeDoubleStrColumnInterpreter.java
@@ -0,0 +1,106 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.regex.Pattern;
+
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class CompositeDoubleStrColumnInterpreter extends
+    AbstractDoubleColumnInterpreter {
+  private String delimiter = ",";
+  private int index = 0;
+  private Pattern pattern = null;
+
+  public CompositeDoubleStrColumnInterpreter() {
+  }
+
+  public CompositeDoubleStrColumnInterpreter(String delimiter, int index) {
+    this.delimiter = delimiter;
+    this.index = index;
+  }
+
+  public Double getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv) throws IOException {
+    if (kv == null) {
+      return null;
+    }
+    String val = Bytes.toString(kv.getBuffer(), kv.getValueOffset(),
+      kv.getValueLength());
+
+    if (val == null) {
+      return null;
+    }
+    if (this.index < 0) {
+      return null;
+    }
+    if (this.pattern == null) {
+      this.pattern = Pattern.compile(this.delimiter);
+    }
+    String[] parts = this.pattern.split(val, this.index + 2);
+    if (parts.length <= this.index) {
+      return null;
+    }
+    Double result = null;
+    try {
+      val = parts[this.index];
+      result = Double.valueOf(val);
+    } catch (NumberFormatException e) {
+    }
+    return result;
+  }
+
+  public String getDelimiter() {
+    return this.delimiter;
+  }
+
+  public int getIndex() {
+    return this.index;
+  }
+
+  public void readFields(DataInput in) throws IOException {
+    super.readFields(in);
+    this.delimiter = in.readUTF();
+    this.index = in.readInt();
+    this.pattern = null;
+  }
+
+  public void write(DataOutput out) throws IOException {
+    super.write(out);
+    out.writeUTF(this.delimiter);
+    out.writeInt(this.index);
+  }
+
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if ((obj instanceof CompositeDoubleStrColumnInterpreter)) {
+      CompositeDoubleStrColumnInterpreter another = (CompositeDoubleStrColumnInterpreter) obj;
+      return (this.delimiter.equals(another.getDelimiter()))
+          && (this.index == another.getIndex());
+    }
+
+    return false;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeLongStrColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeLongStrColumnInterpreter.java
new file mode 100644
index 0000000..2475bdc
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/CompositeLongStrColumnInterpreter.java
@@ -0,0 +1,102 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.regex.Pattern;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class CompositeLongStrColumnInterpreter extends
+    AbstractLongColumnInterpreter {
+  private String delimiter = ",";
+  private int index = 0;
+  private Pattern pattern = null;
+
+  public CompositeLongStrColumnInterpreter() {
+  }
+
+  public CompositeLongStrColumnInterpreter(String delimiter, int index) {
+    this.delimiter = delimiter;
+    this.index = index;
+  }
+
+  public Long getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv) throws IOException {
+    if (kv == null) {
+      return null;
+    }
+    String val = Bytes.toString(kv.getBuffer(), kv.getValueOffset(),
+      kv.getValueLength());
+
+    if (val == null) {
+      return null;
+    }
+    if (this.index < 0) {
+      return null;
+    }
+    if (this.pattern == null) {
+      this.pattern = Pattern.compile(this.delimiter);
+    }
+    String[] parts = this.pattern.split(val, this.index + 2);
+    if (parts.length <= this.index) return null;
+    try {
+      val = parts[this.index];
+      return Long.valueOf(val);
+    } catch (NumberFormatException e) {
+    }
+    return null;
+  }
+
+  public String getDelimiter() {
+    return this.delimiter;
+  }
+
+  public int getIndex() {
+    return this.index;
+  }
+
+  public void readFields(DataInput in) throws IOException {
+    super.readFields(in);
+    this.delimiter = in.readUTF();
+    this.index = in.readInt();
+    this.pattern = null;
+  }
+
+  public void write(DataOutput out) throws IOException {
+    super.write(out);
+    out.writeUTF(this.delimiter);
+    out.writeInt(this.index);
+  }
+
+  public boolean equals(Object obj) {
+    if (this == obj) {
+      return true;
+    }
+    if ((obj instanceof CompositeLongStrColumnInterpreter)) {
+      CompositeLongStrColumnInterpreter another = (CompositeLongStrColumnInterpreter) obj;
+      return (this.delimiter.equals(another.getDelimiter()))
+          && (this.index == another.getIndex());
+    }
+
+    return false;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleColumnInterpreter.java
new file mode 100644
index 0000000..1739be1
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleColumnInterpreter.java
@@ -0,0 +1,37 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.IOException;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class DoubleColumnInterpreter extends AbstractDoubleColumnInterpreter {
+  public Double getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv) throws IOException {
+    if ((kv == null) || (kv.getValueLength() != 8)) {
+      return null;
+    }
+    return Double.valueOf(Bytes.toDouble(kv.getBuffer(), kv.getValueOffset()));
+  }
+
+  public boolean equals(Object obj) {
+    return obj.getClass() == DoubleColumnInterpreter.class;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleStrColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleStrColumnInterpreter.java
new file mode 100644
index 0000000..eda01f8
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/DoubleStrColumnInterpreter.java
@@ -0,0 +1,44 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.IOException;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class DoubleStrColumnInterpreter extends AbstractDoubleColumnInterpreter {
+  public Double getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv) throws IOException {
+    if (kv == null) {
+      return null;
+    }
+    String val = Bytes.toString(kv.getBuffer(), kv.getValueOffset(),
+      kv.getValueLength());
+    Double result = null;
+    try {
+      result = Double.valueOf(val);
+    } catch (NumberFormatException e) {
+    }
+    return result;
+  }
+
+  public boolean equals(Object obj) {
+    return obj.getClass() == DoubleStrColumnInterpreter.class;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongColumnInterpreter.java
index c37b5fd..21ab130 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongColumnInterpreter.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongColumnInterpreter.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2011 The Apache Software Foundation
+ * Copyright 2010 The Apache Software Foundation
  *
  * Licensed to the Apache Software Foundation (ASF) under one
  * or more contributor license agreements.  See the NOTICE file
@@ -19,88 +19,19 @@
  */
 package org.apache.hadoop.hbase.client.coprocessor;
 
-import java.io.DataInput;
-import java.io.DataOutput;
 import java.io.IOException;
-
 import org.apache.hadoop.hbase.KeyValue;
-import org.apache.hadoop.hbase.coprocessor.ColumnInterpreter;
 import org.apache.hadoop.hbase.util.Bytes;
 
-/**
- * a concrete column interpreter implementation. The cell value is a Long value
- * and its promoted data type is also a Long value. For computing aggregation
- * function, this class is used to find the datatype of the cell value. Client
- * is supposed to instantiate it and passed along as a parameter. See
- * TestAggregateProtocol methods for its sample usage.
- * Its methods handle null arguments gracefully. 
- */
-public class LongColumnInterpreter implements ColumnInterpreter<Long, Long> {
-
-  public Long getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv)
-      throws IOException {
-    if (kv == null || kv.getValueLength() != Bytes.SIZEOF_LONG)
-      return null;
-    return Bytes.toLong(kv.getBuffer(), kv.getValueOffset());
-  }
-
-   @Override
-  public Long add(Long l1, Long l2) {
-    if (l1 == null ^ l2 == null) {
-      return (l1 == null) ? l2 : l1; // either of one is null.
-    } else if (l1 == null) // both are null
+public class LongColumnInterpreter extends AbstractLongColumnInterpreter {
+  public Long getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv) throws IOException {
+    if ((kv == null) || (kv.getValueLength() != 8)) {
       return null;
-    return l1 + l2;
-  }
-
-  @Override
-  public int compare(final Long l1, final Long l2) {
-    if (l1 == null ^ l2 == null) {
-      return l1 == null ? -1 : 1; // either of one is null.
-    } else if (l1 == null)
-      return 0; // both are null
-    return l1.compareTo(l2); // natural ordering.
-  }
-
-  @Override
-  public Long getMaxValue() {
-    return Long.MAX_VALUE;
-  }
-
-  @Override
-  public Long increment(Long o) {
-    return o == null ? null : (o + 1l);
+    }
+    return Long.valueOf(Bytes.toLong(kv.getBuffer(), kv.getValueOffset()));
   }
 
-  @Override
-  public Long multiply(Long l1, Long l2) {
-    return (l1 == null || l2 == null) ? null : l1 * l2;
+  public boolean equals(Object obj) {
+    return obj.getClass() == LongColumnInterpreter.class;
   }
-
-  @Override
-  public Long getMinValue() {
-    return Long.MIN_VALUE;
-  }
-
-  @Override
-  public void readFields(DataInput arg0) throws IOException {
-    // nothing to serialize
-  }
-
-  @Override
-  public void write(DataOutput arg0) throws IOException {
-     // nothing to serialize
-  }
-
-  @Override
-  public double divideForAvg(Long l1, Long l2) {
-    return (l2 == null || l1 == null) ? Double.NaN : (l1.doubleValue() / l2
-        .doubleValue());
-  }
-
-  @Override
-  public Long castToReturnType(Long o) {
-    return o;
-  }
-
 }
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongStrColumnInterpreter.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongStrColumnInterpreter.java
new file mode 100644
index 0000000..b277357
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/LongStrColumnInterpreter.java
@@ -0,0 +1,44 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.IOException;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class LongStrColumnInterpreter extends AbstractLongColumnInterpreter {
+  public Long getValue(byte[] colFamily, byte[] colQualifier, KeyValue kv) throws IOException {
+    if (kv == null) {
+      return null;
+    }
+    String val = Bytes.toString(kv.getBuffer(), kv.getValueOffset(),
+      kv.getValueLength());
+    Long result = null;
+    try {
+      result = Long.valueOf(val);
+    } catch (NumberFormatException e) {
+    }
+    return result;
+  }
+
+  public boolean equals(Object obj) {
+    return obj.getClass() == LongStrColumnInterpreter.class;
+  }
+}
\ No newline at end of file
diff --git a/src/main/ruby/hbase.rb b/src/main/ruby/hbase.rb
index 2a4abcb..4432225 100644
--- a/src/main/ruby/hbase.rb
+++ b/src/main/ruby/hbase.rb
@@ -56,6 +56,7 @@ module HBaseConstants
   SPLITS_FILE = 'SPLITS_FILE'
   SPLITALGO = 'SPLITALGO'
   NUMREGIONS = 'NUMREGIONS'
+  COLUMN_INTERPRETER="COLUMN_INTERPRETER"
 
   # Load constants from hbase java API
   def self.promote_constants(constants)
@@ -77,3 +78,4 @@ require 'hbase/admin'
 require 'hbase/table'
 require 'hbase/replication_admin'
 require 'hbase/security'
+require 'hbase/coprocessor'
diff --git a/src/main/ruby/hbase/coprocessor.rb b/src/main/ruby/hbase/coprocessor.rb
new file mode 100644
index 0000000..47cf963
--- /dev/null
+++ b/src/main/ruby/hbase/coprocessor.rb
@@ -0,0 +1,117 @@
+#
+# Copyright 2010 The Apache Software Foundation
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+include Java
+
+java_import java.util.ArrayList
+java_import java.util.List
+java_import java.util.Map
+
+module Hbase
+  class Coprocessor
+    include HBaseConstants
+
+    def initialize(configuration, formatter)
+      @aClient = org.apache.hadoop.hbase.client.coprocessor.AggregationClient.new(configuration)
+      @formatter = formatter
+    end
+
+    def rowcount(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.rowCount(table.to_s.to_java_bytes, ci, scan)
+    end
+    
+    def min(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.min(table.to_s.to_java_bytes, ci, scan)
+    end
+
+    def max(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.max(table.to_s.to_java_bytes, ci, scan)
+    end
+
+    def sum(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.sum(table.to_s.to_java_bytes, ci, scan)
+    end
+
+    def std(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.std(table.to_s.to_java_bytes, ci, scan)
+    end
+
+    def median(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.median(table.to_s.to_java_bytes, ci, scan)
+    end
+
+    def avg(table, *args)
+      ci, scan = parse_args(table, *args)
+      @aClient.avg(table.to_s.to_java_bytes, ci, scan)
+    end
+
+    def parse_args(table, *args)
+       # Fail if table name is not a string
+      raise(ArgumentError, "Table name must be of type String") unless table.kind_of?(String)
+      args = args.flatten.compact
+      raise(ArgumentError, "Table must have at least one column or column family") if args.empty?
+      
+      scan = org.apache.hadoop.hbase.client.Scan.new()
+      ci = nil
+      args.each do |arg|
+        unless arg.kind_of?(String) || arg.kind_of?(Hash)
+          raise(ArgumentError, "#{arg.class} of #{arg.inspect} is not of Hash or String type")
+        end
+        if arg.kind_of?(Hash) 
+          if arg.has_key?(COLUMN_INTERPRETER)
+            ci = arg[COLUMN_INTERPRETER]
+            raise(ArgumentError, "COLUMN_INTERPRETER must be a subclass of org.apache.hadoop.hbase.coprocessor.ColumnInterpreter") unless ci.kind_of?(org.apache.hadoop.hbase.coprocessor.ColumnInterpreter)
+          end
+          if arg.has_key?(STARTROW)
+            scan.setStartRow(arg[STARTROW].to_java_bytes)
+          end
+          if arg.has_key?(STOPROW)
+            scan.setStopRow(arg[STOPROW].to_java_bytes)
+          end
+          if arg.has_key?(FILTER)
+            scan.setFilter(arg[FILTER])
+          end
+        else
+          parse_column(scan, arg)
+        end
+      end
+      (ci == nil)? ci = org.apache.hadoop.hbase.client.coprocessor.LongStrColumnInterpreter.new(): ci
+      return ci,scan
+    end
+
+
+    def parse_column(scan, column)
+      split = org.apache.hadoop.hbase.KeyValue.parseColumn(column.to_java_bytes)
+      if split.length > 1
+        scan.addColumn(split[0],split[1])
+      else
+        scan.addFamily(split[0])
+      end
+    end
+
+  end
+end
+
diff --git a/src/main/ruby/hbase/hbase.rb b/src/main/ruby/hbase/hbase.rb
index 5ab6a72..40260da 100644
--- a/src/main/ruby/hbase/hbase.rb
+++ b/src/main/ruby/hbase/hbase.rb
@@ -23,6 +23,7 @@ include Java
 require 'hbase/admin'
 require 'hbase/table'
 require 'hbase/security'
+require 'hbase/coprocessor'
 
 module Hbase
   class Hbase
@@ -56,5 +57,9 @@ module Hbase
     def security_admin(formatter)
       ::Hbase::SecurityAdmin.new(configuration, formatter)
     end
+
+    def coprocessor(formatter)
+      ::Hbase::Coprocessor.new(configuration, formatter)
+    end
   end
 end
diff --git a/src/main/ruby/shell.rb b/src/main/ruby/shell.rb
index 768e554..57eac81 100644
--- a/src/main/ruby/shell.rb
+++ b/src/main/ruby/shell.rb
@@ -91,6 +91,10 @@ module Shell
       @hbase_security_admin ||= hbase.security_admin(formatter)
     end
 
+    def hbase_coprocessor
+      @hbase_coprocessor ||= hbase.coprocessor(formatter)
+    end
+
     def export_commands(where)
       ::Shell.commands.keys.each do |cmd|
         # here where is the IRB namespace
@@ -328,3 +332,11 @@ Shell.load_command_group(
   ]
 )
 
+Shell.load_command_group(
+  'coprocessor',
+  :full_name => 'CLUSTER COPROCESSOR TOOLS',
+  :comment => "In order to use these tools, hbase.coprocessor.region.classes must be set",
+  :commands => %w[
+    aggregate
+  ]
+)
diff --git a/src/main/ruby/shell/commands.rb b/src/main/ruby/shell/commands.rb
index c9004fa..c96167c 100644
--- a/src/main/ruby/shell/commands.rb
+++ b/src/main/ruby/shell/commands.rb
@@ -59,6 +59,10 @@ module Shell
         @shell.hbase_security_admin
       end
 
+      def hbase_coprocessor
+        @shell.hbase_coprocessor
+      end
+
       #----------------------------------------------------------------------
 
       def formatter
diff --git a/src/main/ruby/shell/commands/aggregate.rb b/src/main/ruby/shell/commands/aggregate.rb
new file mode 100644
index 0000000..87e2a16
--- /dev/null
+++ b/src/main/ruby/shell/commands/aggregate.rb
@@ -0,0 +1,78 @@
+#
+# Copyright 2010 The Apache Software Foundation
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class Aggregate < Command
+      def help
+        return <<-EOF
+Execute a Coprocessor aggregation function; pass aggregation function name, table name, column name, column interpreter and optionally a dictionary of aggregation specifications. Aggregation specifications may include STARTROW, STOPROW or FILTER. For a cross-site big table, if no clusters are specified, all clusters will be counted for aggregation.
+Usage: aggregate 'subcommand','table','column',[{COLUMN_INTERPRETER => org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.new, STARTROW => 'abc', STOPROW => 'def', FILTER => org.apache.hadoop.hbase.filter.ColumnPaginationFilter.new(1, 0)}]
+Available subcommands:
+  rowcount
+  min
+  max
+  sum
+  std
+  avg
+  median
+Available COLUMN_INTERPRETER:
+  org.apache.hadoop.hbase.client.coprocessor.LongColumnInterpreter.new
+  org.apache.hadoop.hbase.client.coprocessor.LongStrColumnInterpreter.new
+  org.apache.hadoop.hbase.client.coprocessor.CompositeLongStrColumnInterpreter.new(",", 0)
+The default COLUMN_INTERPRETER is org.apache.hadoop.hbase.client.coprocessor.LongStrColumnInterpreter.new.
+
+Some examples:
+
+  hbase>  aggregate 'min','t1','f1:c1'
+  hbase>  aggregate 'sum','t1','f1:c1','f1:c2'
+  hbase>  aggregate 'rowcount','t1','f1:c1' ,{COLUMN_INTERPRETER => org.apache.hadoop.hbase.client.coprocessor.CompositeLongStrColumnInterpreter.new(",", 0)}
+  hbase>  aggregate 'min','t1','f1:c1',{STARTROW => 'abc', STOPROW => 'def'}
+EOF
+      end
+
+      def command(command, table_name, *args)
+        raise(ArgumentError, "Command name must be of type String") unless command.kind_of?(String)
+        format_simple_command do
+          case command.downcase
+          when "rowcount"
+            result = hbase_coprocessor.rowcount(table_name, *args)
+          when "min"
+            result = hbase_coprocessor.min(table_name, *args)
+          when "max"
+            result = hbase_coprocessor.max(table_name, *args)
+          when "sum"
+            result = hbase_coprocessor.sum(table_name, *args)
+          when "std"
+            result = hbase_coprocessor.std(table_name, *args)
+          when "median"
+            result = hbase_coprocessor.median(table_name, *args)
+          when "avg"
+            result = hbase_coprocessor.avg(table_name, *args)
+          else
+            puts "Subcommand must be rowcount, min, max, sum, std, avg or median."
+            return
+          end   
+          puts "The result of " + command.downcase + " for table " + table_name + " is " +  result.to_s
+        end
+      end
+    end
+  end
+end
-- 
1.8.3.2

