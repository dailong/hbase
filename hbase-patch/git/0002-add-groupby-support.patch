From 3f4c5f88795ae27e4f5c0ac5693113330c6f7dd3 Mon Sep 17 00:00:00 2001
From: javachen <june.chan@foxmail.com>
Date: Thu, 16 Jan 2014 13:26:39 +0800
Subject: [PATCH 2/8] add-groupby-support

---
 bin/hirb.rb                                        |   4 +
 pom.xml                                            |   6 +-
 .../java/org/apache/hadoop/hbase/KeyValue.java     |   1 +
 .../hadoop/hbase/ProgressableCancellable.java      |   7 +
 .../apache/hadoop/hbase/client/HConnection.java    |   7 +
 .../hadoop/hbase/client/HConnectionManager.java    |  56 ++
 .../org/apache/hadoop/hbase/client/HTable.java     |  27 +-
 .../hbase/client/coprocessor/GroupByClient.java    | 824 +++++++++++++++++++++
 .../hbase/coprocessor/GroupByCombinedKey.java      | 115 +++
 .../hbase/coprocessor/GroupByImplementation.java   | 281 +++++++
 .../coprocessor/GroupByIntermediateResult.java     |  42 ++
 .../hadoop/hbase/coprocessor/GroupByProtocol.java  |  37 +
 .../hbase/coprocessor/RegionFlushObserver.java     |   9 +
 .../coprocessor/SplittableRegionObserver.java      |  10 +
 .../hbase/coprocessor/WALRestoreFlushObserver.java |  13 +
 .../hadoop/hbase/coprocessor/batch/BatchExec.java  |  96 +++
 .../hbase/coprocessor/batch/BatchExecCall.java     |  24 +
 .../hbase/coprocessor/batch/BatchExecClient.java   | 169 +++++
 .../coprocessor/batch/BatchExecRPCInvoker.java     |  60 ++
 .../hbase/coprocessor/batch/BatchExecResult.java   |  51 ++
 .../hadoop/hbase/execengine/ExecutionClient.java   | 809 ++++++++++++++++++++
 .../hadoop/hbase/execengine/ExecutionUtil.java     | 317 ++++++++
 .../hbase/expression/ArithmeticExpression.java     | 146 ++++
 .../expression/AvroColumnValueExpression.java      | 123 +++
 .../hbase/expression/BytesPartExpression.java      | 170 +++++
 .../hadoop/hbase/expression/CaseExpression.java    | 223 ++++++
 .../hbase/expression/ColumnValueExpression.java    |  76 ++
 .../hbase/expression/ComparisonExpression.java     | 153 ++++
 .../hbase/expression/ConstantExpression.java       |  83 +++
 .../apache/hadoop/hbase/expression/Expression.java |  14 +
 .../hbase/expression/ExpressionException.java      |  12 +
 .../hadoop/hbase/expression/ExpressionFactory.java | 263 +++++++
 .../expression/GroupByAggregationExpression.java   | 147 ++++
 .../hbase/expression/GroupByKeyExpression.java     |  78 ++
 .../hadoop/hbase/expression/InExpression.java      | 114 +++
 .../hadoop/hbase/expression/LogicalExpression.java | 135 ++++
 .../hadoop/hbase/expression/NotExpression.java     |  71 ++
 .../hadoop/hbase/expression/RowExpression.java     |  39 +
 .../hbase/expression/StringConcatExpression.java   | 119 +++
 .../hbase/expression/StringMatchExpression.java    | 100 +++
 .../hbase/expression/StringPartExpression.java     | 165 +++++
 .../hbase/expression/StringReverseExpression.java  |  73 ++
 .../hbase/expression/SubSequenceExpression.java    | 138 ++++
 .../hbase/expression/SubstringExpression.java      | 133 ++++
 .../hadoop/hbase/expression/TernaryExpression.java | 114 +++
 .../hbase/expression/ToBigDecimalExpression.java   |  94 +++
 .../hbase/expression/ToBooleanExpression.java      |  93 +++
 .../hadoop/hbase/expression/ToByteExpression.java  | 100 +++
 .../hadoop/hbase/expression/ToBytesExpression.java | 120 +++
 .../hbase/expression/ToDoubleExpression.java       | 109 +++
 .../hadoop/hbase/expression/ToFloatExpression.java | 109 +++
 .../hbase/expression/ToIntegerExpression.java      | 109 +++
 .../hadoop/hbase/expression/ToLongExpression.java  | 109 +++
 .../hadoop/hbase/expression/ToShortExpression.java | 109 +++
 .../hbase/expression/ToStringExpression.java       |  99 +++
 .../expression/evaluation/BytesReference.java      |  60 ++
 .../expression/evaluation/EvaluationContext.java   | 121 +++
 .../expression/evaluation/EvaluationException.java |  14 +
 .../expression/evaluation/EvaluationResult.java    | 711 ++++++++++++++++++
 .../hbase/expression/evaluation/StatsValue.java    | 113 +++
 .../evaluation/TypeConversionException.java        |  18 +
 .../evaluation/ValueNotAvailableException.java     |  19 +
 .../hbase/expression/visitor/ColumnVisitor.java    |  48 ++
 .../expression/visitor/ExpressionTraversal.java    |  52 ++
 .../expression/visitor/ExpressionVisitor.java      |  13 +
 .../expression/visitor/IsConstantVisitor.java      |  25 +
 .../hbase/filter/BinaryPartialComparator.java      |  42 ++
 .../hbase/filter/BinarySuffixComparator.java       |  19 +
 .../hadoop/hbase/filter/ExpressionFilter.java      |  68 ++
 .../apache/hadoop/hbase/filter/InComparator.java   | 100 +++
 .../hadoop/hbase/filter/MultiRowRangeFilter.java   | 396 ++++++++++
 .../hadoop/hbase/filter/ReferenceOnlyFilter.java   |  22 +
 .../apache/hadoop/hbase/ipc/HRegionInterface.java  |  14 +-
 .../apache/hadoop/hbase/regionserver/HRegion.java  |  62 ++
 .../hadoop/hbase/regionserver/HRegionServer.java   | 116 ++-
 src/main/ruby/hbase.rb                             |   2 +
 src/main/ruby/hbase/coprocessor.rb                 |  39 +
 src/main/ruby/shell.rb                             |   1 +
 src/main/ruby/shell/commands/groupby.rb            |  51 ++
 79 files changed, 8820 insertions(+), 11 deletions(-)
 create mode 100644 src/main/java/org/apache/hadoop/hbase/ProgressableCancellable.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/client/coprocessor/GroupByClient.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByCombinedKey.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByImplementation.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByIntermediateResult.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByProtocol.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/RegionFlushObserver.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/SplittableRegionObserver.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/WALRestoreFlushObserver.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExec.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecCall.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecClient.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecRPCInvoker.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecResult.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/execengine/ExecutionClient.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/execengine/ExecutionUtil.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ArithmeticExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/AvroColumnValueExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/BytesPartExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/CaseExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ColumnValueExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ComparisonExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ConstantExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/Expression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ExpressionException.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ExpressionFactory.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/GroupByAggregationExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/GroupByKeyExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/InExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/LogicalExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/NotExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/RowExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/StringConcatExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/StringMatchExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/StringPartExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/StringReverseExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/SubSequenceExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/SubstringExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/TernaryExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToBigDecimalExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToBooleanExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToByteExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToBytesExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToDoubleExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToFloatExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToIntegerExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToLongExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToShortExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/ToStringExpression.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/BytesReference.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationContext.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationException.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationResult.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/StatsValue.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/TypeConversionException.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/evaluation/ValueNotAvailableException.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/visitor/ColumnVisitor.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionTraversal.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionVisitor.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/expression/visitor/IsConstantVisitor.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/filter/BinaryPartialComparator.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/filter/BinarySuffixComparator.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/filter/ExpressionFilter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/filter/InComparator.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/filter/MultiRowRangeFilter.java
 create mode 100644 src/main/java/org/apache/hadoop/hbase/filter/ReferenceOnlyFilter.java
 create mode 100644 src/main/ruby/shell/commands/groupby.rb

diff --git a/bin/hirb.rb b/bin/hirb.rb
index 32a51b3..19f9c74 100644
--- a/bin/hirb.rb
+++ b/bin/hirb.rb
@@ -33,6 +33,10 @@
 # Run the java magic include and import basic HBase types that will help ease
 # hbase hacking.
 include Java
+include_class 'org.apache.hadoop.hbase.expression.ExpressionFactory' do |package,name|
+  "Exp"
+end
+
 
 # Some goodies for hirb. Should these be left up to the user's discretion?
 require 'irb/completion'
diff --git a/pom.xml b/pom.xml
index a713a6a..65081c6 100644
--- a/pom.xml
+++ b/pom.xml
@@ -1138,7 +1138,11 @@
         * javax.servlet:jsp-api in favour of org.mortbay.jetty:jsp-api-2.1
         * javax.xml.stream:stax-api in favour of stax:stax-api
     -->
-
+   <dependency>
+		<groupId>org.apache.avro</groupId>
+		<artifactId>avro</artifactId>
+		<version>1.7.4</version>
+	</dependency>
 
     <!-- General dependencies -->
     <dependency>
diff --git a/src/main/java/org/apache/hadoop/hbase/KeyValue.java b/src/main/java/org/apache/hadoop/hbase/KeyValue.java
index 39d1f09..ebbbf1b 100644
--- a/src/main/java/org/apache/hadoop/hbase/KeyValue.java
+++ b/src/main/java/org/apache/hadoop/hbase/KeyValue.java
@@ -174,6 +174,7 @@ public class KeyValue implements Writable, HeapSize {
     Delete((byte)8),
     DeleteColumn((byte)12),
     DeleteFamily((byte)14),
+    Reference((byte)45),
 
     // Maximum is used when searching; you look from maximum on down.
     Maximum((byte)255);
diff --git a/src/main/java/org/apache/hadoop/hbase/ProgressableCancellable.java b/src/main/java/org/apache/hadoop/hbase/ProgressableCancellable.java
new file mode 100644
index 0000000..314a637
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/ProgressableCancellable.java
@@ -0,0 +1,7 @@
+package org.apache.hadoop.hbase;
+
+public abstract interface ProgressableCancellable {
+	public abstract long getProgress();
+
+	public abstract void cancel();
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/client/HConnection.java b/src/main/java/org/apache/hadoop/hbase/client/HConnection.java
index 576e2d2..b4b38df 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/HConnection.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/HConnection.java
@@ -38,6 +38,7 @@ import org.apache.hadoop.hbase.client.coprocessor.Batch;
 import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
 import org.apache.hadoop.hbase.ipc.HMasterInterface;
 import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
 
 /**
@@ -389,4 +390,10 @@ public interface HConnection extends Abortable, Closeable {
    * @param sn A server name as hostname:port
    */
   public void clearCaches(final String sn);
+  
+  public abstract <T extends CoprocessorProtocol, R> void processExecs(
+      Class<T> paramClass,
+      List<Pair<byte[], Batch.Call<T, R>>> paramList,
+      byte[] paramArrayOfByte, ExecutorService paramExecutorService,
+      Batch.Callback<R> paramCallback) throws IOException, Throwable;
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java b/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
index 457af66..3eb1933 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
@@ -63,6 +63,8 @@ import org.apache.hadoop.hbase.ZooKeeperConnectionException;
 import org.apache.hadoop.hbase.client.MetaScanner.MetaScannerVisitor;
 import org.apache.hadoop.hbase.client.MetaScanner.MetaScannerVisitorBase;
 import org.apache.hadoop.hbase.client.coprocessor.Batch;
+import org.apache.hadoop.hbase.client.coprocessor.Batch.Call;
+import org.apache.hadoop.hbase.client.coprocessor.Batch.Callback;
 import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
 import org.apache.hadoop.hbase.ipc.ExecRPCInvoker;
 import org.apache.hadoop.hbase.ipc.HBaseRPC;
@@ -1868,6 +1870,60 @@ public class HConnectionManager {
       }
       throw new TableNotFoundException(Bytes.toString(tableName));
     }
+
+    @Override
+    public <T extends CoprocessorProtocol, R> void processExecs(
+        final Class<T> protocol,
+        List<Pair<byte[], Batch.Call<T, R>>> calls, byte[] tableName,
+        ExecutorService pool, final Batch.Callback<R> callback)
+        throws IOException, Throwable {
+      Map<byte[], Future<R>> futures = new TreeMap<byte[], Future<R>>(
+          Bytes.BYTES_COMPARATOR);
+
+      for (Pair p : calls) {
+        final byte[] r = (byte[]) p.getFirst();
+        final Batch.Call<T, R> call = (Batch.Call) p.getSecond();
+        final ExecRPCInvoker invoker = new ExecRPCInvoker(
+            HConnectionManager.HConnectionImplementation.this.conf,
+            this, protocol, tableName, r);
+
+        Future<R> future = pool.submit(new Callable<R>() {
+          public R call() throws Exception {
+            @SuppressWarnings("unchecked")
+            T instance = (T) Proxy
+                .newProxyInstance(
+                    HConnectionManager.HConnectionImplementation.class
+                        .getClassLoader(),
+                    new Class[] { protocol }, invoker);
+
+            R result = call.call(instance);
+            byte[] region = invoker.getRegionName();
+            if (callback != null) {
+              callback.update(region, r, result);
+            }
+            return result;
+          }
+        });
+        futures.put(r, future);
+      }
+      for (Map.Entry<byte[], Future<R>> e : futures.entrySet())
+        try {
+          ((Future<R>) e.getValue()).get();
+        } catch (ExecutionException ee) {
+          LOG.warn(
+              new StringBuilder()
+                  .append("Error executing for row ")
+                  .append(Bytes.toStringBinary((byte[]) e
+                      .getKey())).toString(), ee);
+          throw ee.getCause();
+        } catch (InterruptedException ie) {
+          Thread.currentThread().interrupt();
+          throw new IOException(new StringBuilder()
+              .append("Interrupted executing for row ")
+              .append(Bytes.toStringBinary((byte[]) e.getKey()))
+              .toString(), ie);
+        }
+    }
   }
 
   /**
diff --git a/src/main/java/org/apache/hadoop/hbase/client/HTable.java b/src/main/java/org/apache/hadoop/hbase/client/HTable.java
index e00ebe1..80de0e1 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/HTable.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/HTable.java
@@ -26,17 +26,16 @@ import java.io.IOException;
 import java.lang.reflect.Proxy;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
-import java.util.Collections;
 import java.util.NavigableMap;
 import java.util.TreeMap;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -1135,7 +1134,7 @@ public class HTable implements HTableInterface {
    * The pool is used for mutli requests for this HTable
    * @return the pool used for mutli
    */
-  ExecutorService getPool() {
+  public ExecutorService getPool() {
     return this.pool;
   }
 
@@ -1313,4 +1312,24 @@ public class HTable implements HTableInterface {
     return operationTimeout;
   }
 
+  public <T extends CoprocessorProtocol, R> void coprocessorExec(
+      final Class<T> protocol,
+      final List<Pair<Pair<byte[], byte[]>, Batch.Call<T, R>>> callablePairs,
+      final Batch.Callback<R> callback) throws IOException, Throwable {
+    List<Pair<byte[],Batch.Call<T, R>>> calls = new ArrayList<Pair<byte[],Batch.Call<T, R>>>();
+    Pair<Pair<byte[], byte[]>, Batch.Call<T, R>> p;
+    for (Iterator<Pair<Pair<byte[], byte[]>, Batch.Call<T, R>>> i$ = callablePairs.iterator(); i$.hasNext();) {
+      p =  i$.next();
+      Pair<byte[], byte[]> startEndKey =p.getFirst();
+      List<byte[]> keys = getStartKeysInRange(
+          (byte[]) startEndKey.getFirst(),
+          (byte[]) startEndKey.getSecond());
+      for (byte[] key : keys)
+        calls.add(new Pair<byte[], Batch.Call<T, R>>(key, p.getSecond()));
+    }
+
+    this.connection.processExecs(protocol, calls, this.tableName,
+        this.pool, callback);
+  }
+
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/client/coprocessor/GroupByClient.java b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/GroupByClient.java
new file mode 100644
index 0000000..7108326
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/client/coprocessor/GroupByClient.java
@@ -0,0 +1,824 @@
+package org.apache.hadoop.hbase.client.coprocessor;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.SortedSet;
+import java.util.TreeMap;
+import java.util.TreeSet;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.client.coprocessor.Batch.Callback;
+import org.apache.hadoop.hbase.coprocessor.GroupByCombinedKey;
+import org.apache.hadoop.hbase.coprocessor.GroupByIntermediateResult;
+import org.apache.hadoop.hbase.coprocessor.GroupByProtocol;
+import org.apache.hadoop.hbase.execengine.ExecutionClient;
+import org.apache.hadoop.hbase.expression.BytesPartExpression;
+import org.apache.hadoop.hbase.expression.ColumnValueExpression;
+import org.apache.hadoop.hbase.expression.ConstantExpression;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.ExpressionException;
+import org.apache.hadoop.hbase.expression.GroupByAggregationExpression;
+import org.apache.hadoop.hbase.expression.GroupByKeyExpression;
+import org.apache.hadoop.hbase.expression.RowExpression;
+import org.apache.hadoop.hbase.expression.SubSequenceExpression;
+import org.apache.hadoop.hbase.expression.SubstringExpression;
+import org.apache.hadoop.hbase.expression.ToBytesExpression;
+import org.apache.hadoop.hbase.expression.ToStringExpression;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.expression.visitor.ColumnVisitor;
+import org.apache.hadoop.hbase.expression.visitor.ExpressionTraversal;
+import org.apache.hadoop.hbase.expression.visitor.ExpressionVisitor;
+import org.apache.hadoop.hbase.expression.visitor.IsConstantVisitor;
+import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Pair;
+
+import com.google.common.collect.MinMaxPriorityQueue;
+
+public class GroupByClient {
+	Configuration conf;
+	private int MAP_SIZE = 16;
+	private float LOAD_FACTOR = 0.75F;
+	private static final String BATCH_EXEC = "hbase.groupby.batch.execution";
+	protected static Log log = LogFactory.getLog(GroupByClient.class);
+
+	public GroupByClient(Configuration conf) {
+		this.conf = conf;
+	}
+
+	public List<EvaluationResult[]> groupBy(byte[] tableName, Scan[] scans,
+			List<Expression> groupByKeyExpressions,
+			List<Expression> selectExpressions, Expression havingExpression)
+			throws Throwable {
+		return groupBy(tableName, scans, groupByKeyExpressions,
+				selectExpressions, havingExpression, null, null);
+	}
+
+	public List<EvaluationResult[]> groupBy(byte[] tableName, Scan[] scans,
+			List<Expression> groupByKeyExpressions,
+			List<Expression> selectExpressions, Expression havingExpression,
+			int[] orderByIndices, boolean[] ascending) throws Throwable {
+		if (this.conf.getBoolean(BATCH_EXEC, false)) {
+			return new ExecutionClient(this.conf).groupBy(tableName, scans,
+					groupByKeyExpressions, selectExpressions, havingExpression,
+					orderByIndices, ascending);
+		}
+		List<Expression> groupByStatsExpressions = processSelectExpressions(
+				groupByKeyExpressions, selectExpressions, havingExpression);
+
+		Comparator<GroupByCombinedKey> comparator = processSortSpecs(
+				selectExpressions, orderByIndices, ascending);
+
+		List<EvaluationResult[]> ret = new ArrayList<EvaluationResult[]>();
+		Map<GroupByCombinedKey, List<StatsValue>> groupByMap = getStatsInternal(
+				tableName, scans, groupByKeyExpressions,
+				groupByStatsExpressions, comparator != null, comparator);
+
+		EvaluationContext context = new EvaluationContext(this.conf);
+		int count = selectExpressions.size();
+
+		for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : groupByMap
+				.entrySet()) {
+			context.setAggregationValues(entry.getKey(), entry.getValue());
+			Boolean b = null;
+			if (havingExpression != null) {
+				b = havingExpression.evaluate(context).asBoolean();
+			}
+			if ((havingExpression == null)
+					|| ((b != null) && (b.booleanValue() == true))) {
+				EvaluationResult[] resultRow = new EvaluationResult[count];
+				for (int i = 0; i < count; i++) {
+					resultRow[i] = selectExpressions.get(i).evaluate(context);
+				}
+				ret.add(resultRow);
+			}
+		}
+
+		if (comparator == null) {
+			log.debug("Perform additional sorting on resultsets... ");
+			Collections.sort(ret, createComparator(orderByIndices, ascending));
+		}
+
+		return ret;
+	}
+
+	public List<EvaluationResult[]> getTopNByRow(byte[] tableName,
+			final Scan[] scans, final List<Expression> selectExpressions,
+			final int[] orderByIndices, final boolean[] ascending,
+			final int topCount) throws Throwable {
+		if (this.conf.getBoolean(BATCH_EXEC, false)) {
+			return new ExecutionClient(this.conf).getTopNByRow(tableName,
+					scans, selectExpressions, orderByIndices, ascending,
+					topCount);
+		}
+		final MinMaxPriorityQueue<EvaluationResult[]> queue = MinMaxPriorityQueue
+				.orderedBy(createComparator(orderByIndices, ascending))
+				.maximumSize(topCount).create();
+
+		validateAndDecorateParameters(scans, new ArrayList<Expression>(),
+				selectExpressions);
+		Callback<List<EvaluationResult[]>> topNCB = new Batch.Callback<List<EvaluationResult[]>>() {
+			public synchronized void update(byte[] region, byte[] row,
+					List<EvaluationResult[]> resultList) {
+				for (Iterator<EvaluationResult[]> iter = resultList.iterator(); iter
+						.hasNext();)
+					queue.add(iter.next());
+			}
+		};
+		HTable table = new HTable(this.conf, tableName);
+
+		List<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, List<EvaluationResult[]>>>> calls = new ArrayList<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, List<EvaluationResult[]>>>>();
+
+		for (final Scan scan : scans) {
+			calls.add(new Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, List<EvaluationResult[]>>>(
+					new Pair<byte[], byte[]>(scan.getStartRow(), scan
+							.getStopRow()),
+					new Batch.Call<GroupByProtocol, List<EvaluationResult[]>>() {
+						public List<EvaluationResult[]> call(
+								GroupByProtocol instance) throws IOException {
+							return instance.getTopNByRow(scan,
+									selectExpressions, orderByIndices,
+									ascending, topCount);
+						}
+					}));
+		}
+		try {
+			table.coprocessorExec(GroupByProtocol.class, calls, topNCB);
+		} finally {
+			table.close();
+		}
+
+		List<EvaluationResult[]> ret = new ArrayList<EvaluationResult[]>();
+		EvaluationResult[] elem = queue.pollFirst();
+		while (elem != null) {
+			ret.add(elem);
+			elem = queue.pollFirst();
+		}
+		return ret;
+	}
+
+	public List<EvaluationResult[]> getTopN(byte[] tableName, Scan[] scans,
+			List<Expression> groupByKeyExpressions,
+			List<Expression> selectExpressions, Expression havingExpression,
+			int[] orderByIndices, boolean[] ascending, int topCount)
+			throws Throwable {
+		if (this.conf.getBoolean(BATCH_EXEC, false)) {
+			return new ExecutionClient(this.conf).getTopN(tableName, scans,
+					groupByKeyExpressions, selectExpressions, havingExpression,
+					orderByIndices, ascending, topCount);
+		}
+		boolean isRowGrouping = isRowGrouping(groupByKeyExpressions);
+		log.debug("Is row grouping? " + isRowGrouping);
+		List<EvaluationResult[]> ret;
+		if (isRowGrouping) {
+			List<Expression> groupByStatsExpressions = processSelectExpressions(
+					groupByKeyExpressions, selectExpressions, havingExpression);
+
+			Comparator<GroupByCombinedKey> comparator = processSortSpecs(
+					selectExpressions, orderByIndices, ascending);
+
+			boolean isSortedMap = comparator != null;
+			MinMaxPriorityQueue<EvaluationResult[]> queue = MinMaxPriorityQueue
+					.orderedBy(createComparator(orderByIndices, ascending))
+					.maximumSize(topCount).create();
+
+			Map<GroupByCombinedKey, List<StatsValue>> map = getTopNInternal(
+					tableName, scans, groupByKeyExpressions,
+					groupByStatsExpressions, selectExpressions,
+					havingExpression, orderByIndices, ascending, topCount,
+					queue, isSortedMap, comparator);
+
+			EvaluationContext context = new EvaluationContext(this.conf);
+			int count = selectExpressions.size();
+			int counter = 0;
+			for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : map
+					.entrySet()) {
+				if (isSortedMap) {
+					counter++;
+					if (counter > topCount)
+						break;
+				}
+				context.setAggregationValues(
+						(GroupByCombinedKey) entry.getKey(),
+						(List<StatsValue>) entry.getValue());
+				Boolean b = null;
+				if (havingExpression != null) {
+					b = havingExpression.evaluate(context).asBoolean();
+				}
+				if ((havingExpression == null)
+						|| ((b != null) && (b.booleanValue() == true))) {
+					EvaluationResult[] resultRow = new EvaluationResult[count];
+					for (int i = 0; i < count; i++) {
+						resultRow[i] = ((Expression) selectExpressions.get(i))
+								.evaluate(context);
+					}
+					queue.add(resultRow);
+				}
+			}
+
+			ret = new ArrayList<EvaluationResult[]>();
+			EvaluationResult[] elem = (EvaluationResult[]) queue.pollFirst();
+			while (elem != null) {
+				ret.add(elem);
+				elem = (EvaluationResult[]) queue.pollFirst();
+			}
+		} else {
+			List<EvaluationResult[]> groupByResults = groupBy(tableName, scans,
+					groupByKeyExpressions, selectExpressions, havingExpression,
+					orderByIndices, ascending);
+
+			ret = groupByResults.size() <= topCount ? groupByResults
+					: groupByResults.subList(0, topCount);
+		}
+
+		return ret;
+	}
+
+	public List<EvaluationResult[]> distinct(byte[] tableName, Scan[] scans,
+			final List<Expression> distinctExpressions,
+			GroupByAggregationExpression.AggregationType type) throws Throwable {
+		if (this.conf.getBoolean(BATCH_EXEC, false)) {
+			return new ExecutionClient(this.conf).distinct(tableName, scans,
+					distinctExpressions, type);
+		}
+		if ((type != null)
+				&& (type != GroupByAggregationExpression.AggregationType.COUNT)
+				&& (distinctExpressions.size() > 1)) {
+			throw new IOException("Aggregation '" + type.toString()
+					+ "' is not allowed on non-numeric types");
+		}
+		validateAndDecorateParameters(scans, distinctExpressions, null);
+		final SortedSet<GroupByCombinedKey> finalSet = new TreeSet<GroupByCombinedKey>(
+				GroupByCombinedKey.DEFAULT_COMPARATOR);
+
+		Callback<Set<GroupByCombinedKey>> distinctCB = new Batch.Callback<Set<GroupByCombinedKey>>() {
+			public synchronized void update(byte[] region, byte[] row,
+					Set<GroupByCombinedKey> resultSet) {
+				for (GroupByCombinedKey value : resultSet)
+					finalSet.add(value);
+			}
+		};
+		HTable table = new HTable(this.conf, tableName);
+
+		List<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, Set<GroupByCombinedKey>>>> calls = new ArrayList<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, Set<GroupByCombinedKey>>>>();
+
+		for (final Scan scan : scans)
+			calls.add(new Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, Set<GroupByCombinedKey>>>(
+					new Pair<byte[], byte[]>(scan.getStartRow(), scan
+							.getStopRow()),
+					new Batch.Call<GroupByProtocol, Set<GroupByCombinedKey>>() {
+						public Set<GroupByCombinedKey> call(
+								GroupByProtocol instance) throws IOException {
+							instance.setMapSize(GroupByClient.this.getMapSize());
+							return instance.distinct(scan, distinctExpressions);
+						}
+					}));
+		try {
+			table.coprocessorExec(GroupByProtocol.class, calls, distinctCB);
+		} finally {
+			table.close();
+		}
+
+		List<EvaluationResult[]> res = new ArrayList<EvaluationResult[]>();
+		if (type == null) {
+			for (GroupByCombinedKey value : finalSet)
+				res.add(value.getKeys());
+		} else {
+			EvaluationResult eval = null;
+			switch (type.ordinal()) {
+			case 1:
+				eval = new EvaluationResult(Integer.valueOf(finalSet.size()),
+						EvaluationResult.ResultType.INTEGER);
+				break;
+			case 2:
+				eval = finalSet.isEmpty() ? new EvaluationResult()
+						: ((GroupByCombinedKey) finalSet.first()).getKeys()[0];
+				break;
+			case 3:
+				eval = finalSet.isEmpty() ? new EvaluationResult()
+						: ((GroupByCombinedKey) finalSet.last()).getKeys()[0];
+				break;
+			case 4:
+				if (!finalSet.isEmpty()) {
+					eval = new EvaluationResult(Integer.valueOf(0),
+							EvaluationResult.ResultType.LONG);
+					for (GroupByCombinedKey value : finalSet) {
+						EvaluationResult val = value.getKeys()[0];
+						if (!val.isNullResult())
+							eval = EvaluationResult.numberAdd(eval, val);
+					}
+				} else {
+					eval = new EvaluationResult();
+				}
+				break;
+			case 5:
+				int count = finalSet.size();
+				if (count > 0) {
+					eval = new EvaluationResult(Integer.valueOf(0),
+							EvaluationResult.ResultType.LONG);
+					for (GroupByCombinedKey value : finalSet) {
+						EvaluationResult val = value.getKeys()[0];
+						if (!val.isNullResult())
+							eval = EvaluationResult.numberAdd(eval, val);
+					}
+					eval = EvaluationResult.numberDivide(eval,
+							new EvaluationResult(Integer.valueOf(count),
+									EvaluationResult.ResultType.INTEGER));
+				} else {
+					eval = new EvaluationResult();
+				}
+				break;
+			case 6:
+				count = finalSet.size();
+				if (count > 0) {
+					double sum = 0.0D;
+					double sumOfSquares = 0.0D;
+					for (GroupByCombinedKey value : finalSet) {
+						EvaluationResult val = value.getKeys()[0];
+						if (!val.isNullResult()) {
+							double d = val.asDouble().doubleValue();
+							sum += d;
+							sumOfSquares += d * d;
+						}
+					}
+					double avg = sum / count;
+					double avgOfSumOfSquares = sumOfSquares / count;
+					eval = new EvaluationResult(Double.valueOf(Math.pow(
+							avgOfSumOfSquares - avg * avg, 0.5D)),
+							EvaluationResult.ResultType.DOUBLE);
+				} else {
+					eval = new EvaluationResult();
+				}
+				break;
+			default:
+				throw new IOException("Unsupported aggregation type " + type);
+			}
+
+			res.add(new EvaluationResult[] { eval });
+		}
+
+		return res;
+	}
+
+	protected boolean isRowGrouping(List<Expression> keyExpressions) {
+		if (keyExpressions.size() != 1) {
+			return false;
+		}
+		Expression keyExpr = (Expression) keyExpressions.get(0);
+		if ((keyExpr instanceof SubSequenceExpression)) {
+			return ((((SubSequenceExpression) keyExpr).getSource() instanceof RowExpression))
+					&& ((((SubSequenceExpression) keyExpr).getStart() instanceof ConstantExpression))
+					&& (((ConstantExpression) ((SubSequenceExpression) keyExpr)
+							.getStart()).getConstant().equals(Integer
+							.valueOf(0)));
+		}
+
+		if ((keyExpr instanceof ToBytesExpression)) {
+			Expression firstLevelExpr = ((ToBytesExpression) keyExpr)
+					.getSubExpression();
+			if ((firstLevelExpr instanceof SubstringExpression)) {
+				return ((((SubstringExpression) firstLevelExpr).getSource() instanceof ToStringExpression))
+						&& ((((ToStringExpression) ((SubstringExpression) firstLevelExpr)
+								.getSource()).getSubExpression() instanceof RowExpression))
+						&& ((((SubstringExpression) firstLevelExpr).getStart() instanceof ConstantExpression))
+						&& (((ConstantExpression) ((SubstringExpression) firstLevelExpr)
+								.getStart()).getConstant().equals(Integer
+								.valueOf(0)));
+			}
+
+			if ((firstLevelExpr instanceof BytesPartExpression)) {
+				return ((((BytesPartExpression) firstLevelExpr).getSource() instanceof RowExpression))
+						&& ((((BytesPartExpression) firstLevelExpr).getIndex() instanceof ConstantExpression))
+						&& (((ConstantExpression) ((BytesPartExpression) firstLevelExpr)
+								.getIndex()).getConstant().equals(Integer
+								.valueOf(0)));
+			}
+
+			return false;
+		}
+
+		return (keyExpr instanceof RowExpression);
+	}
+
+	protected Map<GroupByCombinedKey, List<StatsValue>> getTopNInternal(
+			byte[] tableName, Scan[] scans,
+			final List<Expression> groupByKeyExpressions,
+			final List<Expression> groupByStatsExpressions,
+			final List<Expression> selectExpressions,
+			final Expression havingExpression, final int[] orderByIndices,
+			final boolean[] ascending, final int topCount,
+			final MinMaxPriorityQueue<EvaluationResult[]> queue,
+			boolean requireSortedMap, Comparator<GroupByCombinedKey> comparator)
+			throws Throwable {
+		final Map<GroupByCombinedKey, List<StatsValue>> map = requireSortedMap ? new TreeMap<GroupByCombinedKey, List<StatsValue>>(
+				comparator)
+				: new HashMap<GroupByCombinedKey, List<StatsValue>>();
+
+		validateAndDecorateParameters(scans, groupByKeyExpressions,
+				groupByStatsExpressions);
+		class TopNCallback implements Batch.Callback<GroupByIntermediateResult> {
+			Throwable lastException = null;
+
+			public Throwable getLastException() {
+				return this.lastException;
+			}
+
+			public synchronized void update(byte[] region, byte[] row,
+					GroupByIntermediateResult result) {
+				Iterator<EvaluationResult[]> iter = result.getTopList()
+						.iterator();
+				while (iter.hasNext()) {
+					queue.add((EvaluationResult[]) iter.next());
+				}
+				for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : result
+						.getStatsMap().entrySet()) {
+					List<StatsValue> finalStats = map.get(entry.getKey());
+					Iterator<StatsValue> itFinal;
+					Iterator<StatsValue> itTemp;
+					if (finalStats != null) {
+						itFinal = finalStats.iterator();
+						for (itTemp = entry.getValue().iterator(); itFinal
+								.hasNext();)
+							try {
+								((StatsValue) itFinal.next())
+										.accumulate((StatsValue) itTemp.next());
+							} catch (TypeConversionException e) {
+								this.lastException = e;
+							}
+					} else {
+						map.put(entry.getKey(), entry.getValue());
+					}
+				}
+			}
+		}
+		;
+
+		TopNCallback topNCB = new TopNCallback();
+		HTable table = new HTable(this.conf, tableName);
+
+		List<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, GroupByIntermediateResult>>> calls = new ArrayList<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, GroupByIntermediateResult>>>();
+
+		for (final Scan scan : scans) {
+			calls.add(new Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, GroupByIntermediateResult>>(
+					new Pair<byte[], byte[]>(scan.getStartRow(), scan
+							.getStopRow()),
+					new Batch.Call<GroupByProtocol, GroupByIntermediateResult>() {
+						public GroupByIntermediateResult call(
+								GroupByProtocol instance) throws IOException {
+							return instance.getTopNByRowGrouping(scan,
+									groupByKeyExpressions,
+									groupByStatsExpressions, selectExpressions,
+									havingExpression, orderByIndices,
+									ascending, topCount);
+						}
+					}));
+		}
+		try {
+			table.coprocessorExec(GroupByProtocol.class, calls, topNCB);
+		} finally {
+			table.close();
+		}
+
+		if (topNCB.getLastException() != null) {
+			throw topNCB.getLastException();
+		}
+
+		return map;
+	}
+
+	protected Map<GroupByCombinedKey, List<StatsValue>> getStatsInternal(
+			byte[] tableName, Scan[] scans,
+			final List<Expression> groupByKeyExpressions,
+			final List<Expression> groupByStatsExpressions,
+			final boolean requireSortedMap,
+			final Comparator<GroupByCombinedKey> comparator) throws Throwable {
+		final boolean isConstantGroupByKey = validateAndDecorateParameters(
+				scans, groupByKeyExpressions, groupByStatsExpressions);
+
+		log.debug("Is constant group-by key? " + isConstantGroupByKey);
+
+		class RowNumCallback implements
+				Batch.Callback<Map<GroupByCombinedKey, List<StatsValue>>> {
+			private Map<GroupByCombinedKey, List<StatsValue>> finalMap = requireSortedMap ? new TreeMap<GroupByCombinedKey, List<StatsValue>>(
+					comparator)
+					: new HashMap<GroupByCombinedKey, List<StatsValue>>();
+
+			Throwable lastException = null;
+
+			public Map<GroupByCombinedKey, List<StatsValue>> getFinalMap() {
+				return this.finalMap;
+			}
+
+			public Throwable getLastException() {
+				return this.lastException;
+			}
+
+			public synchronized void update(byte[] region, byte[] row,
+					Map<GroupByCombinedKey, List<StatsValue>> resultMap) {
+				for (GroupByCombinedKey facet : resultMap.keySet()) {
+					List<StatsValue> finalStats = this.finalMap.get(facet);
+					Iterator<StatsValue> itFinal;
+					Iterator<StatsValue> itTemp;
+					if (finalStats != null) {
+						itFinal = finalStats.iterator();
+						for (itTemp = resultMap.get(facet).iterator(); itFinal
+								.hasNext();)
+							try {
+								itFinal.next().accumulate(
+										(StatsValue) itTemp.next());
+							} catch (TypeConversionException e) {
+								this.lastException = e;
+							}
+					} else {
+						this.finalMap.put(facet, resultMap.get(facet));
+					}
+				}
+			}
+		}
+		;
+
+		RowNumCallback rowNumCB = new RowNumCallback();
+		HTable table = new HTable(this.conf, tableName);
+
+		List<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>>> calls = new ArrayList<Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>>>();
+
+		for (final Scan scan : scans) {
+			calls.add(new Pair<Pair<byte[], byte[]>, Batch.Call<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>>(
+					new Pair<byte[], byte[]>(scan.getStartRow(), scan
+							.getStopRow()),
+					new Batch.Call<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>() {
+						public Map<GroupByCombinedKey, List<StatsValue>> call(
+								GroupByProtocol instance) throws IOException {
+							instance.setMapSize(GroupByClient.this.getMapSize());
+							return instance.getStats(scan,
+									groupByKeyExpressions,
+									groupByStatsExpressions,
+									isConstantGroupByKey);
+						}
+					}));
+		}
+		try {
+			table.coprocessorExec(GroupByProtocol.class, calls, rowNumCB);
+		} finally {
+			table.close();
+		}
+
+		if (rowNumCB.getLastException() != null) {
+			throw rowNumCB.getLastException();
+		}
+
+		return rowNumCB.getFinalMap();
+	}
+
+	private List<Expression> processSelectExpressions(
+			final List<Expression> groupByKeyExpressions,
+			List<Expression> selectExpressions, Expression havingExpression)
+			throws ExpressionException {
+		final List<Expression> groupByStatsExpressions = new ArrayList<Expression>();
+		ExpressionVisitor visitor = new ExpressionVisitor() {
+			public ExpressionVisitor.ReturnCode processExpression(
+					Expression expression) throws ExpressionException {
+				if ((expression instanceof RowExpression)) {
+					throw new ExpressionException(
+							"The group-by select expression cannot contain RowExpression");
+				}
+				if ((expression instanceof ColumnValueExpression)) {
+					throw new ExpressionException(
+							"The group-by select expression cannot contain ColumnValueExpression");
+				}
+				if ((expression instanceof GroupByKeyExpression)) {
+					GroupByKeyExpression keyExpr = (GroupByKeyExpression) expression;
+					Expression refExpr = keyExpr.getReferenceExpression();
+					if (refExpr == null) {
+						throw new ExpressionException(
+								"The group-by key expression cannot contain null expressions");
+					}
+					for (int i = 0; i < groupByKeyExpressions.size(); i++) {
+						if (refExpr.equals(groupByKeyExpressions.get(i))) {
+							keyExpr.setKeyIndex(i);
+							break;
+						}
+					}
+					if (keyExpr.getKeyIndex() == GroupByKeyExpression.INVALID_KEY_ID) {
+						throw new ExpressionException(
+								"Could not find group-by key expression: "
+										+ refExpr);
+					}
+					return ExpressionVisitor.ReturnCode.SKIP_SUBTREE;
+				}
+				if ((expression instanceof GroupByAggregationExpression)) {
+					GroupByAggregationExpression aggrExpr = (GroupByAggregationExpression) expression;
+					Expression statsExpr = aggrExpr.getSubExpression();
+					if (statsExpr == null) {
+						throw new ExpressionException(
+								"The group-by aggregation expression cannot contain null expressions");
+					}
+					if ((aggrExpr.getType() != GroupByAggregationExpression.AggregationType.COUNT)
+							&& (!EvaluationResult.isNumber(statsExpr
+									.getReturnType()))) {
+						throw new ExpressionException(
+								"Invalid return type for group-by stats expression: "
+										+ statsExpr.getReturnType());
+					}
+
+					for (int i = 0; i < groupByStatsExpressions.size(); i++) {
+						if (statsExpr.equals(groupByStatsExpressions.get(i))) {
+							aggrExpr.setStatsIndex(i);
+							break;
+						}
+					}
+					if (aggrExpr.getStatsIndex() == GroupByAggregationExpression.INVALID_STATS_INDEX) {
+						aggrExpr.setStatsIndex(groupByStatsExpressions.size());
+						groupByStatsExpressions.add(statsExpr);
+					}
+					return ExpressionVisitor.ReturnCode.SKIP_SUBTREE;
+				}
+				return ExpressionVisitor.ReturnCode.CONTINUE;
+			}
+		};
+		for (Expression expr : selectExpressions) {
+			ExpressionTraversal.traverse(expr, visitor);
+		}
+		if (havingExpression != null) {
+			ExpressionTraversal.traverse(havingExpression, visitor);
+		}
+
+		return groupByStatsExpressions;
+	}
+
+	private Comparator<GroupByCombinedKey> processSortSpecs(
+			List<Expression> selectExpressions, int[] orderByIndices,
+			final boolean[] ascending) {
+		if (orderByIndices == null) {
+			return GroupByCombinedKey.DEFAULT_COMPARATOR;
+		}
+		int count = orderByIndices.length;
+		final int[] keySorting = new int[count];
+		for (int i = 0; i < count; i++) {
+			Expression expr = (Expression) selectExpressions
+					.get(orderByIndices[i]);
+			if (!(expr instanceof GroupByKeyExpression)) {
+				return null;
+			}
+			keySorting[i] = ((GroupByKeyExpression) expr).getKeyIndex();
+		}
+
+		return new Comparator<GroupByCombinedKey>() {
+			public int compare(GroupByCombinedKey left, GroupByCombinedKey right) {
+				int comp = left.getKeys().length - right.getKeys().length;
+				if (comp != 0) {
+					return comp;
+				}
+				for (int i = 0; i < keySorting.length; i++) {
+					int keyIndex = keySorting[i];
+					comp = EvaluationResult.NULL_AS_MAX_COMPARATOR
+							.compare(left.getKeys()[keyIndex],
+									right.getKeys()[keyIndex]);
+
+					if (comp != 0) {
+						return ascending[i] != false ? comp : -comp;
+					}
+				}
+				return 0;
+			}
+		};
+	}
+
+	private Comparator<EvaluationResult[]> createComparator(
+			final int[] orderByIndices, final boolean[] ascending) {
+		return new Comparator<EvaluationResult[]>() {
+			public int compare(EvaluationResult[] left, EvaluationResult[] right) {
+				int comp = left.length - right.length;
+				if (comp == 0) {
+					for (int i = 0; i < orderByIndices.length; i++) {
+						int index = orderByIndices[i];
+						comp = EvaluationResult.NULL_AS_MAX_COMPARATOR.compare(
+								left[index], right[index]);
+						if (comp != 0) {
+							if (ascending[i] != false)
+								break;
+							comp = -comp;
+							break;
+						}
+					}
+
+				}
+
+				return comp;
+			}
+		};
+	}
+
+	private boolean validateAndDecorateParameters(Scan[] scans,
+			List<Expression> groupByKeyExpressions,
+			List<Expression> groupByStatsExpressions) throws IOException,
+			ExpressionException {
+		for (Scan scan : scans) {
+			if ((scan != null)
+					&& ((!Bytes.equals(scan.getStartRow(), scan.getStopRow())) || (Bytes
+							.equals(scan.getStartRow(),
+									HConstants.EMPTY_START_ROW)))
+					&& ((Bytes.compareTo(scan.getStartRow(), scan.getStopRow()) <= 0) || (Bytes
+							.equals(scan.getStopRow(), HConstants.EMPTY_END_ROW)))) {
+				continue;
+			}
+
+			throw new IOException(
+					"GroupBy client Exception: Startrow should be smaller than Stoprow");
+		}
+
+		List<Pair<byte[], byte[]>> columns = new ArrayList<Pair<byte[], byte[]>>();
+		boolean isConstantGroupByKey = true;
+		for (Expression keyExpr : groupByKeyExpressions) {
+			ColumnVisitor visitor = new ColumnVisitor();
+			ExpressionTraversal.traverse(keyExpr, visitor);
+			for (Pair<byte[], byte[]> columnPair : visitor.getColumnSet()) {
+				if ((columnPair.getFirst() == null)
+						|| (columnPair.getSecond() == null))
+					throw new IllegalArgumentException(
+							"ColumnValueExpression cannot specify null family or qualifier");
+				columns.add(columnPair);
+			}
+
+			if ((isConstantGroupByKey) && (visitor.getColumnSet().isEmpty())) {
+				IsConstantVisitor constVisitor = new IsConstantVisitor();
+				ExpressionTraversal.traverse(keyExpr, constVisitor);
+				isConstantGroupByKey = constVisitor.isConstant();
+			} else {
+				isConstantGroupByKey = false;
+			}
+		}
+
+		ExpressionVisitor groupByExprCheckVisitor = new ExpressionVisitor() {
+			public ExpressionVisitor.ReturnCode processExpression(
+					Expression expression) throws ExpressionException {
+				if ((expression instanceof GroupByKeyExpression)) {
+					throw new ExpressionException(
+							"The stats expression cannot contain GroupByKeyExpression");
+				}
+				if ((expression instanceof GroupByAggregationExpression)) {
+					throw new ExpressionException(
+							"The stats expression cannot contain GroupByAggregationExpression");
+				}
+				return ExpressionVisitor.ReturnCode.CONTINUE;
+			}
+		};
+		if (groupByStatsExpressions != null) {
+			for (Expression statsExpr : groupByStatsExpressions) {
+				ExpressionTraversal
+						.traverse(statsExpr, groupByExprCheckVisitor);
+				ColumnVisitor visitor = new ColumnVisitor();
+				ExpressionTraversal.traverse(statsExpr, visitor);
+				for (Pair<byte[], byte[]> columnPair : visitor.getColumnSet()) {
+					if ((columnPair.getFirst() == null)
+							|| (columnPair.getSecond() == null))
+						throw new IllegalArgumentException(
+								"ColumnValueExpression cannot specify null family or qualifier");
+					columns.add(columnPair);
+				}
+			}
+		}
+
+		for (Scan scan : scans) {
+			scan.setCacheBlocks(false);
+			scan.getFamilyMap().clear();
+			if ((columns.isEmpty()) && (!scan.hasFilter())) {
+				log.debug("Use FirstKeyOnlyFilter");
+				scan.setFilter(new FirstKeyOnlyFilter());
+			}
+		}
+
+		return isConstantGroupByKey;
+	}
+
+	public int getMapSize() {
+		return this.MAP_SIZE;
+	}
+
+	public float getMapLoadFactor() {
+		return this.LOAD_FACTOR;
+	}
+
+	public void setMapLoadFactor(float loadFactor) {
+		this.LOAD_FACTOR = loadFactor;
+	}
+
+	public void setMapSize(int mapSize) {
+		this.MAP_SIZE = mapSize;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByCombinedKey.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByCombinedKey.java
new file mode 100644
index 0000000..8d60c26
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByCombinedKey.java
@@ -0,0 +1,115 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.Comparator;
+import java.util.List;
+
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.io.Writable;
+
+public class GroupByCombinedKey implements Writable, Serializable {
+  private static final long serialVersionUID = 2560573700294001437L;
+  private EvaluationResult[] keys;
+  public static final Comparator<GroupByCombinedKey> DEFAULT_COMPARATOR =
+      new Comparator<GroupByCombinedKey>() {
+        public int compare(GroupByCombinedKey left, GroupByCombinedKey right) {
+          int comp = left.keys.length - right.keys.length;
+          if (comp != 0) {
+            return comp;
+          }
+          for (int i = 0; i < left.keys.length; i++) {
+            comp = EvaluationResult.NULL_AS_MAX_COMPARATOR.compare(
+              left.keys[i], right.keys[i]);
+            if (comp != 0) {
+              return comp;
+            }
+          }
+          return 0;
+        }
+      };
+
+  public GroupByCombinedKey() {
+    this.keys = new EvaluationResult[0];
+  }
+
+  protected GroupByCombinedKey(EvaluationResult[] keys) {
+    this();
+    if (keys != null) this.keys = keys;
+  }
+
+  public static GroupByCombinedKey getCombinedKey(
+      List<Expression> groupByKeyExpressions, EvaluationContext context)
+      throws IOException {
+    int size = groupByKeyExpressions.size();
+    EvaluationResult[] keys = new EvaluationResult[size];
+    try {
+      for (int i = 0; i < size; i++)
+        keys[i] = ((Expression) groupByKeyExpressions.get(i)).evaluate(
+          context).asSerializableResult();
+    } catch (Throwable t) {
+      throw ((IOException) (IOException) new IOException().initCause(t));
+    }
+    return new GroupByCombinedKey(keys);
+  }
+
+  public EvaluationResult[] getKeys() {
+    return this.keys;
+  }
+
+  public String getStringValue(String delimiter) {
+    StringBuilder sb = new StringBuilder();
+    for (int i = 0; i < this.keys.length; i++) {
+      sb.append(this.keys[i].toString());
+      if (i < this.keys.length - 1) {
+        sb.append(delimiter);
+      }
+    }
+    return sb.toString();
+  }
+
+  public boolean equals(Object obj) {
+    if (obj == null) {
+      return false;
+    }
+    if (this == obj) {
+      return true;
+    }
+    if (!(obj instanceof GroupByCombinedKey)) {
+      return false;
+    }
+    return DEFAULT_COMPARATOR.compare(this, (GroupByCombinedKey) obj) == 0;
+  }
+
+  public int hashCode() {
+    if (this.keys == null) {
+      return super.hashCode();
+    }
+    int result = 11;
+    for (int i = 0; i < this.keys.length; i++) {
+      result = 37 * result + this.keys[i].hashCode();
+    }
+
+    return result;
+  }
+
+  public void readFields(DataInput in) throws IOException {
+    int count = in.readInt();
+    this.keys = new EvaluationResult[count];
+    for (int i = 0; i < count; i++) {
+      EvaluationResult key = new EvaluationResult();
+      key.readFields(in);
+      this.keys[i] = key;
+    }
+  }
+
+  public void write(DataOutput out) throws IOException {
+    out.writeInt(this.keys.length);
+    for (EvaluationResult key : this.keys)
+      key.write(out);
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByImplementation.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByImplementation.java
new file mode 100644
index 0000000..5fb0110
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByImplementation.java
@@ -0,0 +1,281 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.execengine.ExecutionUtil;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+import org.apache.hadoop.hbase.regionserver.InternalScanner;
+
+import com.google.common.collect.MinMaxPriorityQueue;
+
+public class GroupByImplementation extends BaseEndpointCoprocessor implements
+    GroupByProtocol {
+  protected static Log log = LogFactory.getLog(GroupByImplementation.class);
+
+  private int MAP_SIZE = 16;
+  private float LOAD_FACTOR = 0.75F;
+
+  public Map<GroupByCombinedKey, List<StatsValue>> getStats(Scan scan,
+      List<Expression> groupByKeyExpressions,
+      List<Expression> groupByStatsExpressions,
+      boolean isConstantGroupByKey) throws IOException {
+    RegionCoprocessorEnvironment env = (RegionCoprocessorEnvironment) getEnvironment();
+    Configuration conf = env.getConfiguration();
+    InternalScanner scanner = env.getRegion().getScanner(scan);
+
+    List<KeyValue> results = new ArrayList<KeyValue>();
+    Map<GroupByCombinedKey, List<StatsValue>> facets =
+        new HashMap<GroupByCombinedKey, List<StatsValue>>(
+            isConstantGroupByKey ? 1 : this.MAP_SIZE, this.LOAD_FACTOR);
+
+    int statsCount = groupByStatsExpressions.size();
+    EvaluationContext context = new EvaluationContext(conf);
+    context.setCurrentRow(results);
+    GroupByCombinedKey key = null;
+    List<StatsValue> facet = null;
+    try {
+      boolean hasMoreRows = false;
+      do {
+        hasMoreRows = scanner.next(results);
+
+        if (results.isEmpty()) {
+          continue;
+        }
+        key = (isConstantGroupByKey) && (key != null) ? key
+            : GroupByCombinedKey.getCombinedKey(
+              groupByKeyExpressions, context);
+
+        facet = (isConstantGroupByKey) && (facet != null) ? facet
+            : (List<StatsValue>) facets.get(key);
+
+        if (facet == null) {
+          facet = new ArrayList<StatsValue>();
+          for (int i = 0; i < statsCount; i++) {
+            facet.add(new StatsValue());
+          }
+          facets.put(key, facet);
+        }
+
+        Iterator<StatsValue> itValue = facet.iterator();
+        Iterator<Expression> itExpr = groupByStatsExpressions
+            .iterator();
+        while (itExpr.hasNext()) {
+          Expression statsExpr = itExpr.next();
+          StatsValue value = (StatsValue) itValue.next();
+          try {
+            value.accumulate(statsExpr.evaluate(context));
+          } catch (Throwable t) {
+            throw ((IOException) (IOException) new IOException(
+                "Exception occurred in evaluation")
+                .initCause(t));
+          }
+        }
+
+        results.clear();
+      } while (hasMoreRows);
+    } finally {
+      scanner.close();
+    }
+
+    return facets;
+  }
+
+  public List<EvaluationResult[]> getTopNByRow(Scan scan,
+      List<Expression> groupByStatsExpressions, int[] orderByIndices,
+      boolean[] ascending, int topCount) throws IOException {
+    RegionCoprocessorEnvironment env = (RegionCoprocessorEnvironment) getEnvironment();
+    Configuration conf = env.getConfiguration();
+    InternalScanner scanner = env.getRegion().getScanner(scan);
+
+    List<KeyValue> results = new ArrayList<KeyValue>();
+    List<EvaluationResult[]> ret = new ArrayList<EvaluationResult[]>();
+
+    MinMaxPriorityQueue<EvaluationResult[]> queue = ExecutionUtil
+        .createPriorityQueue(orderByIndices, ascending, topCount);
+
+    int statsCount = groupByStatsExpressions.size();
+    EvaluationContext context = new EvaluationContext(conf);
+    context.setCurrentRow(results);
+    try {
+      boolean hasMoreRows = false;
+      do {
+        hasMoreRows = scanner.next(results);
+
+        if (results.isEmpty()) {
+          continue;
+        }
+        EvaluationResult[] eval = new EvaluationResult[statsCount];
+        for (int i = 0; i < statsCount; i++) {
+          eval[i] = (groupByStatsExpressions.get(i))
+              .evaluate(context).asSerializableResult();
+        }
+        queue.add(eval);
+
+        results.clear();
+      } while (hasMoreRows);
+    } catch (Throwable t) {
+      throw ((t instanceof IOException) ? (IOException) t
+          : new IOException(t));
+    } finally {
+      scanner.close();
+    }
+
+    EvaluationResult[] elem = (EvaluationResult[]) queue.pollFirst();
+    while (elem != null) {
+      ret.add(elem);
+      elem = (EvaluationResult[]) queue.pollFirst();
+    }
+
+    return ret;
+  }
+
+  public GroupByIntermediateResult getTopNByRowGrouping(Scan scan,
+      List<Expression> groupByKeyExpressions,
+      List<Expression> groupByStatsExpressions,
+      List<Expression> selectExpressions, Expression havingExpression,
+      int[] orderByIndices, boolean[] ascending, int topCount)
+      throws IOException {
+    RegionCoprocessorEnvironment env = (RegionCoprocessorEnvironment) getEnvironment();
+    Configuration conf = env.getConfiguration();
+    InternalScanner scanner = env.getRegion().getScanner(scan);
+
+    List<KeyValue> results = new ArrayList<KeyValue>();
+    MinMaxPriorityQueue<EvaluationResult[]> queue = ExecutionUtil
+        .createPriorityQueue(orderByIndices, ascending, topCount);
+
+    GroupByIntermediateResult ret = new GroupByIntermediateResult(null,
+        new HashMap<GroupByCombinedKey, List<StatsValue>>(2));
+
+    int statsCount = groupByStatsExpressions.size();
+    int selectCount = selectExpressions.size();
+    EvaluationContext context = new EvaluationContext(conf);
+    context.setCurrentRow(results);
+    GroupByCombinedKey lastKey = null;
+    List<StatsValue> facet = null;
+    try {
+      boolean hasMoreRows = false;
+      do {
+        hasMoreRows = scanner.next(results);
+
+        if (results.isEmpty()) {
+          continue;
+        }
+        GroupByCombinedKey key = GroupByCombinedKey.getCombinedKey(
+          groupByKeyExpressions, context);
+        if ((lastKey != null) && (!key.equals(lastKey))) {
+          if (ret.getStatsMap().isEmpty()) {
+            ret.getStatsMap().put(lastKey, facet);
+          } else {
+            context.setAggregationValues(lastKey, facet);
+            Boolean b = null;
+            if (havingExpression != null) {
+              b = havingExpression.evaluate(context).asBoolean();
+            }
+            if ((havingExpression == null)
+                || ((b != null) && (b.booleanValue() == true))) {
+              EvaluationResult[] eval = new EvaluationResult[selectCount];
+              for (int i = 0; i < eval.length; i++) {
+                eval[i] = (selectExpressions.get(i)).evaluate(
+                  context).asSerializableResult();
+              }
+              queue.add(eval);
+            }
+          }
+          facet = null;
+        }
+
+        if (facet == null) {
+          facet = new ArrayList<StatsValue>();
+          for (int i = 0; i < statsCount; i++) {
+            facet.add(new StatsValue());
+          }
+        }
+        Iterator<StatsValue> itValue = facet.iterator();
+        Iterator<Expression> itExpr = groupByStatsExpressions
+            .iterator();
+        while (itExpr.hasNext()) {
+          Expression statsExpr = itExpr.next();
+          StatsValue value = (StatsValue) itValue.next();
+          value.accumulate(statsExpr.evaluate(context));
+        }
+
+        lastKey = key;
+        results.clear();
+      } while (hasMoreRows);
+
+      if (lastKey != null) {
+        ret.getStatsMap().put(lastKey, facet);
+      }
+      List<EvaluationResult[]> topList = new ArrayList<EvaluationResult[]>();
+      EvaluationResult[] elem = (EvaluationResult[]) queue.pollFirst();
+      while (elem != null) {
+        topList.add(elem);
+        elem = (EvaluationResult[]) queue.pollFirst();
+      }
+      ret.setTopList(topList);
+    } catch (Throwable t) {
+      throw ((t instanceof IOException) ? (IOException) t
+          : new IOException(t));
+    } finally {
+      scanner.close();
+    }
+
+    return ret;
+  }
+
+  public Set<GroupByCombinedKey> distinct(Scan scan,
+      List<Expression> distinctExpressions) throws IOException {
+    RegionCoprocessorEnvironment env = (RegionCoprocessorEnvironment) getEnvironment();
+    Configuration conf = env.getConfiguration();
+    InternalScanner scanner = env.getRegion().getScanner(scan);
+
+    List<KeyValue> results = new ArrayList<KeyValue>();
+    Set<GroupByCombinedKey> resultSet = new HashSet<GroupByCombinedKey>(
+        this.MAP_SIZE, this.LOAD_FACTOR);
+
+    EvaluationContext context = new EvaluationContext(conf);
+    context.setCurrentRow(results);
+    try {
+      boolean hasMoreRows = false;
+      do {
+        hasMoreRows = scanner.next(results);
+
+        if (results.isEmpty()) {
+          continue;
+        }
+        GroupByCombinedKey values = GroupByCombinedKey.getCombinedKey(
+          distinctExpressions, context);
+        resultSet.add(values);
+
+        results.clear();
+      } while (hasMoreRows);
+    } finally {
+      scanner.close();
+    }
+
+    return resultSet;
+  }
+
+  public void setMapSize(int mapSize) {
+    this.MAP_SIZE = mapSize;
+  }
+
+  public void setMapLoadFactor(float loadFactor) {
+    this.LOAD_FACTOR = loadFactor;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByIntermediateResult.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByIntermediateResult.java
new file mode 100644
index 0000000..2710474
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByIntermediateResult.java
@@ -0,0 +1,42 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.Serializable;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+
+public class GroupByIntermediateResult implements Serializable {
+  /**
+   * 
+   */
+  private static final long serialVersionUID = 1L;
+  private List<EvaluationResult[]> topList;
+  private Map<GroupByCombinedKey, List<StatsValue>> statsMap;
+
+  public GroupByIntermediateResult() {
+  }
+
+  public GroupByIntermediateResult(List<EvaluationResult[]> topList,
+      Map<GroupByCombinedKey, List<StatsValue>> statsMap) {
+    this.topList = topList;
+    this.statsMap = statsMap;
+  }
+
+  public List<EvaluationResult[]> getTopList() {
+    return this.topList;
+  }
+
+  public void setTopList(List<EvaluationResult[]> topList) {
+    this.topList = topList;
+  }
+
+  public Map<GroupByCombinedKey, List<StatsValue>> getStatsMap() {
+    return this.statsMap;
+  }
+
+  public void setStatsMap(Map<GroupByCombinedKey, List<StatsValue>> statsMap) {
+    this.statsMap = statsMap;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByProtocol.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByProtocol.java
new file mode 100644
index 0000000..3e4c460
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/GroupByProtocol.java
@@ -0,0 +1,37 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
+
+public abstract interface GroupByProtocol extends CoprocessorProtocol {
+  public static final long VERSION = 1L;
+
+  public abstract Map<GroupByCombinedKey, List<StatsValue>> getStats(
+      Scan paramScan, List<Expression> paramList1,
+      List<Expression> paramList2, boolean paramBoolean)
+      throws IOException;
+
+  public abstract List<EvaluationResult[]> getTopNByRow(Scan paramScan,
+      List<Expression> paramList, int[] paramArrayOfInt,
+      boolean[] paramArrayOfBoolean, int paramInt) throws IOException;
+
+  public abstract GroupByIntermediateResult getTopNByRowGrouping(
+      Scan paramScan, List<Expression> paramList1,
+      List<Expression> paramList2, List<Expression> paramList3,
+      Expression paramExpression, int[] paramArrayOfInt,
+      boolean[] paramArrayOfBoolean, int paramInt) throws IOException;
+
+  public abstract Set<GroupByCombinedKey> distinct(Scan paramScan,
+      List<Expression> paramList) throws IOException;
+
+  public abstract void setMapSize(int paramInt);
+
+  public abstract void setMapLoadFactor(float paramFloat);
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionFlushObserver.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionFlushObserver.java
new file mode 100644
index 0000000..a89a6ba
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/RegionFlushObserver.java
@@ -0,0 +1,9 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.IOException;
+
+public abstract interface RegionFlushObserver extends RegionObserver {
+	public abstract void onFlush(
+			ObserverContext<RegionCoprocessorEnvironment> paramObserverContext)
+			throws IOException;
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/SplittableRegionObserver.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/SplittableRegionObserver.java
new file mode 100644
index 0000000..41133b5
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/SplittableRegionObserver.java
@@ -0,0 +1,10 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.IOException;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+
+public abstract interface SplittableRegionObserver extends RegionObserver {
+	public abstract void onSplit(
+			ObserverContext<RegionCoprocessorEnvironment> paramObserverContext,
+			HRegion paramHRegion1, HRegion paramHRegion2) throws IOException;
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/WALRestoreFlushObserver.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/WALRestoreFlushObserver.java
new file mode 100644
index 0000000..de813d3
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/WALRestoreFlushObserver.java
@@ -0,0 +1,13 @@
+package org.apache.hadoop.hbase.coprocessor;
+
+import java.io.IOException;
+
+public abstract interface WALRestoreFlushObserver extends RegionObserver {
+	public abstract void preFlushWALRestore(
+			ObserverContext<RegionCoprocessorEnvironment> paramObserverContext)
+			throws IOException;
+
+	public abstract void postFlushWALRestore(
+			ObserverContext<RegionCoprocessorEnvironment> paramObserverContext)
+			throws IOException;
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExec.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExec.java
new file mode 100644
index 0000000..1410a9f
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExec.java
@@ -0,0 +1,96 @@
+package org.apache.hadoop.hbase.coprocessor.batch;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.List;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.ProgressableCancellable;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
+import org.apache.hadoop.hbase.ipc.Invocation;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Classes;
+
+public class BatchExec extends Invocation {
+  private byte[] regionName;
+  private Class<? extends CoprocessorProtocol> protocol;
+  private String protocolName;
+
+  public BatchExec() {
+  }
+
+  public BatchExec(Configuration configuration, byte[] regionName,
+      Class<? extends CoprocessorProtocol> protocol, Method method,
+      Object[] parameters) {
+    super(method, protocol, parameters);
+    this.conf = configuration;
+    this.regionName = regionName;
+    this.protocol = protocol;
+    this.protocolName = protocol.getName();
+  }
+
+  public String getProtocolName() {
+    return this.protocolName;
+  }
+
+  public Class<? extends CoprocessorProtocol> getProtocol() {
+    return this.protocol;
+  }
+
+  public byte[] getRegionName() {
+    return this.regionName;
+  }
+
+  public ProgressableCancellable[] getProgressableCancellableParameters() {
+    List<ProgressableCancellable> params = new ArrayList<ProgressableCancellable>();
+
+    for (Object parameter : this.parameters) {
+      if ((parameter instanceof ProgressableCancellable)) {
+        params.add((ProgressableCancellable) parameter);
+      }
+    }
+    return (ProgressableCancellable[]) params
+        .toArray(new ProgressableCancellable[params.size()]);
+  }
+
+  public void write(DataOutput out) throws IOException {
+    out.writeUTF(this.methodName);
+    out.writeInt(this.parameterClasses.length);
+    for (int i = 0; i < this.parameterClasses.length; i++) {
+      HbaseObjectWritable.writeObject(out, this.parameters[i],
+        this.parameters[i] != null ? this.parameters[i].getClass()
+            : this.parameterClasses[i], this.conf);
+
+      out.writeUTF(this.parameterClasses[i].getName());
+    }
+
+    Bytes.writeByteArray(out, this.regionName);
+    out.writeUTF(this.protocol.getName());
+  }
+
+  public void readFields(DataInput in) throws IOException {
+    this.methodName = in.readUTF();
+    this.parameters = new Object[in.readInt()];
+    this.parameterClasses = new Class[this.parameters.length];
+    HbaseObjectWritable objectWritable = new HbaseObjectWritable();
+    for (int i = 0; i < this.parameters.length; i++) {
+      this.parameters[i] = HbaseObjectWritable.readObject(in,
+        objectWritable, this.conf);
+
+      String parameterClassName = in.readUTF();
+      try {
+        this.parameterClasses[i] = Classes
+            .extendedForName(parameterClassName);
+      } catch (ClassNotFoundException e) {
+        throw new IOException("Couldn't find class: "
+            + parameterClassName);
+      }
+    }
+
+    this.regionName = Bytes.readByteArray(in);
+    this.protocolName = in.readUTF();
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecCall.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecCall.java
new file mode 100644
index 0000000..998b18a
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecCall.java
@@ -0,0 +1,24 @@
+package org.apache.hadoop.hbase.coprocessor.batch;
+
+import java.io.IOException;
+import java.util.List;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.io.Writable;
+
+public abstract interface BatchExecCall<T, R> {
+  public abstract R call(T paramT) throws IOException;
+
+  public static abstract interface ClientCallback<R> {
+    public abstract void update(ServerName paramServerName,
+        List<byte[]> paramList, R paramR) throws IOException;
+  }
+
+  public static abstract interface ServerCallback<R> extends Writable {
+    public abstract void update(byte[] paramArrayOfByte, R paramR)
+        throws IOException;
+
+    public abstract void init();
+
+    public abstract R getResult();
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecClient.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecClient.java
new file mode 100644
index 0000000..7efaac8
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecClient.java
@@ -0,0 +1,169 @@
+package org.apache.hadoop.hbase.coprocessor.batch;
+
+import java.io.IOException;
+import java.lang.reflect.Proxy;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Future;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HConnectionManager;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Pair;
+
+public class BatchExecClient {
+  private static final Log LOG = LogFactory.getLog(BatchExecClient.class);
+
+  public static <T extends CoprocessorProtocol, R> void coprocessorExec(
+      HTable table, Class<T> protocol, BatchExecCall<T, R> call,
+      BatchExecCall.ServerCallback<R> serverCallback,
+      BatchExecCall.ClientCallback<R> callback) throws IOException,
+      Throwable {
+    List<Pair<Pair<byte[], byte[]>, BatchExecCall<T, R>>> callsByKeyRange =
+        new ArrayList<Pair<Pair<byte[], byte[]>, BatchExecCall<T, R>>>();
+
+    callsByKeyRange
+        .add(new Pair<Pair<byte[], byte[]>, BatchExecCall<T, R>>(
+            new Pair<byte[], byte[]>(HConstants.EMPTY_START_ROW,
+                HConstants.EMPTY_END_ROW), call));
+
+    coprocessorExec(table, protocol, callsByKeyRange, serverCallback,
+      callback);
+  }
+
+  public static <T extends CoprocessorProtocol, R> void coprocessorExec(
+      HTable table,
+      Class<T> protocol,
+      List<Pair<Pair<byte[], byte[]>, BatchExecCall<T, R>>> callsByKeyRange,
+      BatchExecCall.ServerCallback<R> serverCallback,
+      BatchExecCall.ClientCallback<R> callback) throws IOException,
+      Throwable {
+    Map<ServerName, List<Pair<byte[], BatchExecCall<T, R>>>> callsByServer =
+        new HashMap<ServerName, List<Pair<byte[], BatchExecCall<T, R>>>>();
+
+    BatchExecCall<T, R> call;
+    byte[] start;
+    byte[] end;
+
+    NavigableMap<HRegionInfo, ServerName> regions = table
+        .getRegionLocations();
+    for (Pair<Pair<byte[], byte[]>, BatchExecCall<T, R>> callPair : callsByKeyRange) {
+      call = (BatchExecCall<T, R>) callPair.getSecond();
+      start = (byte[]) ((Pair<byte[], byte[]>) callPair.getFirst())
+          .getFirst();
+      end = (byte[]) ((Pair<byte[], byte[]>) callPair.getFirst())
+          .getSecond();
+      for (Map.Entry<HRegionInfo, ServerName> entry : regions.entrySet()) {
+        HRegionInfo region = (HRegionInfo) entry.getKey();
+        boolean include = false;
+        byte[] startKey = region.getStartKey();
+        byte[] endKey = region.getEndKey();
+        if (Bytes.compareTo(start, startKey) >= 0) {
+          if ((Bytes.equals(endKey, HConstants.EMPTY_END_ROW))
+              || (Bytes.compareTo(start, endKey) < 0)) {
+            include = true;
+          }
+        } else {
+          if ((!Bytes.equals(end, HConstants.EMPTY_END_ROW))
+              && (Bytes.compareTo(startKey, end) > 0)) break;
+          include = true;
+        }
+
+        if (include) {
+          ServerName server = (ServerName) entry.getValue();
+          List<Pair<byte[], BatchExecCall<T, R>>> callList =
+              (List<Pair<byte[], BatchExecCall<T, R>>>) callsByServer
+                  .get(server);
+          if (callList == null) {
+            callList = new ArrayList<Pair<byte[], BatchExecCall<T, R>>>();
+            callsByServer.put(server, callList);
+          }
+          callList.add(new Pair<byte[], BatchExecCall<T, R>>(region
+              .getRegionName(), call));
+        }
+      }
+    }
+
+    processBatchExecs(
+      HConnectionManager.getConnection(table.getConfiguration()),
+      table.getPool(), protocol, callsByServer, serverCallback,
+      callback);
+  }
+
+  protected static <T extends CoprocessorProtocol, R> void processBatchExecs(
+      HConnection connection,
+      ExecutorService pool,
+      Class<T> protocol,
+      Map<ServerName, List<Pair<byte[], BatchExecCall<T, R>>>> callsByServer,
+      BatchExecCall.ServerCallback<R> serverCallback,
+      final BatchExecCall.ClientCallback<R> callback) throws IOException,
+      Throwable {
+    Map<String, Future<R>> futures = new TreeMap<String, Future<R>>();
+
+    for (Map.Entry<ServerName, List<Pair<byte[], BatchExecCall<T, R>>>> entry : callsByServer
+        .entrySet()) {
+      Configuration conf = connection.getConfiguration();
+      final ServerName serverName = (ServerName) entry.getKey();
+      final BatchExecRPCInvoker<R> invoker = new BatchExecRPCInvoker<R>(
+          conf, connection, serverName, protocol, serverCallback);
+
+      @SuppressWarnings("unchecked")
+      T instance = (T) Proxy.newProxyInstance(conf.getClassLoader(),
+        new Class[] { protocol }, invoker);
+
+      for (Pair<byte[], BatchExecCall<T, R>> callPair : (List<Pair<byte[], BatchExecCall<T, R>>>) entry
+          .getValue()) {
+        byte[] regionName = (byte[]) callPair.getFirst();
+        BatchExecCall<T, R> call = (BatchExecCall<T, R>) callPair
+            .getSecond();
+        invoker.setRegionName(regionName);
+        call.call(instance);
+      }
+      Future<R> future = pool.submit(new Callable<R>() {
+        public R call() throws Exception {
+          BatchExecResult result = invoker.realInvoke();
+          if (result == null) {
+            return null;
+          }
+          @SuppressWarnings("unchecked")
+          R value = (R) result.getValue();
+          if (callback != null) {
+            callback.update(serverName, result.getRegionNames(),
+              value);
+          }
+          return value;
+        }
+      });
+      futures.put(serverName.getHostAndPort(), future);
+    }
+    for (Map.Entry<String, Future<R>> e : futures.entrySet())
+      try {
+        ((Future<R>) e.getValue()).get();
+      } catch (ExecutionException ee) {
+        LOG.warn(
+          "Error executing from Region Server "
+              + (String) e.getKey(), ee);
+        throw ee.getCause();
+      } catch (InterruptedException ie) {
+        Thread.currentThread().interrupt();
+        throw new IOException(
+            "Interrupted executing from Region Server "
+                + (String) e.getKey(), ie);
+      }
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecRPCInvoker.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecRPCInvoker.java
new file mode 100644
index 0000000..1ebb7c1
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecRPCInvoker.java
@@ -0,0 +1,60 @@
+package org.apache.hadoop.hbase.coprocessor.batch;
+
+import java.lang.reflect.InvocationHandler;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.UUID;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
+
+public class BatchExecRPCInvoker<R> implements InvocationHandler {
+  private Configuration conf;
+  private final HConnection connection;
+  private final ServerName serverName;
+  private Class<? extends CoprocessorProtocol> protocol;
+  private BatchExecCall.ServerCallback<R> serverCallback;
+  private List<BatchExec> execList;
+  private byte[] regionName;
+
+  public BatchExecRPCInvoker(Configuration conf, HConnection connection,
+      ServerName serverName,
+      Class<? extends CoprocessorProtocol> protocol,
+      BatchExecCall.ServerCallback<R> serverCallback) {
+    this.conf = conf;
+    this.connection = connection;
+    this.serverName = serverName;
+    this.protocol = protocol;
+    this.serverCallback = serverCallback;
+    this.execList = new ArrayList<BatchExec>();
+  }
+
+  public void setRegionName(byte[] regionName) {
+    this.regionName = regionName;
+  }
+
+  public Object invoke(Object instance, Method method, Object[] args)
+      throws Throwable {
+    if (this.regionName != null) {
+      this.execList.add(new BatchExec(this.conf, this.regionName,
+          this.protocol, method, args));
+    }
+
+    return null;
+  }
+
+  public BatchExecResult realInvoke() throws Exception {
+    if (!this.execList.isEmpty()) {
+      String id = UUID.randomUUID().toString();
+      return this.connection.getHRegionConnection(
+        this.serverName.getHostname(), this.serverName.getPort())
+          .execBatchCoprocessor(id, this.execList,
+            this.serverCallback);
+    }
+
+    return null;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecResult.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecResult.java
new file mode 100644
index 0000000..75fe9ff
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/batch/BatchExecResult.java
@@ -0,0 +1,51 @@
+package org.apache.hadoop.hbase.coprocessor.batch;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.Writable;
+
+public class BatchExecResult implements Writable {
+  private List<byte[]> regionNames;
+  private Object value;
+
+  public BatchExecResult() {
+  }
+
+  public BatchExecResult(List<byte[]> regions, Object value) {
+    this.regionNames = regions;
+    this.value = value;
+  }
+
+  public List<byte[]> getRegionNames() {
+    return this.regionNames;
+  }
+
+  public Object getValue() {
+    return this.value;
+  }
+
+  public void write(DataOutput out) throws IOException {
+    int count = this.regionNames.size();
+    out.writeInt(count);
+    for (int i = 0; i < count; i++) {
+      Bytes.writeByteArray(out, (byte[]) this.regionNames.get(i));
+    }
+    HbaseObjectWritable.writeObject(out, this.value,
+      this.value != null ? this.value.getClass() : Writable.class,
+      null);
+  }
+
+  public void readFields(DataInput in) throws IOException {
+    int count = in.readInt();
+    this.regionNames = new ArrayList<byte[]>();
+    for (int i = 0; i < count; i++) {
+      this.regionNames.add(Bytes.readByteArray(in));
+    }
+    this.value = HbaseObjectWritable.readObject(in, null);
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/execengine/ExecutionClient.java b/src/main/java/org/apache/hadoop/hbase/execengine/ExecutionClient.java
new file mode 100644
index 0000000..4e13bd9
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/execengine/ExecutionClient.java
@@ -0,0 +1,809 @@
+package org.apache.hadoop.hbase.execengine;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.SortedSet;
+import java.util.TreeMap;
+import java.util.TreeSet;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.coprocessor.GroupByCombinedKey;
+import org.apache.hadoop.hbase.coprocessor.GroupByIntermediateResult;
+import org.apache.hadoop.hbase.coprocessor.GroupByProtocol;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecCall;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecCall.ClientCallback;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecClient;
+import org.apache.hadoop.hbase.expression.BytesPartExpression;
+import org.apache.hadoop.hbase.expression.ColumnValueExpression;
+import org.apache.hadoop.hbase.expression.ConstantExpression;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.ExpressionException;
+import org.apache.hadoop.hbase.expression.GroupByAggregationExpression;
+import org.apache.hadoop.hbase.expression.GroupByKeyExpression;
+import org.apache.hadoop.hbase.expression.RowExpression;
+import org.apache.hadoop.hbase.expression.SubSequenceExpression;
+import org.apache.hadoop.hbase.expression.SubstringExpression;
+import org.apache.hadoop.hbase.expression.ToBytesExpression;
+import org.apache.hadoop.hbase.expression.ToStringExpression;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.expression.visitor.ColumnVisitor;
+import org.apache.hadoop.hbase.expression.visitor.ExpressionTraversal;
+import org.apache.hadoop.hbase.expression.visitor.ExpressionVisitor;
+import org.apache.hadoop.hbase.expression.visitor.IsConstantVisitor;
+import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Pair;
+
+import com.google.common.collect.MinMaxPriorityQueue;
+
+public class ExecutionClient {
+  Configuration conf;
+  private int MAP_SIZE = 16;
+  private float LOAD_FACTOR = 0.75F;
+
+  protected static Log log = LogFactory.getLog(ExecutionClient.class);
+
+  public ExecutionClient(Configuration conf) {
+    this.conf = conf;
+  }
+
+  public List<EvaluationResult[]> groupBy(byte[] tableName, Scan[] scans,
+      List<Expression> groupByKeyExpressions,
+      List<Expression> selectExpressions, Expression havingExpression)
+      throws Throwable {
+    return groupBy(tableName, scans, groupByKeyExpressions,
+      selectExpressions, havingExpression, null, null);
+  }
+
+  public List<EvaluationResult[]> groupBy(byte[] tableName, Scan[] scans,
+      List<Expression> groupByKeyExpressions,
+      List<Expression> selectExpressions, Expression havingExpression,
+      int[] orderByIndices, boolean[] ascending) throws Throwable {
+    List<Expression> groupByStatsExpressions = processSelectExpressions(
+      groupByKeyExpressions, selectExpressions, havingExpression);
+
+    Comparator<GroupByCombinedKey> comparator = processSortSpecs(selectExpressions,
+      orderByIndices, ascending);
+
+    List<EvaluationResult[]> ret = new ArrayList<EvaluationResult[]>();
+    Map<GroupByCombinedKey, List<StatsValue>> groupByMap = getStatsInternal(
+      tableName, scans, groupByKeyExpressions,
+      groupByStatsExpressions, comparator != null, comparator);
+
+    EvaluationContext context = new EvaluationContext(this.conf);
+    int count = selectExpressions.size();
+
+    for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : groupByMap
+        .entrySet()) {
+      context.setAggregationValues((GroupByCombinedKey) entry.getKey(),
+        (List<StatsValue>) entry.getValue());
+      Boolean b = null;
+      if (havingExpression != null) {
+        b = havingExpression.evaluate(context).asBoolean();
+      }
+      if ((havingExpression == null)
+          || ((b != null) && (b.booleanValue() == true))) {
+        EvaluationResult[] resultRow = new EvaluationResult[count];
+        for (int i = 0; i < count; i++) {
+          resultRow[i] = ((Expression) selectExpressions.get(i))
+              .evaluate(context);
+        }
+        ret.add(resultRow);
+      }
+    }
+
+    if (comparator == null) {
+      log.debug("Perform additional sorting on resultsets... ");
+      Collections.sort(ret, createComparator(orderByIndices, ascending));
+    }
+
+    return ret;
+  }
+
+  public List<EvaluationResult[]> getTopNByRow(byte[] tableName,
+      final Scan[] scans, final List<Expression> selectExpressions,
+      final int[] orderByIndices, final boolean[] ascending,
+      final int topCount) throws Throwable {
+    final MinMaxPriorityQueue<EvaluationResult[]> queue = MinMaxPriorityQueue
+        .orderedBy(createComparator(orderByIndices, ascending))
+        .maximumSize(topCount).create();
+
+    validateAndDecorateParameters(scans, new ArrayList<Expression>(), selectExpressions);
+
+    ClientCallback<List<EvaluationResult[]>> topNCB =
+        new BatchExecCall.ClientCallback<List<EvaluationResult[]>>() {
+          public synchronized void update(ServerName server,
+              List<byte[]> regions, List<EvaluationResult[]> resultList)
+              throws IOException {
+            for (Iterator<EvaluationResult[]> iter = resultList.iterator(); iter
+                .hasNext();)
+              queue.add(iter.next());
+          }
+        };
+    HTable table = new HTable(this.conf, tableName);
+
+    List<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, List<EvaluationResult[]>>>> calls =
+        new ArrayList<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, List<EvaluationResult[]>>>>();
+
+    for (final Scan scan : scans) {
+      calls
+          .add(new Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, List<EvaluationResult[]>>>(
+              new Pair<byte[], byte[]>(scan.getStartRow(), scan.getStopRow()),
+              new BatchExecCall<GroupByProtocol, List<EvaluationResult[]>>() {
+                public List<EvaluationResult[]> call(
+                    GroupByProtocol instance) throws IOException {
+                  return instance.getTopNByRow(scan,
+                    selectExpressions, orderByIndices,
+                    ascending, topCount);
+                }
+              }));
+    }
+    try {
+      BatchExecClient.coprocessorExec(table, GroupByProtocol.class,
+        calls, new ExecutionUtil.TopNCallback(orderByIndices,
+            ascending, topCount), topNCB);
+    } finally {
+      table.close();
+    }
+
+    List<EvaluationResult[]> ret = new ArrayList<EvaluationResult[]>();
+    EvaluationResult[] elem = (EvaluationResult[]) queue.pollFirst();
+    while (elem != null) {
+      ret.add(elem);
+      elem = (EvaluationResult[]) queue.pollFirst();
+    }
+    return ret;
+  }
+
+  public List<EvaluationResult[]> getTopN(byte[] tableName, Scan[] scans,
+      List<Expression> groupByKeyExpressions,
+      List<Expression> selectExpressions, Expression havingExpression,
+      int[] orderByIndices, boolean[] ascending, int topCount)
+      throws Throwable {
+    boolean isRowGrouping = isRowGrouping(groupByKeyExpressions);
+    log.debug("Is row grouping? " + isRowGrouping);
+    List<EvaluationResult[]> ret;
+    if (isRowGrouping) {
+      List<Expression> groupByStatsExpressions = processSelectExpressions(
+        groupByKeyExpressions, selectExpressions, havingExpression);
+
+      Comparator<GroupByCombinedKey> comparator = processSortSpecs(
+        selectExpressions, orderByIndices, ascending);
+
+      boolean isSortedMap = comparator != null;
+      MinMaxPriorityQueue<EvaluationResult[]> queue = MinMaxPriorityQueue
+          .orderedBy(createComparator(orderByIndices, ascending))
+          .maximumSize(topCount).create();
+
+      Map<GroupByCombinedKey, List<StatsValue>> map = getTopNInternal(
+        tableName, scans, groupByKeyExpressions,
+        groupByStatsExpressions, selectExpressions,
+        havingExpression, orderByIndices, ascending, topCount,
+        queue, isSortedMap, comparator);
+
+      EvaluationContext context = new EvaluationContext(this.conf);
+      int count = selectExpressions.size();
+      int counter = 0;
+      for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : map
+          .entrySet()) {
+        if (isSortedMap) {
+          counter++;
+          if (counter > topCount) break;
+        }
+        context.setAggregationValues(
+          (GroupByCombinedKey) entry.getKey(),
+          (List<StatsValue>) entry.getValue());
+        Boolean b = null;
+        if (havingExpression != null) {
+          b = havingExpression.evaluate(context).asBoolean();
+        }
+        if ((havingExpression == null)
+            || ((b != null) && (b.booleanValue() == true))) {
+          EvaluationResult[] resultRow = new EvaluationResult[count];
+          for (int i = 0; i < count; i++) {
+            resultRow[i] = ((Expression) selectExpressions.get(i))
+                .evaluate(context);
+          }
+          queue.add(resultRow);
+        }
+      }
+
+      ret = new ArrayList<EvaluationResult[]>();
+      EvaluationResult[] elem = (EvaluationResult[]) queue.pollFirst();
+      while (elem != null) {
+        ret.add(elem);
+        elem = (EvaluationResult[]) queue.pollFirst();
+      }
+    } else {
+      List<EvaluationResult[]> groupByResults = groupBy(tableName, scans,
+        groupByKeyExpressions, selectExpressions, havingExpression,
+        orderByIndices, ascending);
+
+      ret = groupByResults.size() <= topCount ? groupByResults
+          : groupByResults.subList(0, topCount);
+    }
+
+    return ret;
+  }
+
+  public List<EvaluationResult[]> distinct(byte[] tableName, Scan[] scans,
+      final List<Expression> distinctExpressions,
+      GroupByAggregationExpression.AggregationType type) throws Throwable {
+    if ((type != null)
+        && (type != GroupByAggregationExpression.AggregationType.COUNT)
+        && (distinctExpressions.size() > 1)) {
+      throw new IOException("Aggregation '" + type.toString()
+          + "' is not allowed on non-numeric types");
+    }
+    validateAndDecorateParameters(scans, distinctExpressions, null);
+    final SortedSet<GroupByCombinedKey> finalSet = new TreeSet<GroupByCombinedKey>(
+        GroupByCombinedKey.DEFAULT_COMPARATOR);
+
+    class DistinctCallback implements
+        BatchExecCall.ClientCallback<Set<GroupByCombinedKey>> {
+      public synchronized void update(ServerName server,
+          List<byte[]> region, Set<GroupByCombinedKey> resultSet)
+          throws IOException {
+        for (GroupByCombinedKey value : resultSet)
+          finalSet.add(value);
+      }
+    }
+    ;
+
+    DistinctCallback distinctCB = new DistinctCallback();
+    HTable table = new HTable(this.conf, tableName);
+
+    List<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, Set<GroupByCombinedKey>>>> calls =
+        new ArrayList<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, Set<GroupByCombinedKey>>>>();
+
+    for (final Scan scan : scans)
+      calls
+          .add(new Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, Set<GroupByCombinedKey>>>(
+              new Pair<byte[], byte[]>(scan.getStartRow(), scan.getStopRow()),
+              new BatchExecCall<GroupByProtocol, Set<GroupByCombinedKey>>() {
+                public Set<GroupByCombinedKey> call(
+                    GroupByProtocol instance) throws IOException {
+                  return instance.distinct(scan, distinctExpressions);
+                }
+              }));
+    try {
+      BatchExecClient.coprocessorExec(table, GroupByProtocol.class,
+        calls, new ExecutionUtil.DistinctCallback(this.MAP_SIZE,
+            this.LOAD_FACTOR), distinctCB);
+    } finally {
+      table.close();
+    }
+
+    List<EvaluationResult[]> res = new ArrayList<EvaluationResult[]>();
+    if (type == null) {
+      for (GroupByCombinedKey value : finalSet)
+        res.add(value.getKeys());
+    } else {
+      EvaluationResult eval = null;
+      switch (type.ordinal()) {
+      case 1:
+        eval = new EvaluationResult(Integer.valueOf(finalSet.size()),
+            EvaluationResult.ResultType.INTEGER);
+        break;
+      case 2:
+        eval = finalSet.isEmpty() ? new EvaluationResult()
+            : ((GroupByCombinedKey) finalSet.first()).getKeys()[0];
+        break;
+      case 3:
+        eval = finalSet.isEmpty() ? new EvaluationResult()
+            : ((GroupByCombinedKey) finalSet.last()).getKeys()[0];
+        break;
+      case 4:
+        if (!finalSet.isEmpty()) {
+          eval = new EvaluationResult(Integer.valueOf(0),
+              EvaluationResult.ResultType.LONG);
+          for (GroupByCombinedKey value : finalSet) {
+            EvaluationResult val = value.getKeys()[0];
+            if (!val.isNullResult()) eval = EvaluationResult.numberAdd(eval, val);
+          }
+        } else {
+          eval = new EvaluationResult();
+        }
+        break;
+      case 5:
+        int count = finalSet.size();
+        if (count > 0) {
+          eval = new EvaluationResult(Integer.valueOf(0),
+              EvaluationResult.ResultType.LONG);
+          for (GroupByCombinedKey value : finalSet) {
+            EvaluationResult val = value.getKeys()[0];
+            if (!val.isNullResult()) eval = EvaluationResult.numberAdd(eval, val);
+          }
+          eval = EvaluationResult.numberDivide(eval,
+            new EvaluationResult(Integer.valueOf(count),
+                EvaluationResult.ResultType.INTEGER));
+        } else {
+          eval = new EvaluationResult();
+        }
+        break;
+      case 6:
+        count = finalSet.size();
+        if (count > 0) {
+          double sum = 0.0D;
+          double sumOfSquares = 0.0D;
+          for (GroupByCombinedKey value : finalSet) {
+            EvaluationResult val = value.getKeys()[0];
+            if (!val.isNullResult()) {
+              double d = val.asDouble().doubleValue();
+              sum += d;
+              sumOfSquares += d * d;
+            }
+          }
+          double avg = sum / count;
+          double avgOfSumOfSquares = sumOfSquares / count;
+          eval = new EvaluationResult(Double.valueOf(Math.pow(
+            avgOfSumOfSquares - avg * avg, 0.5D)),
+              EvaluationResult.ResultType.DOUBLE);
+        } else {
+          eval = new EvaluationResult();
+        }
+        break;
+      default:
+        throw new IOException("Unsupported aggregation type " + type);
+      }
+
+      res.add(new EvaluationResult[] { eval });
+    }
+
+    return res;
+  }
+
+  protected boolean isRowGrouping(List<Expression> keyExpressions) {
+    if (keyExpressions.size() != 1) {
+      return false;
+    }
+    Expression keyExpr = (Expression) keyExpressions.get(0);
+    if ((keyExpr instanceof SubSequenceExpression)) {
+      return ((((SubSequenceExpression) keyExpr).getSource() instanceof RowExpression))
+          && ((((SubSequenceExpression) keyExpr).getStart() instanceof ConstantExpression))
+          && (((ConstantExpression) ((SubSequenceExpression) keyExpr)
+              .getStart()).getConstant().equals(Integer
+              .valueOf(0)));
+    }
+
+    if ((keyExpr instanceof ToBytesExpression)) {
+      Expression firstLevelExpr = ((ToBytesExpression) keyExpr)
+          .getSubExpression();
+      if ((firstLevelExpr instanceof SubstringExpression)) {
+        return ((((SubstringExpression) firstLevelExpr).getSource() instanceof ToStringExpression))
+            && ((((ToStringExpression) ((SubstringExpression) firstLevelExpr)
+                .getSource()).getSubExpression() instanceof RowExpression))
+            && ((((SubstringExpression) firstLevelExpr).getStart() instanceof ConstantExpression))
+            && (((ConstantExpression) ((SubstringExpression) firstLevelExpr)
+                .getStart()).getConstant().equals(Integer
+                .valueOf(0)));
+      }
+
+      if ((firstLevelExpr instanceof BytesPartExpression)) {
+        return ((((BytesPartExpression) firstLevelExpr).getSource() instanceof RowExpression))
+            && ((((BytesPartExpression) firstLevelExpr).getIndex() instanceof ConstantExpression))
+            && (((ConstantExpression) ((BytesPartExpression) firstLevelExpr)
+                .getIndex()).getConstant().equals(Integer
+                .valueOf(0)));
+      }
+
+      return false;
+    }
+
+    return (keyExpr instanceof RowExpression);
+  }
+
+  protected Map<GroupByCombinedKey, List<StatsValue>> getTopNInternal(
+      byte[] tableName, Scan[] scans,
+      final List<Expression> groupByKeyExpressions,
+      final List<Expression> groupByStatsExpressions,
+      final List<Expression> selectExpressions,
+      final Expression havingExpression, final int[] orderByIndices,
+      final boolean[] ascending, final int topCount,
+      final MinMaxPriorityQueue<EvaluationResult[]> queue,
+      boolean requireSortedMap, Comparator<GroupByCombinedKey> comparator)
+      throws Throwable {
+    final Map<GroupByCombinedKey, List<StatsValue>> map =
+        requireSortedMap ? new TreeMap<GroupByCombinedKey, List<StatsValue>>(comparator)
+            : new HashMap<GroupByCombinedKey, List<StatsValue>>();
+
+    validateAndDecorateParameters(scans, groupByKeyExpressions,
+      groupByStatsExpressions);
+
+    class TopNCallback implements
+        BatchExecCall.ClientCallback<GroupByIntermediateResult> {
+      public synchronized void update(ServerName server,
+          List<byte[]> region, GroupByIntermediateResult result)
+          throws IOException {
+        Iterator<EvaluationResult[]> iter = result.getTopList()
+            .iterator();
+        while (iter.hasNext()) {
+          queue.add(iter.next());
+        }
+        for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : result.getStatsMap()
+            .entrySet()) {
+          List<StatsValue> finalStats = map.get(entry.getKey());
+          Iterator<StatsValue> itFinal;
+          Iterator<StatsValue> itTemp;
+          if (finalStats != null) {
+            itFinal = finalStats.iterator();
+            for (itTemp = entry.getValue().iterator(); itFinal
+                .hasNext();)
+              try {
+                ((StatsValue) itFinal.next())
+                    .accumulate((StatsValue) itTemp.next());
+              } catch (TypeConversionException e) {
+                throw new IOException(e);
+              }
+          } else {
+            map.put(entry.getKey(), entry.getValue());
+          }
+        }
+      }
+    }
+    ;
+
+    TopNCallback topNCB = new TopNCallback();
+    HTable table = new HTable(this.conf, tableName);
+
+    List<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, GroupByIntermediateResult>>> calls =
+        new ArrayList<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, GroupByIntermediateResult>>>();
+
+    for (final Scan scan : scans) {
+      calls
+          .add(new Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, GroupByIntermediateResult>>(
+              new Pair<byte[], byte[]>(scan.getStartRow(), scan.getStopRow()),
+              new BatchExecCall<GroupByProtocol, GroupByIntermediateResult>() {
+                public GroupByIntermediateResult call(
+                    GroupByProtocol instance) throws IOException {
+                  return instance.getTopNByRowGrouping(scan,
+                    groupByKeyExpressions,
+                    groupByStatsExpressions, selectExpressions,
+                    havingExpression, orderByIndices,
+                    ascending, topCount);
+                }
+              }));
+    }
+    try {
+      BatchExecClient.coprocessorExec(table, GroupByProtocol.class,
+        calls, new ExecutionUtil.TopNGroupingCallback(
+            orderByIndices, ascending, topCount, this.MAP_SIZE,
+            this.LOAD_FACTOR), topNCB);
+    } finally {
+      table.close();
+    }
+
+    return map;
+  }
+
+  protected Map<GroupByCombinedKey, List<StatsValue>> getStatsInternal(
+      byte[] tableName, Scan[] scans,
+      final List<Expression> groupByKeyExpressions,
+      final List<Expression> groupByStatsExpressions,
+      final boolean requireSortedMap,
+      final Comparator<GroupByCombinedKey> comparator) throws Throwable {
+    final boolean isConstantGroupByKey = validateAndDecorateParameters(
+      scans, groupByKeyExpressions, groupByStatsExpressions);
+
+    log.debug("Is constant group-by key? " + isConstantGroupByKey);
+
+    class RowNumCallback
+        implements
+        BatchExecCall.ClientCallback<Map<GroupByCombinedKey, List<StatsValue>>> {
+      private Map<GroupByCombinedKey, List<StatsValue>> finalMap =
+          requireSortedMap ? new TreeMap<GroupByCombinedKey, List<StatsValue>>(
+              comparator)
+              : new HashMap<GroupByCombinedKey, List<StatsValue>>();
+
+      public Map<GroupByCombinedKey, List<StatsValue>> getFinalMap() {
+        return this.finalMap;
+      }
+
+      public synchronized void update(ServerName server,
+          List<byte[]> region,
+          Map<GroupByCombinedKey, List<StatsValue>> resultMap)
+          throws IOException {
+        for (GroupByCombinedKey facet : resultMap.keySet()) {
+          List<StatsValue> finalStats = this.finalMap.get(facet);
+          Iterator<StatsValue> itFinal;
+          Iterator<StatsValue> itTemp;
+          if (finalStats != null) {
+            itFinal = finalStats.iterator();
+            for (itTemp = resultMap.get(facet).iterator(); itFinal
+                .hasNext();)
+              try {
+                ((StatsValue) itFinal.next())
+                    .accumulate((StatsValue) itTemp.next());
+              } catch (TypeConversionException e) {
+                throw new IOException(e);
+              }
+          } else {
+            this.finalMap.put(facet, resultMap.get(facet));
+          }
+        }
+      }
+    }
+    ;
+
+    RowNumCallback rowNumCB = new RowNumCallback();
+
+    HTable table = new HTable(this.conf, tableName);
+
+    List<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>>> calls =
+        new ArrayList<Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>>>();
+
+    for (final Scan scan : scans) {
+      calls
+          .add(new Pair<Pair<byte[], byte[]>, BatchExecCall<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>>(
+              new Pair<byte[], byte[]>(scan.getStartRow(), scan.getStopRow()),
+              new BatchExecCall<GroupByProtocol, Map<GroupByCombinedKey, List<StatsValue>>>() {
+                public Map<GroupByCombinedKey, List<StatsValue>> call(
+                    GroupByProtocol instance) throws IOException {
+                  return instance.getStats(scan,
+                    groupByKeyExpressions,
+                    groupByStatsExpressions,
+                    isConstantGroupByKey);
+                }
+              }));
+    }
+    try {
+      BatchExecClient.coprocessorExec(table, GroupByProtocol.class,
+        calls, new ExecutionUtil.GroupByCallback(this.MAP_SIZE,
+            this.LOAD_FACTOR), rowNumCB);
+    } finally {
+      table.close();
+    }
+
+    return rowNumCB.getFinalMap();
+  }
+
+  private List<Expression> processSelectExpressions(
+      final List<Expression> groupByKeyExpressions,
+      final List<Expression> selectExpressions,
+      Expression havingExpression) throws ExpressionException {
+    final List<Expression> groupByStatsExpressions = new ArrayList<Expression>();
+    ExpressionVisitor visitor = new ExpressionVisitor() {
+      public ExpressionVisitor.ReturnCode processExpression(
+          Expression expression) throws ExpressionException {
+        if ((expression instanceof RowExpression)) {
+          throw new ExpressionException(
+              "The group-by select expression cannot contain RowExpression");
+        }
+        if ((expression instanceof ColumnValueExpression)) {
+          throw new ExpressionException(
+              "The group-by select expression cannot contain ColumnValueExpression");
+        }
+        if ((expression instanceof GroupByKeyExpression)) {
+          GroupByKeyExpression keyExpr = (GroupByKeyExpression) expression;
+          Expression refExpr = keyExpr.getReferenceExpression();
+          if (refExpr == null) {
+            throw new ExpressionException(
+                "The group-by key expression cannot contain null expressions");
+          }
+          for (int i = 0; i < groupByKeyExpressions.size(); i++) {
+            if (refExpr.equals(groupByKeyExpressions.get(i))) {
+              keyExpr.setKeyIndex(i);
+              break;
+            }
+          }
+          if (keyExpr.getKeyIndex() == GroupByKeyExpression.INVALID_KEY_ID) {
+            throw new ExpressionException(
+                "Could not find group-by key expression: "
+                    + refExpr);
+          }
+          return ExpressionVisitor.ReturnCode.SKIP_SUBTREE;
+        }
+        if ((expression instanceof GroupByAggregationExpression)) {
+          GroupByAggregationExpression aggrExpr = (GroupByAggregationExpression) expression;
+          Expression statsExpr = aggrExpr.getSubExpression();
+          if (statsExpr == null) {
+            throw new ExpressionException(
+                "The group-by aggregation expression cannot contain null expressions");
+          }
+          if ((aggrExpr.getType() != GroupByAggregationExpression.AggregationType.COUNT)
+              && (!EvaluationResult.isNumber(statsExpr
+                  .getReturnType()))) {
+            throw new ExpressionException(
+                "Invalid return type for group-by stats expression: "
+                    + statsExpr.getReturnType());
+          }
+
+          for (int i = 0; i < groupByStatsExpressions.size(); i++) {
+            if (statsExpr.equals(groupByStatsExpressions.get(i))) {
+              aggrExpr.setStatsIndex(i);
+              break;
+            }
+          }
+          if (aggrExpr.getStatsIndex() == GroupByAggregationExpression.INVALID_STATS_INDEX) {
+            aggrExpr.setStatsIndex(groupByStatsExpressions.size());
+            groupByStatsExpressions.add(statsExpr);
+          }
+          return ExpressionVisitor.ReturnCode.SKIP_SUBTREE;
+        }
+        return ExpressionVisitor.ReturnCode.CONTINUE;
+      }
+    };
+    for (Expression expr : selectExpressions) {
+      ExpressionTraversal.traverse(expr, visitor);
+    }
+    if (havingExpression != null) {
+      ExpressionTraversal.traverse(havingExpression, visitor);
+    }
+
+    return groupByStatsExpressions;
+  }
+
+  private Comparator<GroupByCombinedKey> processSortSpecs(
+      List<Expression> selectExpressions, int[] orderByIndices,
+      final boolean[] ascending) {
+    if (orderByIndices == null) {
+      return GroupByCombinedKey.DEFAULT_COMPARATOR;
+    }
+    int count = orderByIndices.length;
+    final int[] keySorting = new int[count];
+    for (int i = 0; i < count; i++) {
+      Expression expr = (Expression) selectExpressions
+          .get(orderByIndices[i]);
+      if (!(expr instanceof GroupByKeyExpression)) {
+        return null;
+      }
+      keySorting[i] = ((GroupByKeyExpression) expr).getKeyIndex();
+    }
+
+    return new Comparator<GroupByCombinedKey>() {
+      public int compare(GroupByCombinedKey left, GroupByCombinedKey right) {
+        int comp = left.getKeys().length - right.getKeys().length;
+        if (comp != 0) {
+          return comp;
+        }
+        for (int i = 0; i < keySorting.length; i++) {
+          int keyIndex = keySorting[i];
+          comp = EvaluationResult.NULL_AS_MAX_COMPARATOR
+              .compare(left.getKeys()[keyIndex],
+                right.getKeys()[keyIndex]);
+
+          if (comp != 0) {
+            return ascending[i] != false ? comp : -comp;
+          }
+        }
+        return 0;
+      }
+    };
+  }
+
+  private Comparator<EvaluationResult[]> createComparator(
+      final int[] orderByIndices, final boolean[] ascending) {
+    return new Comparator<EvaluationResult[]>() {
+      public int compare(EvaluationResult[] left, EvaluationResult[] right) {
+        int comp = left.length - right.length;
+        if (comp == 0) {
+          for (int i = 0; i < orderByIndices.length; i++) {
+            int index = orderByIndices[i];
+            comp = EvaluationResult.NULL_AS_MAX_COMPARATOR.compare(
+              left[index], right[index]);
+            if (comp != 0) {
+              if (ascending[i] != false) break;
+              comp = -comp;
+              break;
+            }
+          }
+
+        }
+
+        return comp;
+      }
+    };
+  }
+
+  private boolean validateAndDecorateParameters(Scan[] scans,
+      List<Expression> groupByKeyExpressions,
+      List<Expression> groupByStatsExpressions) throws IOException,
+      ExpressionException {
+    for (Scan scan : scans) {
+      if ((scan != null)
+          && ((!Bytes.equals(scan.getStartRow(), scan.getStopRow())) || (Bytes
+              .equals(scan.getStartRow(),
+                HConstants.EMPTY_START_ROW)))
+          && ((Bytes.compareTo(scan.getStartRow(), scan.getStopRow()) <= 0) || (Bytes
+              .equals(scan.getStopRow(), HConstants.EMPTY_END_ROW)))) {
+        continue;
+      }
+
+      throw new IOException(
+          "GroupBy client Exception: Startrow should be smaller than Stoprow");
+    }
+
+    List<Pair<byte[], byte[]>> columns = new ArrayList<Pair<byte[], byte[]>>();
+    boolean isConstantGroupByKey = true;
+    for (Expression keyExpr : groupByKeyExpressions) {
+      ColumnVisitor visitor = new ColumnVisitor();
+      ExpressionTraversal.traverse(keyExpr, visitor);
+      for (Pair<byte[], byte[]> columnPair : visitor.getColumnSet()) {
+        if ((columnPair.getFirst() == null)
+            || (columnPair.getSecond() == null)) throw new IllegalArgumentException(
+            "ColumnValueExpression cannot specify null family or qualifier");
+        columns.add(columnPair);
+      }
+
+      if ((isConstantGroupByKey) && (visitor.getColumnSet().isEmpty())) {
+        IsConstantVisitor constVisitor = new IsConstantVisitor();
+        ExpressionTraversal.traverse(keyExpr, constVisitor);
+        isConstantGroupByKey = constVisitor.isConstant();
+      } else {
+        isConstantGroupByKey = false;
+      }
+    }
+
+    ExpressionVisitor groupByExprCheckVisitor = new ExpressionVisitor() {
+      public ExpressionVisitor.ReturnCode processExpression(
+          Expression expression) throws ExpressionException {
+        if ((expression instanceof GroupByKeyExpression)) {
+          throw new ExpressionException(
+              "The stats expression cannot contain GroupByKeyExpression");
+        }
+        if ((expression instanceof GroupByAggregationExpression)) {
+          throw new ExpressionException(
+              "The stats expression cannot contain GroupByAggregationExpression");
+        }
+        return ExpressionVisitor.ReturnCode.CONTINUE;
+      }
+    };
+    if (groupByStatsExpressions != null) {
+      for (Expression statsExpr : groupByStatsExpressions) {
+        ExpressionTraversal
+            .traverse(statsExpr, groupByExprCheckVisitor);
+        ColumnVisitor visitor = new ColumnVisitor();
+        ExpressionTraversal.traverse(statsExpr, visitor);
+        for (Pair<byte[], byte[]> columnPair : visitor.getColumnSet()) {
+          if ((columnPair.getFirst() == null)
+              || (columnPair.getSecond() == null)) throw new IllegalArgumentException(
+              "ColumnValueExpression cannot specify null family or qualifier");
+          columns.add(columnPair);
+        }
+      }
+    }
+
+    for (Scan scan : scans) {
+      scan.setCacheBlocks(false);
+      scan.getFamilyMap().clear();
+      if ((columns.isEmpty()) && (!scan.hasFilter())) {
+        log.debug("Use FirstKeyOnlyFilter");
+        scan.setFilter(new FirstKeyOnlyFilter());
+      }
+    }
+
+    return isConstantGroupByKey;
+  }
+
+  public int getMapSize() {
+    return this.MAP_SIZE;
+  }
+
+  public float getMapLoadFactor() {
+    return this.LOAD_FACTOR;
+  }
+
+  public void setMapLoadFactor(float loadFactor) {
+    this.LOAD_FACTOR = loadFactor;
+  }
+
+  public void setMapSize(int mapSize) {
+    this.MAP_SIZE = mapSize;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/execengine/ExecutionUtil.java b/src/main/java/org/apache/hadoop/hbase/execengine/ExecutionUtil.java
new file mode 100644
index 0000000..45a0246
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/execengine/ExecutionUtil.java
@@ -0,0 +1,317 @@
+package org.apache.hadoop.hbase.execengine;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.hadoop.hbase.coprocessor.GroupByCombinedKey;
+import org.apache.hadoop.hbase.coprocessor.GroupByIntermediateResult;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecCall;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+
+import com.google.common.collect.MinMaxPriorityQueue;
+
+public class ExecutionUtil {
+  public static MinMaxPriorityQueue<EvaluationResult[]> createPriorityQueue(
+      final int[] orderByIndices, final boolean[] ascending, int topCount) {
+    return MinMaxPriorityQueue
+        .orderedBy(new Comparator<EvaluationResult[]>() {
+          public int compare(EvaluationResult[] left,
+              EvaluationResult[] right) {
+            int comp = left.length - right.length;
+            if (comp == 0) {
+              for (int i = 0; i < orderByIndices.length; i++) {
+                int index = orderByIndices[i];
+                comp = EvaluationResult.NULL_AS_MAX_COMPARATOR
+                    .compare(left[index], right[index]);
+                if (comp != 0) {
+                  if (ascending[i] != false)
+                  break;
+                  comp = -comp;
+                  break;
+                }
+              }
+
+            }
+
+            return comp;
+          }
+        }).maximumSize(topCount).create();
+  }
+
+  public static class DistinctCallback implements
+      BatchExecCall.ServerCallback<Set<GroupByCombinedKey>> {
+    private int mapSize = 16;
+    private float loadFactor = 0.75F;
+    private Set<GroupByCombinedKey> set = null;
+
+    public DistinctCallback() {
+    }
+
+    public DistinctCallback(int mapSize, float loadFactor) {
+      this.mapSize = mapSize;
+      this.loadFactor = loadFactor;
+    }
+
+    public synchronized void update(byte[] region,
+        Set<GroupByCombinedKey> resultSet) throws IOException {
+      for (GroupByCombinedKey value : resultSet)
+        this.set.add(value);
+    }
+
+    public Set<GroupByCombinedKey> getResult() {
+      return this.set;
+    }
+
+    public void init() {
+      this.set = new HashSet<GroupByCombinedKey>(this.mapSize,
+          this.loadFactor);
+    }
+
+    public void readFields(DataInput in) throws IOException {
+      this.mapSize = in.readInt();
+      this.loadFactor = in.readFloat();
+    }
+
+    public void write(DataOutput out) throws IOException {
+      out.writeInt(this.mapSize);
+      out.writeFloat(this.loadFactor);
+    }
+  }
+
+  public static class GroupByCallback
+      implements
+      BatchExecCall.ServerCallback<Map<GroupByCombinedKey, List<StatsValue>>> {
+    private int mapSize = 16;
+    private float loadFactor = 0.75F;
+    private Map<GroupByCombinedKey, List<StatsValue>> map = null;
+
+    public GroupByCallback() {
+    }
+
+    public GroupByCallback(int mapSize, float loadFactor) {
+      this.mapSize = mapSize;
+      this.loadFactor = loadFactor;
+    }
+
+    public synchronized void update(byte[] region,
+        Map<GroupByCombinedKey, List<StatsValue>> resultMap)
+        throws IOException {
+      for (GroupByCombinedKey facet : resultMap.keySet()) {
+        List<StatsValue> finalStats = this.map.get(facet);
+        Iterator<StatsValue> itFinal;
+        Iterator<StatsValue> itTemp;
+        if (finalStats != null) {
+          itFinal = finalStats.iterator();
+          for (itTemp = resultMap.get(facet).iterator(); itFinal
+              .hasNext();)
+            try {
+              ((StatsValue) itFinal.next())
+                  .accumulate((StatsValue) itTemp.next());
+            } catch (TypeConversionException e) {
+              throw new IOException(e);
+            }
+        } else {
+          this.map.put(facet, resultMap.get(facet));
+        }
+      }
+    }
+
+    public Map<GroupByCombinedKey, List<StatsValue>> getResult() {
+      return this.map;
+    }
+
+    public void init() {
+      this.map = new HashMap<GroupByCombinedKey, List<StatsValue>>(
+          this.mapSize, this.loadFactor);
+    }
+
+    public void readFields(DataInput in) throws IOException {
+      this.mapSize = in.readInt();
+      this.loadFactor = in.readFloat();
+    }
+
+    public void write(DataOutput out) throws IOException {
+      out.writeInt(this.mapSize);
+      out.writeFloat(this.loadFactor);
+    }
+  }
+
+  public static class TopNGroupingCallback implements
+      BatchExecCall.ServerCallback<GroupByIntermediateResult> {
+    private int[] orderByIndices;
+    private boolean[] ascending;
+    private int topCount;
+    private int mapSize = 16;
+    private float loadFactor = 0.75F;
+    private MinMaxPriorityQueue<EvaluationResult[]> queue = null;
+    private Map<GroupByCombinedKey, List<StatsValue>> map = null;
+
+    public TopNGroupingCallback() {
+    }
+
+    public TopNGroupingCallback(int[] orderByIndices, boolean[] ascending,
+        int topCount, int mapSize, float loadFactor) {
+      this.orderByIndices = orderByIndices;
+      this.ascending = ascending;
+      this.topCount = topCount;
+      this.mapSize = mapSize;
+      this.loadFactor = loadFactor;
+    }
+
+    public synchronized void update(byte[] region,
+        GroupByIntermediateResult result) throws IOException {
+      Iterator<EvaluationResult[]> iter = result.getTopList().iterator();
+      while (iter.hasNext()) {
+        this.queue.add(iter.next());
+      }
+      for (Map.Entry<GroupByCombinedKey, List<StatsValue>> entry : result
+          .getStatsMap().entrySet()) {
+        List<StatsValue> finalStats = this.map.get(entry.getKey());
+        Iterator<StatsValue> itFinal;
+        Iterator<StatsValue> itTemp;
+        if (finalStats != null) {
+          itFinal = finalStats.iterator();
+          for (itTemp = entry.getValue().iterator(); itFinal
+              .hasNext();)
+            try {
+              ((StatsValue) itFinal.next())
+                  .accumulate((StatsValue) itTemp.next());
+            } catch (TypeConversionException e) {
+              throw new IOException(e);
+            }
+        } else {
+          this.map.put(entry.getKey(), entry.getValue());
+        }
+      }
+    }
+
+    public GroupByIntermediateResult getResult() {
+      List<EvaluationResult[]> list = new ArrayList<EvaluationResult[]>();
+
+      EvaluationResult[] elem = (EvaluationResult[]) this.queue
+          .pollFirst();
+      while (elem != null) {
+        list.add(elem);
+        elem = (EvaluationResult[]) this.queue.pollFirst();
+      }
+
+      return new GroupByIntermediateResult(list, this.map);
+    }
+
+    public void init() {
+      this.queue = ExecutionUtil.createPriorityQueue(this.orderByIndices,
+        this.ascending, this.topCount);
+      this.map = new HashMap<GroupByCombinedKey, List<StatsValue>>(
+          this.mapSize, this.loadFactor);
+    }
+
+    public void readFields(DataInput in) throws IOException {
+      int count = in.readInt();
+      this.orderByIndices = new int[count];
+      for (int i = 0; i < count; i++) {
+        this.orderByIndices[i] = in.readInt();
+      }
+      count = in.readInt();
+      this.ascending = new boolean[count];
+      for (int i = 0; i < count; i++) {
+        this.ascending[i] = in.readBoolean();
+      }
+      this.topCount = in.readInt();
+      this.mapSize = in.readInt();
+      this.loadFactor = in.readFloat();
+    }
+
+    public void write(DataOutput out) throws IOException {
+      out.writeInt(this.orderByIndices.length);
+      for (int i = 0; i < this.orderByIndices.length; i++) {
+        out.writeInt(this.orderByIndices[i]);
+      }
+      out.writeInt(this.ascending.length);
+      for (int i = 0; i < this.ascending.length; i++) {
+        out.writeBoolean(this.ascending[i]);
+      }
+      out.writeInt(this.topCount);
+      out.writeInt(this.mapSize);
+      out.writeFloat(this.loadFactor);
+    }
+  }
+
+  public static class TopNCallback implements
+      BatchExecCall.ServerCallback<List<EvaluationResult[]>> {
+    private int[] orderByIndices;
+    private boolean[] ascending;
+    private int topCount;
+    private MinMaxPriorityQueue<EvaluationResult[]> queue = null;
+
+    public TopNCallback() {
+    }
+
+    public TopNCallback(int[] orderByIndices, boolean[] ascending,
+        int topCount) {
+      this.orderByIndices = orderByIndices;
+      this.ascending = ascending;
+      this.topCount = topCount;
+    }
+
+    public void init() {
+      this.queue = ExecutionUtil.createPriorityQueue(this.orderByIndices,
+        this.ascending, this.topCount);
+    }
+
+    public synchronized void update(byte[] region,
+        List<EvaluationResult[]> resultList) throws IOException {
+      for (Iterator<EvaluationResult[]> iter = resultList.iterator(); iter
+          .hasNext();)
+        this.queue.add((EvaluationResult[]) iter.next());
+    }
+
+    public List<EvaluationResult[]> getResult() {
+      List<EvaluationResult[]> ret = new ArrayList<EvaluationResult[]>();
+
+      EvaluationResult[] elem = (EvaluationResult[]) this.queue
+          .pollFirst();
+      while (elem != null) {
+        ret.add(elem);
+        elem = (EvaluationResult[]) this.queue.pollFirst();
+      }
+      return ret;
+    }
+
+    public void readFields(DataInput in) throws IOException {
+      int count = in.readInt();
+      this.orderByIndices = new int[count];
+      for (int i = 0; i < count; i++) {
+        this.orderByIndices[i] = in.readInt();
+      }
+      count = in.readInt();
+      this.ascending = new boolean[count];
+      for (int i = 0; i < count; i++) {
+        this.ascending[i] = in.readBoolean();
+      }
+      this.topCount = in.readInt();
+    }
+
+    public void write(DataOutput out) throws IOException {
+      out.writeInt(this.orderByIndices.length);
+      for (int i = 0; i < this.orderByIndices.length; i++) {
+        out.writeInt(this.orderByIndices[i]);
+      }
+      out.writeInt(this.ascending.length);
+      for (int i = 0; i < this.ascending.length; i++) {
+        out.writeBoolean(this.ascending[i]);
+      }
+      out.writeInt(this.topCount);
+    }
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ArithmeticExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ArithmeticExpression.java
new file mode 100644
index 0000000..62474f0
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ArithmeticExpression.java
@@ -0,0 +1,146 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.Text;
+
+public class ArithmeticExpression implements Expression {
+	private ArithmeticOperator operator;
+	private Expression left;
+	private Expression right;
+
+	public ArithmeticExpression() {
+		this(ArithmeticOperator.NO_OP, null, null);
+	}
+
+	public ArithmeticExpression(ArithmeticOperator operator, Expression left,
+			Expression right) {
+		this.operator = operator;
+		this.left = left;
+		this.right = right;
+	}
+
+	public ArithmeticOperator getOperator() {
+		return this.operator;
+	}
+
+	public Expression getLeft() {
+		return this.left;
+	}
+
+	public Expression getRight() {
+		return this.right;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.operator == null) || (this.left == null)
+				|| (this.right == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult l = this.left.evaluate(context);
+		EvaluationResult r = this.right.evaluate(context);
+		if ((l.isNullResult()) || (r.isNullResult())) {
+			return new EvaluationResult();
+		}
+		EvaluationResult res = null;
+		switch (this.operator.ordinal()) {
+		case 1:
+			res = EvaluationResult.numberAdd(l, r);
+			break;
+		case 2:
+			res = EvaluationResult.numberSubtract(l, r);
+			break;
+		case 3:
+			res = EvaluationResult.numberMultiply(l, r);
+			break;
+		case 4:
+			res = EvaluationResult.numberDivide(l, r);
+			break;
+		case 5:
+			res = EvaluationResult.numberRemainder(l, r);
+			break;
+		default:
+			throw new EvaluationException("Unsupported operator: "
+					+ this.operator);
+		}
+
+		return res;
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ArithmeticExpression)))
+			return false;
+		ArithmeticExpression other = (ArithmeticExpression) expr;
+		boolean b = this.operator == other.operator;
+		if (b) {
+			if (this.left == null)
+				b = other.left == null;
+			else {
+				b = this.left.equals(other.left);
+			}
+		}
+		if (b) {
+			if (this.right == null)
+				b = other.right == null;
+			else {
+				b = this.right.equals(other.right);
+			}
+		}
+
+		return b;
+	}
+
+	public int hashCode() {
+		int result = this.operator == null ? 1 : this.operator.hashCode();
+		result = result * 31 + (this.left == null ? 1 : this.left.hashCode());
+		result = result * 31 + (this.right == null ? 1 : this.right.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return this.operator.toString().toLowerCase() + "("
+				+ this.left.toString() + ", " + this.right.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.operator = ArithmeticOperator.valueOf(Text.readString(in));
+		this.left = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.right = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		Text.writeString(out, this.operator.toString());
+		HbaseObjectWritable.writeObject(out, this.left, this.left.getClass(),
+				null);
+		HbaseObjectWritable.writeObject(out, this.right, this.right.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return (this.left == null) || (this.right == null) ? EvaluationResult.ResultType.BIGDECIMAL
+				: EvaluationResult.getMaxResultType(this.left.getReturnType(),
+						this.right.getReturnType());
+	}
+
+	public static enum ArithmeticOperator {
+		ADD(1), SUBTRACT(2), MULTIPLY(3), DIVIDE(4), REMAINDER(5), NO_OP(-1);
+		private final int value;
+
+		private ArithmeticOperator(int value) {
+			this.value = value;
+		}
+
+		public int getValue() {
+			return value;
+		}
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/AvroColumnValueExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/AvroColumnValueExpression.java
new file mode 100644
index 0000000..cdabec5
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/AvroColumnValueExpression.java
@@ -0,0 +1,123 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.avro.Schema;
+import org.apache.avro.Schema.Parser;
+import org.apache.avro.generic.GenericDatumReader;
+import org.apache.avro.generic.GenericRecord;
+import org.apache.avro.io.BinaryDecoder;
+import org.apache.avro.io.DecoderFactory;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class AvroColumnValueExpression implements Expression {
+  public static final Log LOG = LogFactory
+      .getLog(AvroColumnValueExpression.class.getName());
+  private byte[] family;
+  private byte[] qualifier;
+  private byte[] colName;
+  private byte[] schemaString;
+  GenericDatumReader<GenericRecord> reader;
+  Schema schema;
+  BinaryDecoder decoder;
+  GenericRecord result;
+  EvaluationResult.ResultType returnType = EvaluationResult.ResultType.BYTE;
+
+  public AvroColumnValueExpression() {
+  }
+
+  public AvroColumnValueExpression(byte[] family, byte[] qualifier,
+      byte[] colName, byte[] schemaString) {
+    this.family = family;
+    this.qualifier = qualifier;
+    this.colName = colName;
+    this.schemaString = schemaString;
+    this.schema = new Parser().parse(new String(this.schemaString));
+    this.reader = new GenericDatumReader<GenericRecord>(this.schema);
+  }
+
+  public byte[] getFamily() {
+    return this.family;
+  }
+
+  public byte[] getQualifier() {
+    return this.qualifier;
+  }
+
+  public EvaluationResult evaluate(EvaluationContext context)
+      throws EvaluationException {
+    if ((this.family == null) || (this.qualifier == null)) throw new EvaluationException(
+        "Missing required arguments");
+    if (this.reader == null) {
+      this.schema = new Parser().parse(new String(this.schemaString));
+      this.reader = new GenericDatumReader<GenericRecord>(this.schema);
+      LOG.info("avro_schema=" + new String(this.schemaString));
+    }
+    BytesReference ref = context
+        .getColumnValue(this.family, this.qualifier);
+    if (ref == null) {
+      EvaluationResult result = new EvaluationResult(null, null);
+      this.returnType = result.getResultType();
+      return result;
+    }
+    this.decoder = DecoderFactory.get().binaryDecoder(ref.getReference(),
+      ref.getOffset(), ref.getLength(), this.decoder);
+    try {
+      this.result = ((GenericRecord) this.reader.read(null, this.decoder));
+    } catch (IOException e) {
+      throw new EvaluationException(e.getMessage());
+    }
+    Object obj = this.result.get(new String(this.colName));
+    EvaluationResult result = new EvaluationResult(obj, null);
+    this.returnType = result.getResultType();
+    return result;
+  }
+
+  public boolean equals(Object expr) {
+    if (this == expr) return true;
+    if ((expr == null) || (!(expr instanceof AvroColumnValueExpression))) return false;
+    AvroColumnValueExpression other = (AvroColumnValueExpression) expr;
+    return (Bytes.equals(this.family, other.family))
+        && (Bytes.equals(this.qualifier, other.qualifier))
+        && (Bytes.equals(this.colName, other.colName));
+  }
+
+  public int hashCode() {
+    int result = this.family == null ? 1 : Bytes.hashCode(this.family);
+    result = result * 31
+        + (this.qualifier == null ? 1 : Bytes.hashCode(this.qualifier));
+    return result;
+  }
+
+  public String toString() {
+    return "avroColumnValue(\"" + Bytes.toString(this.family) + "\", \""
+        + Bytes.toString(this.qualifier) + "\", \""
+        + Bytes.toString(this.colName) + "\")";
+  }
+
+  public void readFields(DataInput in) throws IOException {
+    this.family = Bytes.readByteArray(in);
+    this.qualifier = Bytes.readByteArray(in);
+    this.colName = Bytes.readByteArray(in);
+    this.schemaString = Bytes.readByteArray(in);
+  }
+
+  public void write(DataOutput out) throws IOException {
+    Bytes.writeByteArray(out, this.family);
+    Bytes.writeByteArray(out, this.qualifier);
+    Bytes.writeByteArray(out, this.colName);
+    Bytes.writeByteArray(out, this.schemaString);
+  }
+
+  public EvaluationResult.ResultType getReturnType() {
+    return this.returnType;
+  }
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/BytesPartExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/BytesPartExpression.java
new file mode 100644
index 0000000..51cd2d4
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/BytesPartExpression.java
@@ -0,0 +1,170 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class BytesPartExpression implements Expression {
+	private Expression source;
+	private byte[] delimiter;
+	private Expression index;
+
+	public BytesPartExpression() {
+	}
+
+	public BytesPartExpression(Expression source, String delimiter, int index) {
+		this(source, delimiter, new ConstantExpression(Integer.valueOf(index)));
+	}
+
+	public BytesPartExpression(Expression source, String delimiter,
+			Expression index) {
+		this.source = source;
+		this.delimiter = (delimiter == null ? null : Bytes.toBytes(delimiter));
+		this.index = index;
+	}
+
+	public Expression getSource() {
+		return this.source;
+	}
+
+	public String getDelimiter() {
+		return Bytes.toString(this.delimiter);
+	}
+
+	public Expression getIndex() {
+		return this.index;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.source == null) || (this.delimiter == null)
+				|| (null == this.delimiter) || (this.delimiter.length == 0)
+				|| (this.index == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		BytesReference s = this.source.evaluate(context).asBytesReference();
+		Integer i = this.index.evaluate(context).asInteger();
+
+		if ((s == null) || (i == null)) {
+			return new EvaluationResult();
+		}
+		if (i.intValue() < 0) {
+			throw new EvaluationException(
+					"Could not evaluate BytesPartExpression(" + s + ",\""
+							+ this.delimiter + "\"," + i + ")");
+		}
+
+		BytesReference column = seek(s, i.intValue(), this.delimiter);
+		if (null == column) {
+			throw new EvaluationException(
+					"Could not evaluate BytesPartExpression(" + s + ",\""
+							+ this.delimiter + "\"," + i + ")");
+		}
+
+		return new EvaluationResult(column,
+				EvaluationResult.ResultType.BYTESREFERENCE);
+	}
+
+	private static BytesReference seek(BytesReference s, int index,
+			byte[] delimeter) {
+		int offset = s.getOffset();
+		int length = s.getLength();
+		byte[] buffer = s.getReference();
+		int lastOffset = offset + length;
+
+		int count = 0;
+		int start = -1;
+
+		if (index == 0) {
+			start = offset;
+		} else {
+			for (int i = offset; i < lastOffset; i++) {
+				if (delimeter[0] == buffer[i]) {
+					count++;
+					if (count == index) {
+						start = i + 1;
+						break;
+					}
+				}
+			}
+		}
+
+		if (-1 == start) {
+			return null;
+		}
+
+		int end = -1;
+		for (int i = start; i < lastOffset; i++) {
+			if ((delimeter[0] != buffer[i]) || (count != index))
+				continue;
+			end = i;
+			break;
+		}
+
+		if (end == -1) {
+			end = lastOffset;
+		}
+		return new BytesReference(buffer, start, end - start);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof BytesPartExpression)))
+			return false;
+		BytesPartExpression other = (BytesPartExpression) expr;
+		return ((this.source == null) && (other.source == null))
+				|| ((this.source != null) && (this.source.equals(other.source)) && (((this.delimiter == null) && (other.delimiter == null)) || ((this.delimiter != null)
+						&& (Bytes.equals(this.delimiter, other.delimiter)) && (((this.index == null) && (other.index == null)) || ((this.index != null) && (this.index
+						.equals(other.index)))))));
+	}
+
+	public int hashCode() {
+		int result = this.source == null ? 1 : this.source.hashCode();
+		result = result * 31
+				+ (this.delimiter == null ? 1 : Bytes.hashCode(this.delimiter));
+		result = result * 31 + (this.index == null ? 1 : this.index.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return "bytesPart(" + this.source.toString() + ", "
+				+ Bytes.toString(this.delimiter) + ", " + this.index.toString()
+				+ ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.source = ((Expression) HbaseObjectWritable.readObject(in, null));
+		boolean notNull = in.readBoolean();
+		if (notNull)
+			this.delimiter = Bytes.readByteArray(in);
+		else {
+			this.delimiter = null;
+		}
+		this.index = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.source,
+				this.source.getClass(), null);
+		if (this.delimiter == null) {
+			out.writeBoolean(false);
+		} else {
+			out.writeBoolean(true);
+			Bytes.writeByteArray(out, this.delimiter);
+		}
+		HbaseObjectWritable.writeObject(out, this.index, this.index.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BYTESREFERENCE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/CaseExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/CaseExpression.java
new file mode 100644
index 0000000..99ed1df
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/CaseExpression.java
@@ -0,0 +1,223 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.List;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class CaseExpression implements Expression {
+	private Expression conditionExpression;
+	private Expression defaultExpression;
+	private List<WhenBranch> whenBranches = new ArrayList<WhenBranch>();
+
+	public CaseExpression() {
+	}
+
+	public CaseExpression(Expression conditionExpression,
+			Expression defaultExpression) {
+		this.conditionExpression = conditionExpression;
+		this.defaultExpression = defaultExpression;
+	}
+
+	public CaseExpression when(Expression matchExpression,
+			Expression returnExpression) {
+		this.whenBranches
+				.add(new WhenBranch(matchExpression, returnExpression));
+		return this;
+	}
+
+	public Expression getConditionExpression() {
+		return this.conditionExpression;
+	}
+
+	public Expression getDefaultExpression() {
+		return this.defaultExpression;
+	}
+
+	public List<WhenBranch> getWhenBranches() {
+		return Collections.unmodifiableList(this.whenBranches);
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.conditionExpression == null)
+				|| (this.defaultExpression == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult cond = this.conditionExpression.evaluate(context);
+		for (Iterator<WhenBranch> it = this.whenBranches.iterator(); it
+				.hasNext();) {
+			WhenBranch when = (WhenBranch) it.next();
+			if ((when.matchExpression == null)
+					|| (when.returnExpression == null))
+				throw new EvaluationException("Missing required arguments");
+			EvaluationResult match = when.matchExpression.evaluate(context);
+			if (((cond.isNullResult()) && (match.isNullResult()))
+					|| (EvaluationResult.compare(cond, match) == 0)) {
+				return when.returnExpression.evaluate(context);
+			}
+		}
+		return this.defaultExpression.evaluate(context);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof CaseExpression)))
+			return false;
+		CaseExpression other = (CaseExpression) expr;
+		if (((this.conditionExpression == null) && (other.conditionExpression != null))
+				|| ((this.conditionExpression != null) && (!this.conditionExpression
+						.equals(other.conditionExpression)))
+				|| ((this.defaultExpression == null) && (other.defaultExpression != null))
+				|| ((this.defaultExpression != null) && (!this.defaultExpression
+						.equals(other.defaultExpression)))
+				|| (this.whenBranches.size() != other.whenBranches.size())) {
+			return false;
+		}
+		Iterator<WhenBranch> it = this.whenBranches.iterator();
+		for (Iterator<WhenBranch> itOther = other.whenBranches.iterator(); it
+				.hasNext();) {
+			WhenBranch when = (WhenBranch) it.next();
+			WhenBranch whenOther = (WhenBranch) itOther.next();
+			if (!when.equals(whenOther)) {
+				return false;
+			}
+		}
+		return true;
+	}
+
+	public int hashCode() {
+		int result = this.conditionExpression == null ? 1
+				: this.conditionExpression.hashCode();
+		result = result
+				* 31
+				+ (this.defaultExpression == null ? 1 : this.defaultExpression
+						.hashCode());
+		result = result * 31 + this.whenBranches.size();
+		for (Iterator<WhenBranch> it = this.whenBranches.iterator(); it
+				.hasNext();) {
+			result += ((WhenBranch) it.next()).hashCode();
+		}
+		return result;
+	}
+
+	public String toString() {
+		StringBuilder sb = new StringBuilder();
+		sb.append("case (");
+		sb.append(this.conditionExpression.toString());
+		sb.append(")");
+		for (Iterator<WhenBranch> it = this.whenBranches.iterator(); it
+				.hasNext();) {
+			WhenBranch when = (WhenBranch) it.next();
+			sb.append(" when (");
+			sb.append(when.matchExpression.toString());
+			sb.append(") then (");
+			sb.append(when.returnExpression.toString());
+			sb.append(")");
+		}
+		sb.append(" else (");
+		sb.append(this.defaultExpression.toString());
+		sb.append(") end");
+		return sb.toString();
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.conditionExpression = ((Expression) HbaseObjectWritable
+				.readObject(in, null));
+		this.defaultExpression = ((Expression) HbaseObjectWritable.readObject(
+				in, null));
+		int count = in.readInt();
+		for (int i = 0; i < count; i++)
+			this.whenBranches.add(new WhenBranch(
+					(Expression) HbaseObjectWritable.readObject(in, null),
+					(Expression) HbaseObjectWritable.readObject(in, null)));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.conditionExpression,
+				this.conditionExpression.getClass(), null);
+		HbaseObjectWritable.writeObject(out, this.defaultExpression,
+				this.defaultExpression.getClass(), null);
+		out.writeInt(this.whenBranches.size());
+		for (Iterator<WhenBranch> it = this.whenBranches.iterator(); it
+				.hasNext();) {
+			WhenBranch when = (WhenBranch) it.next();
+			HbaseObjectWritable.writeObject(out, when.matchExpression,
+					when.matchExpression.getClass(), null);
+			HbaseObjectWritable.writeObject(out, when.returnExpression,
+					when.returnExpression.getClass(), null);
+		}
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		EvaluationResult.ResultType maxType = this.defaultExpression == null ? EvaluationResult.ResultType.UNKNOWN
+				: this.defaultExpression.getReturnType();
+		for (Iterator<WhenBranch> it = this.whenBranches.iterator(); it
+				.hasNext();) {
+			WhenBranch when = (WhenBranch) it.next();
+			if (when.returnExpression == null)
+				continue;
+			EvaluationResult.ResultType whenType = when.returnExpression
+					.getReturnType();
+			if (maxType == EvaluationResult.ResultType.UNKNOWN)
+				maxType = whenType;
+			else if (whenType != EvaluationResult.ResultType.UNKNOWN) {
+				maxType = EvaluationResult.getMaxResultType(maxType, whenType);
+			}
+		}
+		return maxType;
+	}
+
+	public class WhenBranch {
+		private Expression matchExpression;
+		private Expression returnExpression;
+
+		protected WhenBranch(Expression matchExpression,
+				Expression returnExpression) {
+			this.matchExpression = matchExpression;
+			this.returnExpression = returnExpression;
+		}
+
+		public Expression getMatchExpression() {
+			return this.matchExpression;
+		}
+
+		public Expression getReturnExpression() {
+			return this.returnExpression;
+		}
+
+		public boolean equals(Object obj) {
+			if (this == obj) {
+				return true;
+			}
+			if ((obj == null) || (!(obj instanceof WhenBranch))) {
+				return false;
+			}
+			WhenBranch other = (WhenBranch) obj;
+			return ((this.matchExpression == null) && (other.matchExpression == null))
+					|| ((this.matchExpression != null)
+							&& (this.matchExpression
+									.equals(other.matchExpression)) && (((this.returnExpression == null) && (other.returnExpression == null)) || ((this.returnExpression != null) && (this.returnExpression
+							.equals(other.returnExpression)))));
+		}
+
+		public int hashCode() {
+			int result = this.matchExpression == null ? 1
+					: this.matchExpression.hashCode();
+			result = result
+					* 31
+					+ (this.returnExpression == null ? 1
+							: this.returnExpression.hashCode());
+			return result;
+		}
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ColumnValueExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ColumnValueExpression.java
new file mode 100644
index 0000000..48d7bdb
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ColumnValueExpression.java
@@ -0,0 +1,76 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ColumnValueExpression implements Expression {
+	private byte[] family;
+	private byte[] qualifier;
+
+	public ColumnValueExpression() {
+	}
+
+	public ColumnValueExpression(byte[] family, byte[] qualifier) {
+		this.family = family;
+		this.qualifier = qualifier;
+	}
+
+	public byte[] getFamily() {
+		return this.family;
+	}
+
+	public byte[] getQualifier() {
+		return this.qualifier;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.family == null) || (this.qualifier == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		return new EvaluationResult(context.getColumnValue(this.family,
+				this.qualifier), EvaluationResult.ResultType.BYTESREFERENCE);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ColumnValueExpression)))
+			return false;
+		ColumnValueExpression other = (ColumnValueExpression) expr;
+		return (Bytes.equals(this.family, other.family))
+				&& (Bytes.equals(this.qualifier, other.qualifier));
+	}
+
+	public int hashCode() {
+		int result = this.family == null ? 1 : Bytes.hashCode(this.family);
+		result = result * 31
+				+ (this.qualifier == null ? 1 : Bytes.hashCode(this.qualifier));
+		return result;
+	}
+
+	public String toString() {
+		return "columnValue(\"" + Bytes.toString(this.family) + "\", \""
+				+ Bytes.toString(this.qualifier) + "\")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.family = Bytes.readByteArray(in);
+		this.qualifier = Bytes.readByteArray(in);
+	}
+
+	public void write(DataOutput out) throws IOException {
+		Bytes.writeByteArray(out, this.family);
+		Bytes.writeByteArray(out, this.qualifier);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BYTESREFERENCE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ComparisonExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ComparisonExpression.java
new file mode 100644
index 0000000..6ac44db
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ComparisonExpression.java
@@ -0,0 +1,153 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.Text;
+
+public class ComparisonExpression implements Expression {
+	private ComparisonOperator operator;
+	private Expression left;
+	private Expression right;
+
+	public ComparisonExpression() {
+		this(ComparisonOperator.NO_OP, null, null);
+	}
+
+	public ComparisonExpression(ComparisonOperator operator, Expression left,
+			Expression right) {
+		this.operator = operator;
+		this.left = left;
+		this.right = right;
+	}
+
+	public ComparisonOperator getOperator() {
+		return this.operator;
+	}
+
+	public Expression getLeft() {
+		return this.left;
+	}
+
+	public Expression getRight() {
+		return this.right;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.operator == null) || (this.left == null)
+				|| (this.right == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult l = this.left.evaluate(context);
+		EvaluationResult r = this.right.evaluate(context);
+		if ((l.isNullResult()) || (r.isNullResult())) {
+			if (this.operator == ComparisonOperator.EQUAL)
+				return new EvaluationResult(Boolean.valueOf((l.isNullResult())
+						&& (r.isNullResult())),
+						EvaluationResult.ResultType.BOOLEAN);
+			if (this.operator == ComparisonOperator.NOT_EQUAL) {
+				return new EvaluationResult(
+						Boolean.valueOf(((l.isNullResult()) && (!r
+								.isNullResult()))
+								|| ((!l.isNullResult()) && (r.isNullResult()))),
+						EvaluationResult.ResultType.BOOLEAN);
+			}
+
+			return new EvaluationResult();
+		}
+
+		int comp = EvaluationResult.compare(l, r);
+
+		Boolean res = null;
+		switch (this.operator.ordinal()) {
+		case 1:
+			res = Boolean.valueOf(comp < 0);
+			break;
+		case 2:
+			res = Boolean.valueOf(comp <= 0);
+			break;
+		case 3:
+			res = Boolean.valueOf(comp == 0);
+			break;
+		case 4:
+			res = Boolean.valueOf(comp != 0);
+			break;
+		case 5:
+			res = Boolean.valueOf(comp >= 0);
+			break;
+		case 6:
+			res = Boolean.valueOf(comp > 0);
+			break;
+		default:
+			throw new EvaluationException("Unsupported operator: "
+					+ this.operator);
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.BOOLEAN);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ComparisonExpression)))
+			return false;
+		ComparisonExpression other = (ComparisonExpression) expr;
+		boolean b = this.operator == other.operator;
+		if (b) {
+			if (this.left == null)
+				b = other.left == null;
+			else {
+				b = this.left.equals(other.left);
+			}
+		}
+		if (b) {
+			if (this.right == null)
+				b = other.right == null;
+			else {
+				b = this.right.equals(other.right);
+			}
+		}
+
+		return b;
+	}
+
+	public int hashCode() {
+		int result = this.operator == null ? 1 : this.operator.hashCode();
+		result = result * 31 + (this.left == null ? 1 : this.left.hashCode());
+		result = result * 31 + (this.right == null ? 1 : this.right.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return this.operator.toString().toLowerCase() + "("
+				+ this.left.toString() + ", " + this.right.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.operator = ComparisonOperator.valueOf(Text.readString(in));
+		this.left = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.right = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		Text.writeString(out, this.operator.toString());
+		HbaseObjectWritable.writeObject(out, this.left, this.left.getClass(),
+				null);
+		HbaseObjectWritable.writeObject(out, this.right, this.right.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BOOLEAN;
+	}
+
+	public static enum ComparisonOperator {
+		LESS, LESS_OR_EQUAL, EQUAL, NOT_EQUAL, GREATER_OR_EQUAL, GREATER, NO_OP;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ConstantExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ConstantExpression.java
new file mode 100644
index 0000000..b97d041
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ConstantExpression.java
@@ -0,0 +1,83 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.Writable;
+
+public class ConstantExpression implements Expression {
+	private Object constant;
+	private transient EvaluationResult.ResultType type;
+
+	public ConstantExpression() {
+		this(null);
+	}
+
+	public ConstantExpression(Object constant) {
+		this.constant = constant;
+		this.type = EvaluationResult.getObjectResultType(constant);
+	}
+
+	public Object getConstant() {
+		return this.constant;
+	}
+
+	public EvaluationResult.ResultType getType() {
+		return this.type;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		return new EvaluationResult(this.constant, this.type);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ConstantExpression)))
+			return false;
+		ConstantExpression other = (ConstantExpression) expr;
+		return ((this.constant == null) && (other.constant == null))
+				|| ((this.constant != null) && (other.constant != null)
+						&& ((this.constant instanceof byte[]))
+						&& ((other.constant instanceof byte[])) && (Bytes
+							.equals((byte[]) (byte[]) this.constant,
+									(byte[]) (byte[]) other.constant)))
+				|| (this.constant.equals(other.constant));
+	}
+
+	public int hashCode() {
+		return (this.constant instanceof byte[]) ? Bytes
+				.hashCode((byte[]) (byte[]) this.constant)
+				: this.constant == null ? 1 : this.constant.hashCode();
+	}
+
+	public String toString() {
+		return "constant("
+				+ new EvaluationResult(this.constant, this.type).toString()
+				+ ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.constant = HbaseObjectWritable.readObject(in, null);
+		this.type = EvaluationResult.getObjectResultType(this.constant);
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(
+				out,
+				this.constant,
+				this.constant == null ? Writable.class : this.constant
+						.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return this.type;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/Expression.java b/src/main/java/org/apache/hadoop/hbase/expression/Expression.java
new file mode 100644
index 0000000..30ab10e
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/Expression.java
@@ -0,0 +1,14 @@
+package org.apache.hadoop.hbase.expression;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.io.Writable;
+
+public abstract interface Expression extends Writable {
+	public abstract EvaluationResult evaluate(
+			EvaluationContext paramEvaluationContext)
+			throws EvaluationException;
+
+	public abstract EvaluationResult.ResultType getReturnType();
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ExpressionException.java b/src/main/java/org/apache/hadoop/hbase/expression/ExpressionException.java
new file mode 100644
index 0000000..c7bd82a
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ExpressionException.java
@@ -0,0 +1,12 @@
+package org.apache.hadoop.hbase.expression;
+
+public class ExpressionException extends Exception {
+	/**
+	 * 
+	 */
+	private static final long serialVersionUID = 1L;
+
+	public ExpressionException(String msg) {
+		super(msg);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ExpressionFactory.java b/src/main/java/org/apache/hadoop/hbase/expression/ExpressionFactory.java
new file mode 100644
index 0000000..3ce0eb6
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ExpressionFactory.java
@@ -0,0 +1,263 @@
+package org.apache.hadoop.hbase.expression;
+
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ExpressionFactory {
+	public static ArithmeticExpression add(Expression left, Expression right) {
+		return new ArithmeticExpression(
+				ArithmeticExpression.ArithmeticOperator.ADD, left, right);
+	}
+
+	public static ArithmeticExpression subtract(Expression left,
+			Expression right) {
+		return new ArithmeticExpression(
+				ArithmeticExpression.ArithmeticOperator.SUBTRACT, left, right);
+	}
+
+	public static ArithmeticExpression multiply(Expression left,
+			Expression right) {
+		return new ArithmeticExpression(
+				ArithmeticExpression.ArithmeticOperator.MULTIPLY, left, right);
+	}
+
+	public static ArithmeticExpression divide(Expression left, Expression right) {
+		return new ArithmeticExpression(
+				ArithmeticExpression.ArithmeticOperator.DIVIDE, left, right);
+	}
+
+	public static ArithmeticExpression remainder(Expression left,
+			Expression right) {
+		return new ArithmeticExpression(
+				ArithmeticExpression.ArithmeticOperator.REMAINDER, left, right);
+	}
+
+	public static AvroColumnValueExpression avroColumnValue(byte[] family,
+			byte[] qualifier, byte[] colName, byte[] schemaString) {
+		return new AvroColumnValueExpression(family, qualifier, colName,
+				schemaString);
+	}
+
+	public static CaseExpression caseWhenElse(Expression conditionExpression,
+			Expression defaultExpression) {
+		return new CaseExpression(conditionExpression, defaultExpression);
+	}
+
+	public static BytesPartExpression bytesPart(Expression source,
+			String delimiter, int index) {
+		return new BytesPartExpression(source, delimiter, index);
+	}
+
+	public static BytesPartExpression bytesPart(Expression source,
+			String delimiter, Expression index) {
+		return new BytesPartExpression(source, delimiter, index);
+	}
+
+	public static ColumnValueExpression columnValue(byte[] family,
+			byte[] qualifier) {
+		return new ColumnValueExpression(family, qualifier);
+	}
+
+	public static ColumnValueExpression columnValue(String family,
+			String qualifier) {
+		return new ColumnValueExpression(Bytes.toBytes(family),
+				Bytes.toBytes(qualifier));
+	}
+
+	public static ComparisonExpression eq(Expression left, Expression right) {
+		return new ComparisonExpression(
+				ComparisonExpression.ComparisonOperator.EQUAL, left, right);
+	}
+
+	public static ComparisonExpression neq(Expression left, Expression right) {
+		return new ComparisonExpression(
+				ComparisonExpression.ComparisonOperator.NOT_EQUAL, left, right);
+	}
+
+	public static ComparisonExpression lt(Expression left, Expression right) {
+		return new ComparisonExpression(
+				ComparisonExpression.ComparisonOperator.LESS, left, right);
+	}
+
+	public static ComparisonExpression le(Expression left, Expression right) {
+		return new ComparisonExpression(
+				ComparisonExpression.ComparisonOperator.LESS_OR_EQUAL, left,
+				right);
+	}
+
+	public static ComparisonExpression gt(Expression left, Expression right) {
+		return new ComparisonExpression(
+				ComparisonExpression.ComparisonOperator.GREATER, left, right);
+	}
+
+	public static ComparisonExpression ge(Expression left, Expression right) {
+		return new ComparisonExpression(
+				ComparisonExpression.ComparisonOperator.GREATER_OR_EQUAL, left,
+				right);
+	}
+
+	public static ConstantExpression constant(Object constant) {
+		return new ConstantExpression(constant);
+	}
+
+	public static GroupByAggregationExpression sum(Expression subExpression) {
+		return new GroupByAggregationExpression(
+				GroupByAggregationExpression.AggregationType.SUM, subExpression);
+	}
+
+	public static GroupByAggregationExpression avg(Expression subExpression) {
+		return new GroupByAggregationExpression(
+				GroupByAggregationExpression.AggregationType.AVG, subExpression);
+	}
+
+	public static GroupByAggregationExpression count(Expression subExpression) {
+		return new GroupByAggregationExpression(
+				GroupByAggregationExpression.AggregationType.COUNT,
+				subExpression);
+	}
+
+	public static GroupByAggregationExpression min(Expression subExpression) {
+		return new GroupByAggregationExpression(
+				GroupByAggregationExpression.AggregationType.MIN, subExpression);
+	}
+
+	public static GroupByAggregationExpression max(Expression subExpression) {
+		return new GroupByAggregationExpression(
+				GroupByAggregationExpression.AggregationType.MAX, subExpression);
+	}
+
+	public static GroupByAggregationExpression stdDev(Expression subExpression) {
+		return new GroupByAggregationExpression(
+				GroupByAggregationExpression.AggregationType.STDDEV,
+				subExpression);
+	}
+
+	public static GroupByKeyExpression groupByKey(Expression referenceExpression) {
+		return new GroupByKeyExpression(referenceExpression);
+	}
+
+	public static InExpression in(Expression testExpression,
+			ConstantExpression[] constantExpressions) {
+		return new InExpression(testExpression, constantExpressions);
+	}
+
+	public static LogicalExpression and(Expression left, Expression right) {
+		return new LogicalExpression(LogicalExpression.LogicalOperator.AND,
+				left, right);
+	}
+
+	public static LogicalExpression or(Expression left, Expression right) {
+		return new LogicalExpression(LogicalExpression.LogicalOperator.OR,
+				left, right);
+	}
+
+	public static NotExpression not(Expression subExpression) {
+		return new NotExpression(subExpression);
+	}
+
+	public static RowExpression row() {
+		return new RowExpression();
+	}
+
+	public static StringConcatExpression stringConcat(Expression[] parts) {
+		return new StringConcatExpression(parts);
+	}
+
+	public static StringMatchExpression stringMatch(Expression matchExpression,
+			String regex) {
+		return new StringMatchExpression(matchExpression, regex);
+	}
+
+	public static StringPartExpression stringPart(Expression source,
+			String delimiter, int index) {
+		return new StringPartExpression(source, delimiter, index);
+	}
+
+	public static StringPartExpression stringPart(Expression source,
+			String delimiter, Expression index) {
+		return new StringPartExpression(source, delimiter, index);
+	}
+
+	public static SubSequenceExpression subSequence(Expression source, int start) {
+		return new SubSequenceExpression(source, start);
+	}
+
+	public static SubSequenceExpression subSequence(Expression source,
+			int start, int end) {
+		return new SubSequenceExpression(source, start, end);
+	}
+
+	public static SubSequenceExpression subSequence(Expression source,
+			Expression start) {
+		return new SubSequenceExpression(source, start);
+	}
+
+	public static SubSequenceExpression subSequence(Expression source,
+			Expression start, Expression end) {
+		return new SubSequenceExpression(source, start, end);
+	}
+
+	public static SubstringExpression subString(Expression source, int start) {
+		return new SubstringExpression(source, start);
+	}
+
+	public static SubstringExpression subString(Expression source, int start,
+			int end) {
+		return new SubstringExpression(source, start, end);
+	}
+
+	public static SubstringExpression subString(Expression source,
+			Expression start) {
+		return new SubstringExpression(source, start);
+	}
+
+	public static SubstringExpression subString(Expression source,
+			Expression start, Expression end) {
+		return new SubstringExpression(source, start, end);
+	}
+
+	public static TernaryExpression ternary(Expression condExpression,
+			Expression trueExpression, Expression falseExpression) {
+		return new TernaryExpression(condExpression, trueExpression,
+				falseExpression);
+	}
+
+	public static ToBigDecimalExpression toBigDecimal(Expression subExpression) {
+		return new ToBigDecimalExpression(subExpression);
+	}
+
+	public static ToBooleanExpression toBoolean(Expression subExpression) {
+		return new ToBooleanExpression(subExpression);
+	}
+
+	public static ToByteExpression toByte(Expression subExpression) {
+		return new ToByteExpression(subExpression);
+	}
+
+	public static ToBytesExpression toBytes(Expression subExpression) {
+		return new ToBytesExpression(subExpression);
+	}
+
+	public static ToDoubleExpression toDouble(Expression subExpression) {
+		return new ToDoubleExpression(subExpression);
+	}
+
+	public static ToFloatExpression toFloat(Expression subExpression) {
+		return new ToFloatExpression(subExpression);
+	}
+
+	public static ToIntegerExpression toInteger(Expression subExpression) {
+		return new ToIntegerExpression(subExpression);
+	}
+
+	public static ToLongExpression toLong(Expression subExpression) {
+		return new ToLongExpression(subExpression);
+	}
+
+	public static ToShortExpression toShort(Expression subExpression) {
+		return new ToShortExpression(subExpression);
+	}
+
+	public static ToStringExpression toString(Expression subExpression) {
+		return new ToStringExpression(subExpression);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/GroupByAggregationExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/GroupByAggregationExpression.java
new file mode 100644
index 0000000..43427a1
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/GroupByAggregationExpression.java
@@ -0,0 +1,147 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.StatsValue;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.Text;
+
+public class GroupByAggregationExpression implements Expression {
+	public static int INVALID_STATS_INDEX = -1;
+	private AggregationType type;
+	private Expression subExpression;
+	private int statsIndex;
+
+	public GroupByAggregationExpression() {
+		this(AggregationType.NO_OP, null);
+	}
+
+	public GroupByAggregationExpression(AggregationType type,
+			Expression subExpression) {
+		this.type = type;
+		this.subExpression = subExpression;
+		this.statsIndex = INVALID_STATS_INDEX;
+	}
+
+	public AggregationType getType() {
+		return this.type;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public int getStatsIndex() {
+		return this.statsIndex;
+	}
+
+	public void setStatsIndex(int statsIndex) {
+		this.statsIndex = statsIndex;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.type == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		StatsValue value = context.getGroupByStatsValue(this.statsIndex);
+		if (value == null) {
+			return new EvaluationResult();
+		}
+		EvaluationResult res = null;
+		switch (this.type.ordinal()) {
+		case 1:
+			res = new EvaluationResult(value.getSum(), value.getType());
+			break;
+		case 2:
+			res = new EvaluationResult(Double.valueOf(value.getSum()
+					.doubleValue() / value.getCount()),
+					EvaluationResult.ResultType.DOUBLE);
+			break;
+		case 3:
+			res = new EvaluationResult(Long.valueOf(value.getCount()),
+					EvaluationResult.ResultType.LONG);
+			break;
+		case 4:
+			res = new EvaluationResult(value.getMin(), value.getType());
+			break;
+		case 5:
+			res = new EvaluationResult(value.getMax(), value.getType());
+			break;
+		case 6:
+			double avg = value.getSum().doubleValue() / value.getCount();
+			double avgOfSumSq = value.getSumOfSquares().doubleValue()
+					/ value.getCount();
+			res = new EvaluationResult(Double.valueOf(Math.pow(avgOfSumSq - avg
+					* avg, 0.5D)), EvaluationResult.ResultType.DOUBLE);
+			break;
+		default:
+			throw new EvaluationException("Unsupported aggregation type: "
+					+ this.type);
+		}
+
+		return res;
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof GroupByAggregationExpression)))
+			return false;
+		GroupByAggregationExpression other = (GroupByAggregationExpression) expr;
+		return (this.type == other.type)
+				&& (((this.subExpression == null) && (other.subExpression == null)) || ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression))));
+	}
+
+	public int hashCode() {
+		int result = this.type == null ? 1 : this.type.hashCode();
+		result = result
+				* 31
+				+ (this.subExpression == null ? 1 : this.subExpression
+						.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return this.type.toString().toLowerCase() + "("
+				+ this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.type = AggregationType.valueOf(Text.readString(in));
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+		this.statsIndex = in.readInt();
+	}
+
+	public void write(DataOutput out) throws IOException {
+		Text.writeString(out, this.type.toString());
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+		out.writeInt(this.statsIndex);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.DOUBLE;
+	}
+
+	public static enum AggregationType {
+		NO_OP(-1), SUM(1), AVG(2), COUNT(3), MIN(4), MAX(5), STDDEV(6);
+		private final int value;
+
+		private AggregationType(int value) {
+			this.value = value;
+		}
+
+		public int getValue() {
+			return value;
+		}
+
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/GroupByKeyExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/GroupByKeyExpression.java
new file mode 100644
index 0000000..16a739e
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/GroupByKeyExpression.java
@@ -0,0 +1,78 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class GroupByKeyExpression implements Expression {
+	public static int INVALID_KEY_ID = -1;
+	private Expression referenceExpression;
+	private int keyIndex;
+
+	public GroupByKeyExpression() {
+		this(null);
+	}
+
+	public GroupByKeyExpression(Expression referenceExpression) {
+		this.referenceExpression = referenceExpression;
+		this.keyIndex = INVALID_KEY_ID;
+	}
+
+	public Expression getReferenceExpression() {
+		return this.referenceExpression;
+	}
+
+	public int getKeyIndex() {
+		return this.keyIndex;
+	}
+
+	public void setKeyIndex(int keyIndex) {
+		this.keyIndex = keyIndex;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		return context.getGroupByKey(this.keyIndex);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof GroupByKeyExpression)))
+			return false;
+		GroupByKeyExpression other = (GroupByKeyExpression) expr;
+		return ((this.referenceExpression == null) && (other.referenceExpression == null))
+				|| ((this.referenceExpression != null) && (this.referenceExpression
+						.equals(other.referenceExpression)));
+	}
+
+	public int hashCode() {
+		return this.referenceExpression == null ? 1 : this.referenceExpression
+				.hashCode();
+	}
+
+	public String toString() {
+		return "groupByKey(" + this.referenceExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.referenceExpression = ((Expression) HbaseObjectWritable
+				.readObject(in, null));
+		this.keyIndex = in.readInt();
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.referenceExpression,
+				this.referenceExpression.getClass(), null);
+		out.writeInt(this.keyIndex);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return this.referenceExpression.getReturnType();
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/InExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/InExpression.java
new file mode 100644
index 0000000..6d6a489
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/InExpression.java
@@ -0,0 +1,114 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.Set;
+import java.util.TreeSet;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class InExpression implements Expression {
+	private Expression testExpression;
+	private Set<EvaluationResult> valueSet;
+
+	public InExpression() {
+	}
+
+	public InExpression(Expression testExpression,
+			ConstantExpression[] constantExpressions) {
+		this.testExpression = testExpression;
+		this.valueSet = new TreeSet<EvaluationResult>(
+				EvaluationResult.NULL_AS_MIN_COMPARATOR);
+
+		for (ConstantExpression expr : constantExpressions)
+			this.valueSet.add(new EvaluationResult(expr.getConstant(), expr
+					.getType()));
+	}
+
+	public InExpression(Expression testExpression,
+			Set<EvaluationResult> valueSet) {
+		this.testExpression = testExpression;
+		this.valueSet = valueSet;
+	}
+
+	public Expression getTestExpression() {
+		return this.testExpression;
+	}
+
+	public Set<EvaluationResult> getValueSet() {
+		return this.valueSet;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.testExpression == null) || (this.valueSet == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.testExpression.evaluate(context);
+		return new EvaluationResult(Boolean.valueOf(this.valueSet
+				.contains(eval)), EvaluationResult.ResultType.BOOLEAN);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof InExpression)))
+			return false;
+		InExpression other = (InExpression) expr;
+		return ((this.testExpression == null) && (other.testExpression == null))
+				|| ((this.testExpression != null)
+						&& (this.testExpression.equals(other.testExpression)) && (((this.valueSet == null) && (other.valueSet == null)) || ((this.valueSet != null) && (this.valueSet
+						.equals(other.valueSet)))));
+	}
+
+	public int hashCode() {
+		int result = this.testExpression == null ? 1 : this.testExpression
+				.hashCode();
+		result = result * 31
+				+ (this.valueSet == null ? 1 : this.valueSet.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		String res = "in(" + this.testExpression.toString();
+		for (EvaluationResult value : this.valueSet) {
+			res = res + ", " + value.toString();
+		}
+		return res + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.testExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+		int count = in.readInt();
+		if (count < 0) {
+			this.valueSet = null;
+			return;
+		}
+		this.valueSet = new TreeSet<EvaluationResult>(
+				EvaluationResult.NULL_AS_MIN_COMPARATOR);
+		for (int i = 0; i < count; i++)
+			this.valueSet.add((EvaluationResult) HbaseObjectWritable
+					.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.testExpression,
+				this.testExpression.getClass(), null);
+		if (this.valueSet == null) {
+			out.writeInt(-1);
+			return;
+		}
+		out.writeInt(this.valueSet.size());
+		for (EvaluationResult value : this.valueSet)
+			HbaseObjectWritable.writeObject(out, value, value.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BOOLEAN;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/LogicalExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/LogicalExpression.java
new file mode 100644
index 0000000..2c84fc2
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/LogicalExpression.java
@@ -0,0 +1,135 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.Text;
+
+public class LogicalExpression implements Expression {
+	private LogicalOperator operator;
+	private Expression left;
+	private Expression right;
+
+	public LogicalExpression() {
+		this(LogicalOperator.NO_OP, null, null);
+	}
+
+	public LogicalExpression(LogicalOperator operator, Expression left,
+			Expression right) {
+		this.operator = operator;
+		this.left = left;
+		this.right = right;
+	}
+
+	public LogicalOperator getOperator() {
+		return this.operator;
+	}
+
+	public Expression getLeft() {
+		return this.left;
+	}
+
+	public Expression getRight() {
+		return this.right;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.operator == null) || (this.left == null)
+				|| (this.right == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		Boolean l = this.left.evaluate(context).asBoolean();
+		if (l == null) {
+			return new EvaluationResult();
+		}
+		EvaluationResult res = null;
+		switch (this.operator.ordinal()) {
+		case 1:
+			if (!l.booleanValue())
+				res = new EvaluationResult(l,
+						EvaluationResult.ResultType.BOOLEAN);
+			else {
+				res = this.right.evaluate(context);
+			}
+			break;
+		case 2:
+			if (l.booleanValue())
+				res = new EvaluationResult(l,
+						EvaluationResult.ResultType.BOOLEAN);
+			else {
+				res = this.right.evaluate(context);
+			}
+			break;
+		default:
+			throw new EvaluationException("Unsupported operator: "
+					+ this.operator);
+		}
+
+		return res;
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof LogicalExpression)))
+			return false;
+		LogicalExpression other = (LogicalExpression) expr;
+		boolean b = this.operator == other.operator;
+		if (b) {
+			if (this.left == null)
+				b = other.left == null;
+			else {
+				b = this.left.equals(other.left);
+			}
+		}
+		if (b) {
+			if (this.right == null)
+				b = other.right == null;
+			else {
+				b = this.right.equals(other.right);
+			}
+		}
+
+		return b;
+	}
+
+	public int hashCode() {
+		int result = this.operator == null ? 1 : this.operator.hashCode();
+		result = result * 31 + (this.left == null ? 1 : this.left.hashCode());
+		result = result * 31 + (this.right == null ? 1 : this.right.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return this.operator.toString().toLowerCase() + "("
+				+ this.left.toString() + ", " + this.right.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.operator = LogicalOperator.valueOf(Text.readString(in));
+		this.left = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.right = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		Text.writeString(out, this.operator.toString());
+		HbaseObjectWritable.writeObject(out, this.left, this.left.getClass(),
+				null);
+		HbaseObjectWritable.writeObject(out, this.right, this.right.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BOOLEAN;
+	}
+
+	public static enum LogicalOperator {
+		AND, OR, NO_OP;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/NotExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/NotExpression.java
new file mode 100644
index 0000000..72bbcbe
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/NotExpression.java
@@ -0,0 +1,71 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class NotExpression implements Expression {
+	private Expression subExpression;
+
+	public NotExpression() {
+	}
+
+	public NotExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		Boolean b = this.subExpression.evaluate(context).asBoolean();
+		if (b == null) {
+			return new EvaluationResult();
+		}
+		return new EvaluationResult(Boolean.valueOf(!b.booleanValue()),
+				EvaluationResult.ResultType.BOOLEAN);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof NotExpression)))
+			return false;
+		NotExpression other = (NotExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "not(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BOOLEAN;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/RowExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/RowExpression.java
new file mode 100644
index 0000000..9788e57
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/RowExpression.java
@@ -0,0 +1,39 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+
+public class RowExpression implements Expression {
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		return new EvaluationResult(context.getRow(),
+				EvaluationResult.ResultType.BYTESREFERENCE);
+	}
+
+	public boolean equals(Object expr) {
+		return (expr != null) && ((expr instanceof RowExpression));
+	}
+
+	public int hashCode() {
+		return 1;
+	}
+
+	public String toString() {
+		return "row()";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+	}
+
+	public void write(DataOutput out) throws IOException {
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BYTESREFERENCE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/StringConcatExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/StringConcatExpression.java
new file mode 100644
index 0000000..8c89cf3
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/StringConcatExpression.java
@@ -0,0 +1,119 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class StringConcatExpression implements Expression {
+	private Expression[] parts;
+
+	public StringConcatExpression() {
+	}
+
+	public StringConcatExpression(Expression[] parts) {
+		this.parts = parts;
+	}
+
+	public StringConcatExpression(List<Expression> parts) {
+		if (parts != null) {
+			this.parts = new Expression[parts.size()];
+			for (int i = 0; i < parts.size(); i++)
+				this.parts[i] = ((Expression) parts.get(i));
+		}
+	}
+
+	public Expression[] getParts() {
+		return this.parts;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.parts == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		StringBuffer sb = new StringBuffer();
+		for (int i = 0; i < this.parts.length; i++) {
+			if (this.parts[i] == null) {
+				throw new EvaluationException("Missing required arguments");
+			}
+			String s = this.parts[i].evaluate(context).asString();
+			sb.append(s);
+		}
+
+		return new EvaluationResult(sb.toString(),
+				EvaluationResult.ResultType.STRING);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof StringConcatExpression)))
+			return false;
+		StringConcatExpression other = (StringConcatExpression) expr;
+		if ((this.parts == null) && (other.parts == null))
+			return true;
+		if (((this.parts == null) && (other.parts != null))
+				|| ((this.parts != null) && (other.parts == null))
+				|| (this.parts.length != other.parts.length)) {
+			return false;
+		}
+		for (int i = 0; i < this.parts.length; i++) {
+			if (!this.parts[i].equals(other.parts[i]))
+				return false;
+		}
+		return true;
+	}
+
+	public int hashCode() {
+		if (this.parts == null)
+			return 1;
+		int result = 11;
+		for (int i = 0; i < this.parts.length; i++) {
+			result = result * 31
+					+ (this.parts[i] == null ? 1 : this.parts[i].hashCode());
+		}
+		return result;
+	}
+
+	public String toString() {
+		String res = "stringConcat(";
+		for (int i = 0; i < this.parts.length; i++) {
+			res = new StringBuilder().append(res).append(i > 0 ? ", " : "")
+					.append(this.parts[i].toString()).toString();
+		}
+		return new StringBuilder().append(res).append(")").toString();
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		int count = in.readInt();
+		if (count < 0) {
+			this.parts = null;
+			return;
+		}
+		this.parts = new Expression[count];
+		for (int i = 0; i < count; i++)
+			this.parts[i] = ((Expression) HbaseObjectWritable.readObject(in,
+					null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		if (this.parts == null) {
+			out.writeInt(-1);
+			return;
+		}
+		out.writeInt(this.parts.length);
+		for (int i = 0; i < this.parts.length; i++)
+			HbaseObjectWritable.writeObject(out, this.parts[i],
+					this.parts[i].getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.STRING;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/StringMatchExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/StringMatchExpression.java
new file mode 100644
index 0000000..7aa7777
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/StringMatchExpression.java
@@ -0,0 +1,100 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.regex.Pattern;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.Text;
+
+public class StringMatchExpression implements Expression {
+	private Expression matchExpression;
+	private String regex;
+	private Pattern pattern;
+
+	public StringMatchExpression() {
+	}
+
+	public StringMatchExpression(Expression matchExpression, String regex) {
+		this.matchExpression = matchExpression;
+		this.regex = regex;
+		this.pattern = Pattern.compile(regex);
+	}
+
+	public Expression getMatchExpression() {
+		return this.matchExpression;
+	}
+
+	public String getRegex() {
+		return this.regex;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.matchExpression == null) || (this.regex == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		String s = this.matchExpression.evaluate(context).asString();
+		if (s == null) {
+			return new EvaluationResult();
+		}
+		return new EvaluationResult(Boolean.valueOf(this.pattern.matcher(s)
+				.matches()), EvaluationResult.ResultType.BOOLEAN);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof StringMatchExpression)))
+			return false;
+		StringMatchExpression other = (StringMatchExpression) expr;
+		return ((this.matchExpression == null) && (other.matchExpression == null))
+				|| ((this.matchExpression != null)
+						&& (this.matchExpression.equals(other.matchExpression)) && (((this.regex == null) && (other.regex == null)) || ((this.regex != null) && (this.regex
+						.equals(other.regex)))));
+	}
+
+	public int hashCode() {
+		int result = this.matchExpression == null ? 1 : this.matchExpression
+				.hashCode();
+		result = result * 31 + (this.regex == null ? 1 : this.regex.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return "stringMatch(" + this.matchExpression.toString() + ", "
+				+ this.regex + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.matchExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+		boolean notNull = in.readBoolean();
+		if (notNull) {
+			this.regex = Text.readString(in);
+			this.pattern = Pattern.compile(this.regex);
+		} else {
+			this.regex = null;
+			this.pattern = null;
+		}
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.matchExpression,
+				this.matchExpression.getClass(), null);
+		if (this.regex == null) {
+			out.writeBoolean(false);
+		} else {
+			out.writeBoolean(true);
+			Text.writeString(out, this.regex);
+		}
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BOOLEAN;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/StringPartExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/StringPartExpression.java
new file mode 100644
index 0000000..21f5748
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/StringPartExpression.java
@@ -0,0 +1,165 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.Text;
+
+public class StringPartExpression implements Expression {
+	private Expression source;
+	private String delimiter;
+	private Expression index;
+
+	public StringPartExpression() {
+	}
+
+	public StringPartExpression(Expression source, String delimiter, int index) {
+		this(source, delimiter, new ConstantExpression(Integer.valueOf(index)));
+	}
+
+	public StringPartExpression(Expression source, String delimiter,
+			Expression index) {
+		this.source = source;
+		this.delimiter = delimiter;
+		this.index = index;
+	}
+
+	public Expression getSource() {
+		return this.source;
+	}
+
+	public String getDelimiter() {
+		return this.delimiter;
+	}
+
+	public Expression getIndex() {
+		return this.index;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.source == null) || (this.delimiter == null)
+				|| (this.delimiter.isEmpty()) || (this.index == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		String s = this.source.evaluate(context).asString();
+		Integer i = this.index.evaluate(context).asInteger();
+		if ((s == null) || (i == null)) {
+			return new EvaluationResult();
+		}
+		if (i.intValue() < 0) {
+			throw new EvaluationException(
+					"Could not evaluate StringPartExpression(" + s + ",\""
+							+ this.delimiter + "\"," + i + ")");
+		}
+
+		String result = seek(s, i.intValue(), this.delimiter);
+
+		if (result == null) {
+			throw new EvaluationException(
+					"Could not evaluate StringPartExpression(" + s + ",\""
+							+ this.delimiter + "\"," + i + ")");
+		}
+
+		return new EvaluationResult(result, EvaluationResult.ResultType.STRING);
+	}
+
+	private static String seek(String s, int index, String seperator) {
+		int offset = 0;
+		int length = s.length();
+
+		int count = 0;
+		int start = -1;
+		char delimeter = seperator.charAt(0);
+
+		if (index == 0) {
+			start = 0;
+		} else {
+			for (int i = offset; i < length; i++) {
+				if (delimeter == s.charAt(i)) {
+					count++;
+					if (count == index) {
+						start = i + 1;
+						break;
+					}
+				}
+			}
+		}
+
+		if (-1 == start) {
+			return null;
+		}
+
+		int end = -1;
+		for (int i = start; i < length; i++) {
+			if ((delimeter != s.charAt(i)) || (count != index))
+				continue;
+			end = i;
+			break;
+		}
+
+		if (end == -1) {
+			end = length;
+		}
+
+		return s.substring(start, end);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof StringPartExpression)))
+			return false;
+		StringPartExpression other = (StringPartExpression) expr;
+		return ((this.source == null) && (other.source == null))
+				|| ((this.source != null) && (this.source.equals(other.source)) && (((this.delimiter == null) && (other.delimiter == null)) || ((this.delimiter != null)
+						&& (this.delimiter.equals(other.delimiter)) && (((this.index == null) && (other.index == null)) || ((this.index != null) && (this.index
+						.equals(other.index)))))));
+	}
+
+	public int hashCode() {
+		int result = this.source == null ? 1 : this.source.hashCode();
+		result = result * 31
+				+ (this.delimiter == null ? 1 : this.delimiter.hashCode());
+		result = result * 31 + (this.index == null ? 1 : this.index.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return "stringPart(" + this.source.toString() + ", " + this.delimiter
+				+ ", " + this.index.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.source = ((Expression) HbaseObjectWritable.readObject(in, null));
+		boolean notNull = in.readBoolean();
+		if (notNull)
+			this.delimiter = Text.readString(in);
+		else {
+			this.delimiter = null;
+		}
+		this.index = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.source,
+				this.source.getClass(), null);
+		if (this.delimiter == null) {
+			out.writeBoolean(false);
+		} else {
+			out.writeBoolean(true);
+			Text.writeString(out, this.delimiter);
+		}
+		HbaseObjectWritable.writeObject(out, this.index, this.index.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.STRING;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/StringReverseExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/StringReverseExpression.java
new file mode 100644
index 0000000..b79d38b
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/StringReverseExpression.java
@@ -0,0 +1,73 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class StringReverseExpression implements Expression {
+	private Expression subExpression;
+
+	public StringReverseExpression() {
+	}
+
+	public StringReverseExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		String s = this.subExpression.evaluate(context).asString();
+		StringBuilder sb = new StringBuilder();
+		for (int i = s.length() - 1; i > -1; i--) {
+			sb.append(s.charAt(i));
+		}
+		return new EvaluationResult(sb.toString(),
+				EvaluationResult.ResultType.STRING);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof StringReverseExpression)))
+			return false;
+		StringReverseExpression other = (StringReverseExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return new StringBuilder().append("stringReverse(")
+				.append(this.subExpression.toString()).append(")").toString();
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.STRING;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/SubSequenceExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/SubSequenceExpression.java
new file mode 100644
index 0000000..b293722
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/SubSequenceExpression.java
@@ -0,0 +1,138 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.NullWritable;
+
+public class SubSequenceExpression implements Expression {
+	private Expression source;
+	private Expression start;
+	private Expression end;
+
+	public SubSequenceExpression() {
+	}
+
+	public SubSequenceExpression(Expression source, int start) {
+		this(source, new ConstantExpression(Integer.valueOf(start)), null);
+	}
+
+	public SubSequenceExpression(Expression source, int start, int end) {
+		this(source, new ConstantExpression(Integer.valueOf(start)),
+				new ConstantExpression(Integer.valueOf(end)));
+	}
+
+	public SubSequenceExpression(Expression source, Expression start) {
+		this(source, start, null);
+	}
+
+	public SubSequenceExpression(Expression source, Expression start,
+			Expression end) {
+		this.source = source;
+		this.start = start;
+		this.end = end;
+	}
+
+	public Expression getSource() {
+		return this.source;
+	}
+
+	public Expression getStart() {
+		return this.start;
+	}
+
+	public Expression getEnd() {
+		return this.end;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.source == null) || (this.start == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.source.evaluate(context);
+		BytesReference ref = eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE ? eval
+				.asBytesReference() : null;
+		byte[] s = eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE ? ref
+				.getReference() : eval.asBytes();
+		Integer st = this.start.evaluate(context).asInteger();
+		Integer e = this.end == null ? null : this.end.evaluate(context)
+				.asInteger();
+		if ((s == null) || (st == null)) {
+			return new EvaluationResult();
+		}
+		int o = eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE ? ref
+				.getOffset() : 0;
+		int l = eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE ? ref
+				.getLength() : s.length;
+		int len = e == null ? l - st.intValue() : e.intValue() - st.intValue();
+
+		if ((st.intValue() < 0) || (len < 0) || (l < st.intValue() + len)) {
+			throw new EvaluationException(new StringBuilder()
+					.append("Could not evaluate SubSequenceExpression(")
+					.append(Bytes.toString(s)).append(",").append(st)
+					.append(",").append(e).append(")").toString());
+		}
+
+		byte[] res = new byte[len];
+		System.arraycopy(s, st.intValue() + o, res, 0, len);
+		return new EvaluationResult(res, EvaluationResult.ResultType.BYTEARRAY);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof SubSequenceExpression)))
+			return false;
+		SubSequenceExpression other = (SubSequenceExpression) expr;
+		return ((this.source == null) && (other.source == null))
+				|| ((this.source != null) && (this.source.equals(other.source)) && (((this.start == null) && (other.start == null)) || ((this.start != null)
+						&& (this.start.equals(other.start)) && (((this.end == null) && (other.end == null)) || ((this.end != null) && (this.end
+						.equals(other.end)))))));
+	}
+
+	public int hashCode() {
+		int result = this.source == null ? 1 : this.source.hashCode();
+		result = result * 31 + (this.start == null ? 1 : this.start.hashCode());
+		result = result * 31 + (this.end == null ? 1 : this.end.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return new StringBuilder()
+				.append("subSequence(")
+				.append(this.source.toString())
+				.append(", ")
+				.append(this.start.toString())
+				.append(this.end == null ? "" : new StringBuilder()
+						.append(", ").append(this.end.toString()).toString())
+				.append(")").toString();
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.source = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.start = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.end = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.source,
+				this.source.getClass(), null);
+		HbaseObjectWritable.writeObject(out, this.start, this.start.getClass(),
+				null);
+		HbaseObjectWritable.writeObject(out, this.end,
+				this.end == null ? NullWritable.class : this.end.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BYTEARRAY;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/SubstringExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/SubstringExpression.java
new file mode 100644
index 0000000..97f5725
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/SubstringExpression.java
@@ -0,0 +1,133 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.io.NullWritable;
+
+public class SubstringExpression implements Expression {
+	private Expression source;
+	private Expression start;
+	private Expression end;
+
+	public SubstringExpression() {
+	}
+
+	public SubstringExpression(Expression source, int start) {
+		this(source, new ConstantExpression(Integer.valueOf(start)), null);
+	}
+
+	public SubstringExpression(Expression source, int start, int end) {
+		this(source, new ConstantExpression(Integer.valueOf(start)),
+				new ConstantExpression(Integer.valueOf(end)));
+	}
+
+	public SubstringExpression(Expression source, Expression start) {
+		this(source, start, null);
+	}
+
+	public SubstringExpression(Expression source, Expression start,
+			Expression end) {
+		this.source = source;
+		this.start = start;
+		this.end = end;
+	}
+
+	public Expression getSource() {
+		return this.source;
+	}
+
+	public Expression getStart() {
+		return this.start;
+	}
+
+	public Expression getEnd() {
+		return this.end;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.source == null) || (this.start == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		String s = this.source.evaluate(context).asString();
+		Integer st = this.start.evaluate(context).asInteger();
+		Integer e = this.end == null ? null : this.end.evaluate(context)
+				.asInteger();
+		if ((s == null) || (st == null)) {
+			return new EvaluationResult();
+		}
+		int len = e == null ? s.length() - st.intValue() : e.intValue()
+				- st.intValue();
+
+		if ((st.intValue() < 0) || (len < 0)
+				|| (s.length() < st.intValue() + len)) {
+			throw new EvaluationException(new StringBuilder()
+					.append("Could not evaluate SubstringExpression(")
+					.append(s).append(",").append(st).append(",").append(e)
+					.append(")").toString());
+		}
+
+		if (e == null) {
+			return new EvaluationResult(s.substring(st.intValue()),
+					EvaluationResult.ResultType.STRING);
+		}
+		return new EvaluationResult(s.substring(st.intValue(), e.intValue()),
+				EvaluationResult.ResultType.STRING);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof SubstringExpression)))
+			return false;
+		SubstringExpression other = (SubstringExpression) expr;
+		return ((this.source == null) && (other.source == null))
+				|| ((this.source != null) && (this.source.equals(other.source)) && (((this.start == null) && (other.start == null)) || ((this.start != null)
+						&& (this.start.equals(other.start)) && (((this.end == null) && (other.end == null)) || ((this.end != null) && (this.end
+						.equals(other.end)))))));
+	}
+
+	public int hashCode() {
+		int result = this.source == null ? 1 : this.source.hashCode();
+		result = result * 31 + (this.start == null ? 1 : this.start.hashCode());
+		result = result * 31 + (this.end == null ? 1 : this.end.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return new StringBuilder()
+				.append("subString(")
+				.append(this.source.toString())
+				.append(", ")
+				.append(this.start.toString())
+				.append(this.end == null ? "" : new StringBuilder()
+						.append(", ").append(this.end.toString()).toString())
+				.append(")").toString();
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.source = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.start = ((Expression) HbaseObjectWritable.readObject(in, null));
+		this.end = ((Expression) HbaseObjectWritable.readObject(in, null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.source,
+				this.source.getClass(), null);
+		HbaseObjectWritable.writeObject(out, this.start, this.start.getClass(),
+				null);
+		HbaseObjectWritable.writeObject(out, this.end,
+				this.end == null ? NullWritable.class : this.end.getClass(),
+				null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.STRING;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/TernaryExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/TernaryExpression.java
new file mode 100644
index 0000000..16cc022
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/TernaryExpression.java
@@ -0,0 +1,114 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class TernaryExpression implements Expression {
+	private Expression condExpression;
+	private Expression trueExpression;
+	private Expression falseExpression;
+
+	public TernaryExpression() {
+	}
+
+	public TernaryExpression(Expression condExpression,
+			Expression trueExpression, Expression falseExpression) {
+		this.condExpression = condExpression;
+		this.trueExpression = trueExpression;
+		this.falseExpression = falseExpression;
+	}
+
+	public Expression getCondExpression() {
+		return this.condExpression;
+	}
+
+	public Expression getTrueExpression() {
+		return this.trueExpression;
+	}
+
+	public Expression getFalseExpression() {
+		return this.falseExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if ((this.condExpression == null) || (this.trueExpression == null)
+				|| (this.falseExpression == null)) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		Boolean cond = this.condExpression.evaluate(context).asBoolean();
+		if (cond == null) {
+			return new EvaluationResult();
+		}
+		return cond.booleanValue() ? this.trueExpression.evaluate(context)
+				: this.falseExpression.evaluate(context);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof TernaryExpression)))
+			return false;
+		TernaryExpression other = (TernaryExpression) expr;
+		return ((this.condExpression == null) && (other.condExpression == null))
+				|| ((this.condExpression != null)
+						&& (this.condExpression.equals(other.condExpression)) && (((this.trueExpression == null) && (other.trueExpression == null)) || ((this.trueExpression != null)
+						&& (this.trueExpression.equals(other.trueExpression)) && (((this.falseExpression == null) && (other.falseExpression == null)) || ((this.falseExpression != null) && (this.falseExpression
+						.equals(other.falseExpression)))))));
+	}
+
+	public int hashCode() {
+		int result = this.condExpression == null ? 1 : this.condExpression
+				.hashCode();
+		result = result
+				* 31
+				+ (this.trueExpression == null ? 1 : this.trueExpression
+						.hashCode());
+		result = result
+				* 31
+				+ (this.falseExpression == null ? 1 : this.falseExpression
+						.hashCode());
+		return result;
+	}
+
+	public String toString() {
+		return "if(" + this.condExpression.toString() + ") then ("
+				+ this.trueExpression.toString() + ") else ("
+				+ this.falseExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.condExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+		this.trueExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+		this.falseExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.condExpression,
+				this.condExpression.getClass(), null);
+		HbaseObjectWritable.writeObject(out, this.trueExpression,
+				this.trueExpression.getClass(), null);
+		HbaseObjectWritable.writeObject(out, this.falseExpression,
+				this.falseExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		EvaluationResult.ResultType trueType = this.trueExpression == null ? EvaluationResult.ResultType.UNKNOWN
+				: this.trueExpression.getReturnType();
+		EvaluationResult.ResultType falseType = this.falseExpression == null ? EvaluationResult.ResultType.UNKNOWN
+				: this.falseExpression.getReturnType();
+		return falseType == EvaluationResult.ResultType.UNKNOWN ? trueType
+				: trueType == EvaluationResult.ResultType.UNKNOWN ? falseType
+						: EvaluationResult
+								.getMaxResultType(trueType, falseType);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToBigDecimalExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToBigDecimalExpression.java
new file mode 100644
index 0000000..e41a1ff
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToBigDecimalExpression.java
@@ -0,0 +1,94 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.math.BigDecimal;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToBigDecimalExpression implements Expression {
+	private Expression subExpression;
+
+	public ToBigDecimalExpression() {
+	}
+
+	public ToBigDecimalExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		BigDecimal res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asBigDecimal();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				res = Bytes.toBigDecimal(eval.asBytes());
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				res = Bytes.toBigDecimal(ref.getReference(), ref.getOffset(),
+						ref.getLength());
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						BigDecimal.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), BigDecimal.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.BIGDECIMAL);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToBigDecimalExpression)))
+			return false;
+		ToBigDecimalExpression other = (ToBigDecimalExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toBigDecimal(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BIGDECIMAL;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToBooleanExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToBooleanExpression.java
new file mode 100644
index 0000000..9108913
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToBooleanExpression.java
@@ -0,0 +1,93 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToBooleanExpression implements Expression {
+	private Expression subExpression;
+
+	public ToBooleanExpression() {
+	}
+
+	public ToBooleanExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Boolean res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BOOLEAN) {
+				res = eval.asBoolean();
+			} else if ((eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY)
+					|| (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE)) {
+				byte[] b = eval.asBytes();
+				res = Boolean.valueOf(b.length == 0 ? false : Bytes
+						.toBoolean(b));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				res = Boolean.valueOf(eval.asString());
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Boolean.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Boolean.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.BOOLEAN);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToBooleanExpression)))
+			return false;
+		ToBooleanExpression other = (ToBooleanExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toBoolean(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BOOLEAN;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToByteExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToByteExpression.java
new file mode 100644
index 0000000..343ea1a
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToByteExpression.java
@@ -0,0 +1,100 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class ToByteExpression implements Expression {
+	private Expression subExpression;
+
+	public ToByteExpression() {
+	}
+
+	public ToByteExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Byte res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asByte();
+			} else if ((eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY)
+					|| (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE)) {
+				byte[] b = eval.asBytes();
+				if ((b.length == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Byte.valueOf(b[0]);
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				String str = eval.asString();
+				if ((str.isEmpty())
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Byte.valueOf(str);
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Byte.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Byte.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.BYTE);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToByteExpression)))
+			return false;
+		ToByteExpression other = (ToByteExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toByte(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BYTE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToBytesExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToBytesExpression.java
new file mode 100644
index 0000000..3a6c925
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToBytesExpression.java
@@ -0,0 +1,120 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToBytesExpression implements Expression {
+	private Expression subExpression;
+
+	public ToBytesExpression() {
+	}
+
+	public ToBytesExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		if (eval.isNullResult()) {
+			return new EvaluationResult();
+		}
+		byte[] res = null;
+		try {
+			switch (eval.getResultType().ordinal()) {
+			case 1:
+			case 2:
+				res = eval.asBytes();
+				break;
+			case 3:
+				res = new byte[] { eval.asByte().byteValue() };
+				break;
+			case 4:
+				res = Bytes.toBytes(eval.asBigDecimal());
+				break;
+			case 5:
+				res = Bytes.toBytes(eval.asBigDecimal());
+				break;
+			case 6:
+				res = Bytes.toBytes(eval.asBoolean().booleanValue());
+				break;
+			case 7:
+				res = Bytes.toBytes(eval.asDouble().doubleValue());
+				break;
+			case 8:
+				res = Bytes.toBytes(eval.asFloat().floatValue());
+				break;
+			case 9:
+				res = Bytes.toBytes(eval.asInteger().intValue());
+				break;
+			case 10:
+				res = Bytes.toBytes(eval.asLong().longValue());
+				break;
+			case 11:
+				res = Bytes.toBytes(eval.asShort().shortValue());
+				break;
+			case 12:
+				res = Bytes.toBytes(eval.asString());
+				break;
+			default:
+				throw new TypeConversionException(eval.getResultType(),
+						byte[].class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), byte[].class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.BYTEARRAY);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToBytesExpression)))
+			return false;
+		ToBytesExpression other = (ToBytesExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toBytes(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.BYTEARRAY;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToDoubleExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToDoubleExpression.java
new file mode 100644
index 0000000..af8be9a
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToDoubleExpression.java
@@ -0,0 +1,109 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToDoubleExpression implements Expression {
+	private Expression subExpression;
+
+	public ToDoubleExpression() {
+	}
+
+	public ToDoubleExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Double res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asDouble();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				byte[] b = eval.asBytes();
+				if ((b.length == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Double.valueOf(Bytes.toDouble(b));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				if ((ref.getLength() == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Double.valueOf(Bytes.toDouble(ref.getReference(),
+							ref.getOffset()));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				String str = eval.asString();
+				if ((str.isEmpty())
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Double.valueOf(str);
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Double.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Double.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.DOUBLE);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToDoubleExpression)))
+			return false;
+		ToDoubleExpression other = (ToDoubleExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toDouble(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.DOUBLE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToFloatExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToFloatExpression.java
new file mode 100644
index 0000000..177b639
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToFloatExpression.java
@@ -0,0 +1,109 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToFloatExpression implements Expression {
+	private Expression subExpression;
+
+	public ToFloatExpression() {
+	}
+
+	public ToFloatExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Float res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asFloat();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				byte[] b = eval.asBytes();
+				if ((b.length == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Float.valueOf(Bytes.toFloat(b));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				if ((ref.getLength() == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Float.valueOf(Bytes.toFloat(ref.getReference(),
+							ref.getOffset()));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				String str = eval.asString();
+				if ((str.isEmpty())
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Float.valueOf(str);
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Float.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Float.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.FLOAT);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToFloatExpression)))
+			return false;
+		ToFloatExpression other = (ToFloatExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toFloat(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.FLOAT;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToIntegerExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToIntegerExpression.java
new file mode 100644
index 0000000..8cb4758
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToIntegerExpression.java
@@ -0,0 +1,109 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToIntegerExpression implements Expression {
+	private Expression subExpression;
+
+	public ToIntegerExpression() {
+	}
+
+	public ToIntegerExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Integer res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asInteger();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				byte[] b = eval.asBytes();
+				if ((b.length == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Integer.valueOf(Bytes.toInt(b));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				if ((ref.getLength() == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Integer.valueOf(Bytes.toInt(ref.getReference(),
+							ref.getOffset(), ref.getLength()));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				String str = eval.asString();
+				if ((str.isEmpty())
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Integer.valueOf(str);
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Integer.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Integer.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.INTEGER);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToIntegerExpression)))
+			return false;
+		ToIntegerExpression other = (ToIntegerExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toInteger(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.INTEGER;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToLongExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToLongExpression.java
new file mode 100644
index 0000000..d9c7422
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToLongExpression.java
@@ -0,0 +1,109 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToLongExpression implements Expression {
+	private Expression subExpression;
+
+	public ToLongExpression() {
+	}
+
+	public ToLongExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Long res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asLong();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				byte[] b = eval.asBytes();
+				if ((b.length == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Long.valueOf(Bytes.toLong(b));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				if ((ref.getLength() == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Long.valueOf(Bytes.toLong(ref.getReference(),
+							ref.getOffset(), ref.getLength()));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				String str = eval.asString();
+				if ((str.isEmpty())
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Long.valueOf(str);
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Long.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Long.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.LONG);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToLongExpression)))
+			return false;
+		ToLongExpression other = (ToLongExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toLong(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.LONG;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToShortExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToShortExpression.java
new file mode 100644
index 0000000..c58229d
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToShortExpression.java
@@ -0,0 +1,109 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToShortExpression implements Expression {
+	private Expression subExpression;
+
+	public ToShortExpression() {
+	}
+
+	public ToShortExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		Short res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.isNumber()) {
+				res = eval.asShort();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				byte[] b = eval.asBytes();
+				if ((b.length == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Short.valueOf(Bytes.toShort(b));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				if ((ref.getLength() == 0)
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Short.valueOf(Bytes.toShort(ref.getReference(),
+							ref.getOffset(), ref.getLength()));
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				String str = eval.asString();
+				if ((str.isEmpty())
+						&& (context.getCompatibilityMode() == EvaluationContext.CompatibilityMode.HIVE))
+					res = null;
+				else
+					res = Short.valueOf(str);
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						Short.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), Short.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.SHORT);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToShortExpression)))
+			return false;
+		ToShortExpression other = (ToShortExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toShort(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.SHORT;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/ToStringExpression.java b/src/main/java/org/apache/hadoop/hbase/expression/ToStringExpression.java
new file mode 100644
index 0000000..adffac5
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/ToStringExpression.java
@@ -0,0 +1,99 @@
+package org.apache.hadoop.hbase.expression;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.expression.evaluation.BytesReference;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationException;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.expression.evaluation.TypeConversionException;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ToStringExpression implements Expression {
+	private Expression subExpression;
+
+	public ToStringExpression() {
+	}
+
+	public ToStringExpression(Expression subExpression) {
+		this.subExpression = subExpression;
+	}
+
+	public Expression getSubExpression() {
+		return this.subExpression;
+	}
+
+	public EvaluationResult evaluate(EvaluationContext context)
+			throws EvaluationException {
+		if (this.subExpression == null) {
+			throw new EvaluationException("Missing required arguments");
+		}
+		EvaluationResult eval = this.subExpression.evaluate(context);
+		String res = null;
+		try {
+			if (eval.isNullResult()) {
+				res = null;
+			} else if (eval.getResultType() == EvaluationResult.ResultType.STRING) {
+				res = eval.asString();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BIGDECIMAL) {
+				res = eval.asBigDecimal().toPlainString();
+			} else if (eval.isNumber()) {
+				res = eval.asNumber().toString();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BOOLEAN) {
+				res = eval.asBoolean().toString();
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTEARRAY) {
+				res = Bytes.toString(eval.asBytes());
+			} else if (eval.getResultType() == EvaluationResult.ResultType.BYTESREFERENCE) {
+				BytesReference ref = eval.asBytesReference();
+				res = Bytes.toString(ref.getReference(), ref.getOffset(),
+						ref.getLength());
+			} else {
+				throw new TypeConversionException(eval.getResultType(),
+						String.class);
+			}
+		} catch (Throwable t) {
+			if ((t instanceof EvaluationException))
+				throw ((EvaluationException) t);
+			throw ((EvaluationException) new TypeConversionException(
+					eval.getResultType(), String.class).initCause(t));
+		}
+
+		return new EvaluationResult(res, EvaluationResult.ResultType.STRING);
+	}
+
+	public boolean equals(Object expr) {
+		if (this == expr)
+			return true;
+		if ((expr == null) || (!(expr instanceof ToStringExpression)))
+			return false;
+		ToStringExpression other = (ToStringExpression) expr;
+		return ((this.subExpression == null) && (other.subExpression == null))
+				|| ((this.subExpression != null) && (this.subExpression
+						.equals(other.subExpression)));
+	}
+
+	public int hashCode() {
+		return this.subExpression == null ? 1 : this.subExpression.hashCode();
+	}
+
+	public String toString() {
+		return "toString(" + this.subExpression.toString() + ")";
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.subExpression = ((Expression) HbaseObjectWritable.readObject(in,
+				null));
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.subExpression,
+				this.subExpression.getClass(), null);
+	}
+
+	public EvaluationResult.ResultType getReturnType() {
+		return EvaluationResult.ResultType.STRING;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/BytesReference.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/BytesReference.java
new file mode 100644
index 0000000..e0ebf30
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/BytesReference.java
@@ -0,0 +1,60 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class BytesReference implements Comparable<BytesReference> {
+	private final byte[] reference;
+	private final int offset;
+	private final int length;
+
+	public BytesReference(byte[] reference, int offset, int length) {
+		this.reference = reference;
+		this.offset = offset;
+		this.length = length;
+	}
+
+	public byte[] getReference() {
+		return this.reference;
+	}
+
+	public int getOffset() {
+		return this.offset;
+	}
+
+	public int getLength() {
+		return this.length;
+	}
+
+	public byte[] toBytes() {
+		byte[] res = new byte[this.length];
+		System.arraycopy(this.reference, this.offset, res, 0, this.length);
+		return res;
+	}
+
+	public boolean equals(Object arg) {
+		if ((arg == null) || (!(arg instanceof BytesReference))) {
+			return false;
+		}
+		BytesReference other = (BytesReference) arg;
+		return (Bytes.equals(this.reference, other.reference))
+				&& (this.offset == other.offset)
+				&& (this.length == other.length);
+	}
+
+	public int hashCode() {
+		if (this.reference == null) {
+			return 1;
+		}
+		return Bytes.hashCode(this.reference, this.offset, this.length);
+	}
+
+	public int compareTo(BytesReference other) {
+		if (this.reference == null)
+			return other.reference == null ? 0 : -1;
+		if (other.reference == null) {
+			return 1;
+		}
+		return Bytes.compareTo(this.reference, this.offset, this.length,
+				other.reference, other.offset, other.length);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationContext.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationContext.java
new file mode 100644
index 0000000..6c90f70
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationContext.java
@@ -0,0 +1,121 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+import java.util.Iterator;
+import java.util.List;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.coprocessor.GroupByCombinedKey;
+
+public class EvaluationContext {
+	private CompatibilityMode mode;
+	private List<KeyValue> currentRow;
+	private GroupByCombinedKey groupByKey;
+	private List<StatsValue> groupByStats;
+
+	public EvaluationContext() {
+		this(CompatibilityMode.HIVE);
+	}
+
+	public EvaluationContext(Configuration conf) {
+		this(CompatibilityMode.valueOfWithDefault(
+				conf.get("sql.compatibility.mode"), CompatibilityMode.HIVE));
+	}
+
+	public EvaluationContext(CompatibilityMode mode) {
+		this.mode = mode;
+	}
+
+	public void setCurrentRow(List<KeyValue> currentRow) {
+		this.currentRow = currentRow;
+	}
+
+	public void setAggregationValues(GroupByCombinedKey groupByKey,
+			List<StatsValue> groupByStats) {
+		this.groupByKey = groupByKey;
+		this.groupByStats = groupByStats;
+	}
+
+	public void clearAll() {
+		this.currentRow = null;
+		this.groupByKey = null;
+		this.groupByStats = null;
+	}
+
+	public CompatibilityMode getCompatibilityMode() {
+		return this.mode;
+	}
+
+	public BytesReference getRow() {
+		if (this.currentRow == null) {
+			return null;
+		}
+		BytesReference found = null;
+		Iterator<KeyValue> i$ = this.currentRow.iterator();
+		if (i$.hasNext()) {
+			KeyValue kv = (KeyValue) i$.next();
+			found = new BytesReference(kv.getBuffer(), kv.getRowOffset(),
+					kv.getRowLength());
+		}
+
+		return found;
+	}
+
+	public BytesReference getColumnValue(byte[] family, byte[] qualifier)
+			throws EvaluationException {
+		if (this.currentRow == null) {
+			return null;
+		}
+		BytesReference found = null;
+		for (KeyValue kv : this.currentRow) {
+			if (kv.matchingColumn(family, qualifier)) {
+				found = new BytesReference(kv.getBuffer(), kv.getValueOffset(),
+						kv.getValueLength());
+
+				break;
+			}
+		}
+
+		return found;
+	}
+
+	public EvaluationResult getGroupByKey(int index) throws EvaluationException {
+		if (this.groupByKey == null) {
+			throw new ValueNotAvailableException(
+					"Group-by result not available");
+		}
+		EvaluationResult[] keys = this.groupByKey.getKeys();
+
+		if ((index < 0) || (index >= keys.length)) {
+			throw new ValueNotAvailableException("Invalid group-by key index: "
+					+ index);
+		}
+		return keys[index];
+	}
+
+	public StatsValue getGroupByStatsValue(int index)
+			throws EvaluationException {
+		if (this.groupByStats == null) {
+			throw new ValueNotAvailableException(
+					"Group-by result not available");
+		}
+		if ((index < 0) || (index >= this.groupByStats.size())) {
+			throw new ValueNotAvailableException(
+					"Invalid group-by stats value index: " + index);
+		}
+		return (StatsValue) this.groupByStats.get(index);
+	}
+
+	public static enum CompatibilityMode {
+		HIVE, ORACLE, SQLSERVER;
+
+		public static CompatibilityMode valueOfWithDefault(String strValue,
+				CompatibilityMode defaultValue) {
+			try {
+				return strValue == null ? defaultValue : valueOf(strValue
+						.toUpperCase());
+			} catch (Exception e) {
+			}
+			return defaultValue;
+		}
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationException.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationException.java
new file mode 100644
index 0000000..78f367c
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationException.java
@@ -0,0 +1,14 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+import org.apache.hadoop.hbase.expression.ExpressionException;
+
+public class EvaluationException extends ExpressionException {
+	/**
+	 * 
+	 */
+	private static final long serialVersionUID = 3938543899736724947L;
+
+	public EvaluationException(String msg) {
+		super(msg);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationResult.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationResult.java
new file mode 100644
index 0000000..84fb750
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/EvaluationResult.java
@@ -0,0 +1,711 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.io.Serializable;
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.util.Comparator;
+
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.Writable;
+
+public class EvaluationResult implements Writable, Serializable {
+	/**
+	 * 
+	 */
+	private static final long serialVersionUID = 1L;
+
+	public static final Comparator<EvaluationResult> NATURAL_COMPARATOR = new Comparator<EvaluationResult>() {
+		public int compare(EvaluationResult left, EvaluationResult right) {
+			try {
+				return EvaluationResult.compare(left, right);
+			} catch (EvaluationException e) {
+				throw new RuntimeException("Error occurred in comparison", e);
+
+			}
+		}
+	};
+
+	public static final Comparator<EvaluationResult> NULL_AS_MIN_COMPARATOR = new Comparator<EvaluationResult>() {
+		public int compare(EvaluationResult left, EvaluationResult right) {
+			try {
+				return right.isNullResult() ? 1 : left.isNullResult() ? -1
+						: right.isNullResult() ? 0 : EvaluationResult.compare(
+								left, right);
+			} catch (EvaluationException e) {
+				throw new RuntimeException("Error occurred in comparison", e);
+
+			}
+		}
+	};
+
+	public static final Comparator<EvaluationResult> NULL_AS_MAX_COMPARATOR = new Comparator<EvaluationResult>() {
+		public int compare(EvaluationResult left, EvaluationResult right) {
+			try {
+				return right.isNullResult() ? -1 : left.isNullResult() ? 1
+						: right.isNullResult() ? 0 : EvaluationResult.compare(
+								left, right);
+			} catch (EvaluationException e) {
+				throw new RuntimeException("Error occurred in comparison", e);
+			}
+		}
+	};
+	private Object result;
+	private ResultType type;
+
+	public static ResultType getObjectResultType(Object obj) {
+		if (obj == null) {
+			return ResultType.UNKNOWN;
+		}
+		if ((obj instanceof Byte))
+			return ResultType.BYTE;
+		if ((obj instanceof Short))
+			return ResultType.SHORT;
+		if ((obj instanceof Integer))
+			return ResultType.INTEGER;
+		if ((obj instanceof Long))
+			return ResultType.LONG;
+		if ((obj instanceof Float))
+			return ResultType.FLOAT;
+		if ((obj instanceof Double))
+			return ResultType.DOUBLE;
+		if ((obj instanceof BigInteger))
+			return ResultType.BIGINTEGER;
+		if ((obj instanceof BigDecimal))
+			return ResultType.BIGDECIMAL;
+		if ((obj instanceof Boolean))
+			return ResultType.BOOLEAN;
+		if ((obj instanceof byte[]))
+			return ResultType.BYTEARRAY;
+		if ((obj instanceof BytesReference))
+			return ResultType.BYTESREFERENCE;
+		if ((obj instanceof String)) {
+			return ResultType.STRING;
+		}
+		return ResultType.UNKNOWN;
+	}
+
+	public static boolean isNumber(ResultType t) {
+		return t.getCode() <= ResultType.BIGDECIMAL.getCode();
+	}
+
+	public static ResultType getMaxResultType(ResultType t1, ResultType t2) {
+		byte c1 = t1.getCode();
+		byte c2 = t2.getCode();
+		if (c1 == c2) {
+			return t1;
+		}
+		if (c1 == ResultType.BIGINTEGER.getCode())
+			c1 = ResultType.BIGDECIMAL.getCode();
+		if (c2 == ResultType.BIGINTEGER.getCode())
+			c2 = ResultType.BIGDECIMAL.getCode();
+		if (c1 == ResultType.FLOAT.getCode())
+			c1 = ResultType.DOUBLE.getCode();
+		if (c2 == ResultType.FLOAT.getCode()) {
+			c2 = ResultType.DOUBLE.getCode();
+		}
+		if ((isNumber(t1)) && (isNumber(t2))) {
+			return c1 < c2 ? t2 : t1;
+		}
+		if (((c1 == ResultType.BYTEARRAY.getCode()) && (c2 == ResultType.BYTESREFERENCE
+				.getCode()))
+				|| ((c2 == ResultType.BYTEARRAY.getCode()) && (c1 == ResultType.BYTESREFERENCE
+						.getCode()))) {
+			return ResultType.BYTEARRAY;
+		}
+		return ResultType.UNKNOWN;
+	}
+
+	public EvaluationResult() {
+		this(null, ResultType.UNKNOWN);
+	}
+
+	public EvaluationResult(Object result, ResultType type) {
+		this.result = result;
+		this.type = (type == null ? getObjectResultType(result) : type);
+	}
+
+	public boolean isNullResult() {
+		return this.result == null;
+	}
+
+	public ResultType getResultType() {
+		return this.type;
+	}
+
+	public boolean isNumber() {
+		return isNumber(this.type);
+	}
+
+	public Number asNumber() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return (Number) this.result;
+		}
+		throw new TypeConversionException(this.result, Number.class);
+	}
+
+	public String asString() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (this.type == ResultType.STRING) {
+			return (String) this.result;
+		}
+		throw new TypeConversionException(this.result, String.class);
+	}
+
+	public Boolean asBoolean() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (this.type == ResultType.BOOLEAN) {
+			return (Boolean) this.result;
+		}
+		throw new TypeConversionException(this.result, Boolean.class);
+	}
+
+	public byte[] asBytes() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (this.type == ResultType.BYTEARRAY) {
+			return (byte[]) this.result;
+		}
+		if (this.type == ResultType.BYTESREFERENCE) {
+			BytesReference ref = (BytesReference) this.result;
+			return ref.toBytes();
+		}
+
+		throw new TypeConversionException(this.result, byte[].class);
+	}
+
+	public BytesReference asBytesReference() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (this.type == ResultType.BYTESREFERENCE) {
+			return (BytesReference) this.result;
+		}
+		if (this.type == ResultType.BYTEARRAY) {
+			byte[] b = (byte[]) this.result;
+			return new BytesReference(b, 0, b.length);
+		}
+
+		throw new TypeConversionException(this.result, BytesReference.class);
+	}
+
+	public BigDecimal asBigDecimal() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (this.type == ResultType.BYTE) {
+			return new BigDecimal(((Byte) this.result).byteValue());
+		}
+		if (this.type == ResultType.SHORT) {
+			return new BigDecimal(((Short) this.result).shortValue());
+		}
+		if (this.type == ResultType.INTEGER) {
+			return new BigDecimal(((Integer) this.result).intValue());
+		}
+		if (this.type == ResultType.LONG) {
+			return new BigDecimal(((Long) this.result).longValue());
+		}
+		if (this.type == ResultType.FLOAT) {
+			return new BigDecimal(((Float) this.result).floatValue());
+		}
+		if (this.type == ResultType.DOUBLE) {
+			return new BigDecimal(((Double) this.result).doubleValue());
+		}
+		if (this.type == ResultType.BIGINTEGER) {
+			return new BigDecimal((BigInteger) this.result);
+		}
+		if (this.type == ResultType.BIGDECIMAL) {
+			return (BigDecimal) this.result;
+		}
+		throw new TypeConversionException(this.result, BigDecimal.class);
+	}
+
+	public Byte asByte() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return Byte.valueOf(((Number) this.result).byteValue());
+		}
+		throw new TypeConversionException(this.result, Byte.class);
+	}
+
+	public Double asDouble() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return Double.valueOf(((Number) this.result).doubleValue());
+		}
+		throw new TypeConversionException(this.result, Double.class);
+	}
+
+	public Float asFloat() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return Float.valueOf(((Number) this.result).floatValue());
+		}
+		throw new TypeConversionException(this.result, Float.class);
+	}
+
+	public Integer asInteger() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return Integer.valueOf(((Number) this.result).intValue());
+		}
+		throw new TypeConversionException(this.result, Integer.class);
+	}
+
+	public Long asLong() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return Long.valueOf(((Number) this.result).longValue());
+		}
+		throw new TypeConversionException(this.result, Long.class);
+	}
+
+	public Short asShort() throws TypeConversionException {
+		if (this.result == null) {
+			return null;
+		}
+		if (isNumber()) {
+			return Short.valueOf(((Number) this.result).shortValue());
+		}
+		throw new TypeConversionException(this.result, Short.class);
+	}
+
+	public EvaluationResult asSerializableResult() {
+		if ((!isNullResult()) && (this.type == ResultType.BYTESREFERENCE)) {
+			return new EvaluationResult(
+					((BytesReference) this.result).toBytes(),
+					ResultType.BYTEARRAY);
+		}
+		return this;
+	}
+
+	public int hashCode() {
+		if (isNullResult()) {
+			return 1;
+		}
+		if (this.type == ResultType.BYTEARRAY) {
+			return Bytes.hashCode((byte[]) (byte[]) this.result);
+		}
+		return this.result.hashCode();
+	}
+
+	public String toString() {
+		if (isNullResult()) {
+			return null;
+		}
+		String res = null;
+		switch (this.type.ordinal()) {
+		case 8:
+			res = ((BigDecimal) this.result).toPlainString();
+			break;
+		case 7:
+			res = ((BigDecimal) this.result).toPlainString();
+			break;
+		case 10:
+			res = Bytes.toString((byte[]) this.result);
+			break;
+		case 11:
+			BytesReference ref = (BytesReference) this.result;
+			res = Bytes.toString(ref.getReference(), ref.getOffset(),
+					ref.getLength());
+			break;
+		case 12:
+			res = (String) this.result;
+			break;
+		default:
+			res = this.result.toString();
+		}
+
+		return res;
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.result = HbaseObjectWritable.readObject(in, null);
+		this.type = ResultType.codeToResultType(in.readByte());
+	}
+
+	public void write(DataOutput out) throws IOException {
+		if ((!isNullResult()) && (this.type == ResultType.BYTESREFERENCE)) {
+			BytesReference ref = (BytesReference) this.result;
+			byte[] res = ref.toBytes();
+			HbaseObjectWritable.writeObject(out, res, res.getClass(), null);
+			out.writeByte(ResultType.BYTEARRAY.getCode());
+		} else {
+			HbaseObjectWritable.writeObject(
+					out,
+					this.result,
+					this.result == null ? Serializable.class : this.result
+							.getClass(), null);
+
+			out.writeByte(this.type.getCode());
+		}
+	}
+
+	public static int compare(EvaluationResult l, EvaluationResult r)
+			throws EvaluationException {
+		int comp = 0;
+		if ((l.type == ResultType.BYTEARRAY)
+				&& (r.type == ResultType.BYTEARRAY))
+			comp = Bytes.compareTo((byte[]) l.result,
+					(byte[]) r.result);
+		else if ((l.isNumber()) && (r.isNumber()))
+			comp = numberCompare(l, r);
+		else if ((l.type == ResultType.STRING) && (r.type == ResultType.STRING))
+			comp = ((String) l.result).compareTo((String) r.result);
+		else if ((l.type == ResultType.BYTESREFERENCE)
+				&& (r.type == ResultType.BYTESREFERENCE))
+			comp = ((BytesReference) l.result)
+					.compareTo((BytesReference) r.result);
+		else if ((l.type == ResultType.BYTEARRAY)
+				&& (r.type == ResultType.BYTESREFERENCE)) {
+			comp = new BytesReference((byte[]) l.result, 0,
+					((byte[]) l.result).length)
+					.compareTo((BytesReference) r.result);
+		} else if ((l.type == ResultType.BYTESREFERENCE)
+				&& (r.type == ResultType.BYTEARRAY)) {
+			comp = ((BytesReference) l.result).compareTo(new BytesReference(
+					(byte[]) r.result, 0,
+					((byte[]) r.result).length));
+		} else if ((l.type == ResultType.BOOLEAN)
+				&& (r.type == ResultType.BOOLEAN))
+			comp = ((Boolean) l.result).compareTo((Boolean) r.result);
+		else {
+			throw new EvaluationException("Unsupported comparison between "
+					+ l.getClass() + " and " + r.getClass());
+		}
+
+		return comp;
+	}
+
+	public static EvaluationResult numberAdd(EvaluationResult l,
+			EvaluationResult r) throws EvaluationException {
+		if ((l.result == null) || (r.result == null)) {
+			return new EvaluationResult();
+		}
+		ResultType t = getMaxResultType(l.type, r.type);
+		EvaluationResult res = null;
+
+		switch (t.ordinal()) {
+		case 8:
+			res = new EvaluationResult(l.asBigDecimal().add(r.asBigDecimal()),
+					t);
+			break;
+		case 7:
+			res = new EvaluationResult(l.asBigDecimal().add(r.asBigDecimal()),
+					t);
+			break;
+		case 6:
+			res = new EvaluationResult(Double.valueOf(l.asDouble()
+					.doubleValue() + r.asDouble().doubleValue()), t);
+			break;
+		case 5:
+			res = new EvaluationResult(Float.valueOf(l.asFloat().floatValue()
+					+ r.asFloat().floatValue()), t);
+			break;
+		case 4:
+			res = new EvaluationResult(Long.valueOf(l.asLong().longValue()
+					+ r.asLong().longValue()), t);
+			break;
+		case 3:
+			res = new EvaluationResult(Integer.valueOf(l.asInteger().intValue()
+					+ r.asInteger().intValue()), t);
+			break;
+		case 2:
+			res = new EvaluationResult(Integer.valueOf(l.asShort().shortValue()
+					+ r.asShort().shortValue()), t);
+			break;
+		case 1:
+			res = new EvaluationResult(Integer.valueOf(l.asByte().byteValue()
+					+ r.asByte().byteValue()), t);
+			break;
+		default:
+			throw new EvaluationException("Unsupported addition between "
+					+ l.type + " and " + r.type);
+		}
+
+		return res;
+	}
+
+	public static EvaluationResult numberSubtract(EvaluationResult l,
+			EvaluationResult r) throws EvaluationException {
+		if ((l.result == null) || (r.result == null)) {
+			return new EvaluationResult();
+		}
+		ResultType t = getMaxResultType(l.type, r.type);
+		EvaluationResult res = null;
+
+		switch (t.ordinal()) {
+		case 8:
+			res = new EvaluationResult(l.asBigDecimal().subtract(
+					r.asBigDecimal()), t);
+			break;
+		case 7:
+			res = new EvaluationResult(l.asBigDecimal().subtract(
+					r.asBigDecimal()), t);
+			break;
+		case 6:
+			res = new EvaluationResult(Double.valueOf(l.asDouble()
+					.doubleValue() - r.asDouble().doubleValue()), t);
+			break;
+		case 5:
+			res = new EvaluationResult(Float.valueOf(l.asFloat().floatValue()
+					- r.asFloat().floatValue()), t);
+			break;
+		case 4:
+			res = new EvaluationResult(Long.valueOf(l.asLong().longValue()
+					- r.asLong().longValue()), t);
+			break;
+		case 3:
+			res = new EvaluationResult(Integer.valueOf(l.asInteger().intValue()
+					- r.asInteger().intValue()), t);
+			break;
+		case 2:
+			res = new EvaluationResult(Integer.valueOf(l.asShort().shortValue()
+					- r.asShort().shortValue()), t);
+			break;
+		case 1:
+			res = new EvaluationResult(Integer.valueOf(l.asByte().byteValue()
+					- r.asByte().byteValue()), t);
+			break;
+		default:
+			throw new EvaluationException("Unsupported subtraction between "
+					+ l.type + " and " + r.type);
+		}
+
+		return res;
+	}
+
+	public static EvaluationResult numberMultiply(EvaluationResult l,
+			EvaluationResult r) throws EvaluationException {
+		if ((l.result == null) || (r.result == null)) {
+			return new EvaluationResult();
+		}
+		ResultType t = getMaxResultType(l.type, r.type);
+		EvaluationResult res = null;
+
+		switch (t.ordinal()) {
+		case 8:
+			res = new EvaluationResult(l.asBigDecimal().multiply(
+					r.asBigDecimal()), t);
+			break;
+		case 7:
+			res = new EvaluationResult(l.asBigDecimal().multiply(
+					r.asBigDecimal()), t);
+			break;
+		case 6:
+			res = new EvaluationResult(Double.valueOf(l.asDouble()
+					.doubleValue() * r.asDouble().doubleValue()), t);
+			break;
+		case 5:
+			res = new EvaluationResult(Float.valueOf(l.asFloat().floatValue()
+					* r.asFloat().floatValue()), t);
+			break;
+		case 4:
+			res = new EvaluationResult(Long.valueOf(l.asLong().longValue()
+					* r.asLong().longValue()), t);
+			break;
+		case 3:
+			res = new EvaluationResult(Integer.valueOf(l.asInteger().intValue()
+					* r.asInteger().intValue()), t);
+			break;
+		case 2:
+			res = new EvaluationResult(Integer.valueOf(l.asShort().shortValue()
+					* r.asShort().shortValue()), t);
+			break;
+		case 1:
+			res = new EvaluationResult(Integer.valueOf(l.asByte().byteValue()
+					* r.asByte().byteValue()), t);
+			break;
+		default:
+			throw new EvaluationException("Unsupported multiplication between "
+					+ l.type + " and " + r.type);
+		}
+
+		return res;
+	}
+
+	public static EvaluationResult numberDivide(EvaluationResult l,
+			EvaluationResult r) throws EvaluationException {
+		if ((l.result == null) || (r.result == null)) {
+			return new EvaluationResult();
+		}
+		ResultType t = getMaxResultType(l.type, r.type);
+		EvaluationResult res = null;
+
+		switch (t.ordinal()) {
+		case 8:
+			res = new EvaluationResult(l.asBigDecimal()
+					.divide(r.asBigDecimal()), t);
+			break;
+		case 7:
+			res = new EvaluationResult(l.asBigDecimal()
+					.divide(r.asBigDecimal()), t);
+			break;
+		case 6:
+			res = new EvaluationResult(Double.valueOf(l.asDouble()
+					.doubleValue() / r.asDouble().doubleValue()), t);
+			break;
+		case 5:
+			res = new EvaluationResult(Float.valueOf(l.asFloat().floatValue()
+					/ r.asFloat().floatValue()), t);
+			break;
+		case 4:
+			res = new EvaluationResult(Long.valueOf(l.asLong().longValue()
+					/ r.asLong().longValue()), t);
+			break;
+		case 3:
+			res = new EvaluationResult(Integer.valueOf(l.asInteger().intValue()
+					/ r.asInteger().intValue()), t);
+			break;
+		case 2:
+			res = new EvaluationResult(Integer.valueOf(l.asShort().shortValue()
+					/ r.asShort().shortValue()), t);
+			break;
+		case 1:
+			res = new EvaluationResult(Integer.valueOf(l.asByte().byteValue()
+					/ r.asByte().byteValue()), t);
+			break;
+		default:
+			throw new EvaluationException("Unsupported division between "
+					+ l.type + " and " + r.type);
+		}
+
+		return res;
+	}
+
+	public static EvaluationResult numberRemainder(EvaluationResult l,
+			EvaluationResult r) throws EvaluationException {
+		if ((l.result == null) || (r.result == null)) {
+			return new EvaluationResult();
+		}
+		ResultType t = getMaxResultType(l.type, r.type);
+		EvaluationResult res = null;
+
+		switch (t.ordinal()) {
+		case 8:
+			res = new EvaluationResult(l.asBigDecimal().remainder(
+					r.asBigDecimal()), t);
+			break;
+		case 7:
+			res = new EvaluationResult(l.asBigDecimal().remainder(
+					r.asBigDecimal()), t);
+			break;
+		case 6:
+			res = new EvaluationResult(Double.valueOf(l.asDouble()
+					.doubleValue() % r.asDouble().doubleValue()), t);
+			break;
+		case 5:
+			res = new EvaluationResult(Float.valueOf(l.asFloat().floatValue()
+					% r.asFloat().floatValue()), t);
+			break;
+		case 4:
+			res = new EvaluationResult(Long.valueOf(l.asLong().longValue()
+					% r.asLong().longValue()), t);
+			break;
+		case 3:
+			res = new EvaluationResult(Integer.valueOf(l.asInteger().intValue()
+					% r.asInteger().intValue()), t);
+			break;
+		case 2:
+			res = new EvaluationResult(Integer.valueOf(l.asShort().shortValue()
+					% r.asShort().shortValue()), t);
+			break;
+		case 1:
+			res = new EvaluationResult(Integer.valueOf(l.asByte().byteValue()
+					% r.asByte().byteValue()), t);
+			break;
+		default:
+			throw new EvaluationException(
+					"Unsupported remainder operation between " + l.type
+							+ " and " + r.type);
+		}
+
+		return res;
+	}
+
+	protected static int numberCompare(EvaluationResult l, EvaluationResult r)
+			throws EvaluationException {
+		ResultType t = getMaxResultType(l.type, r.type);
+		int res = 0;
+
+		switch (t.ordinal()) {
+		case 1:
+			res = l.asByte().compareTo(r.asByte());
+			break;
+		case 2:
+			res = l.asShort().compareTo(r.asShort());
+			break;
+		case 3:
+			res = l.asInteger().compareTo(r.asInteger());
+			break;
+		case 4:
+			res = l.asLong().compareTo(r.asLong());
+			break;
+		case 5:
+			res = l.asFloat().compareTo(r.asFloat());
+			break;
+		case 6:
+			res = l.asDouble().compareTo(r.asDouble());
+			break;
+		case 7:
+			res = l.asBigDecimal().compareTo(r.asBigDecimal());
+			break;
+		case 8:
+			res = l.asBigDecimal().compareTo(r.asBigDecimal());
+			break;
+		default:
+			throw new EvaluationException(
+					"Unsupported number comparison between " + l.type + " and "
+							+ r.type);
+		}
+
+		return res;
+	}
+
+	public static enum ResultType {
+		UNKNOWN((byte) -1), BYTE((byte) 0), SHORT((byte) 4), INTEGER((byte) 8), LONG(
+				(byte) 12), FLOAT((byte) 16), DOUBLE((byte) 20), BIGINTEGER(
+				(byte) 24), BIGDECIMAL((byte) 28), BOOLEAN((byte) 32), BYTEARRAY(
+				(byte) 36), BYTESREFERENCE((byte) 40), STRING((byte) 44), ;
+
+		private final byte code;
+
+		private ResultType(byte c) {
+			this.code = c;
+		}
+
+		public byte getCode() {
+			return this.code;
+		}
+
+		public static ResultType codeToResultType(byte b) {
+			for (ResultType t : values()) {
+				if (t.getCode() == b) {
+					return t;
+				}
+			}
+			throw new RuntimeException("Unknown code " + b);
+		}
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/StatsValue.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/StatsValue.java
new file mode 100644
index 0000000..d81404d
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/StatsValue.java
@@ -0,0 +1,113 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+import java.io.Serializable;
+
+public class StatsValue implements Serializable {
+	/**
+	 * 
+	 */
+	private static final long serialVersionUID = 1L;
+	private Double min;
+	private Double max;
+	private double sum;
+	private double sumOfSquares;
+	private long count;
+	private long missing;
+	private EvaluationResult.ResultType type;
+
+	public StatsValue() {
+		reset();
+	}
+
+	public void accumulate(EvaluationResult r) throws TypeConversionException {
+		if (r.isNullResult()) {
+			this.missing += 1L;
+		} else if (!r.isNumber()) {
+			this.count += 1L;
+		} else {
+			if ((this.type != EvaluationResult.ResultType.DOUBLE)
+					&& (r.getResultType().getCode() > this.type.getCode())) {
+				this.type = EvaluationResult.ResultType.DOUBLE;
+			}
+			double d = r.asDouble().doubleValue();
+			double multResult = d * d;
+			this.sumOfSquares += multResult;
+			this.min = Double.valueOf((this.min == null)
+					|| (d < this.min.doubleValue()) ? d : this.min
+					.doubleValue());
+			this.max = Double.valueOf((this.max == null)
+					|| (d > this.max.doubleValue()) ? d : this.max
+					.doubleValue());
+			this.sum += d;
+			this.count += 1L;
+		}
+	}
+
+	public void accumulate(StatsValue stv) throws TypeConversionException {
+		if ((this.type != EvaluationResult.ResultType.DOUBLE)
+				&& (stv.getType().getCode() > this.type.getCode())) {
+			this.type = EvaluationResult.ResultType.DOUBLE;
+		}
+		this.min = ((this.min == null)
+				|| ((stv.min != null) && (stv.min.doubleValue() < this.min
+						.doubleValue())) ? stv.min : this.min);
+
+		this.max = ((this.max == null)
+				|| ((stv.max != null) && (stv.max.doubleValue() > this.max
+						.doubleValue())) ? stv.max : this.max);
+
+		this.sum += stv.sum;
+		this.count += stv.count;
+		this.missing += stv.missing;
+		this.sumOfSquares += stv.sumOfSquares;
+	}
+
+	public void reset() {
+		this.min = null;
+		this.max = null;
+		this.sum = 0.0D;
+		this.count = (this.missing = 0L);
+		this.sumOfSquares = 0.0D;
+		this.type = EvaluationResult.ResultType.LONG;
+	}
+
+	public Number getMin() {
+		if ((this.min != null)
+				&& (this.type.getCode() <= EvaluationResult.ResultType.LONG
+						.getCode()))
+			return new Long(this.min.longValue());
+		return this.min;
+	}
+
+	public Number getMax() {
+		if ((this.max != null)
+				&& (this.type.getCode() <= EvaluationResult.ResultType.LONG
+						.getCode()))
+			return new Long(this.max.longValue());
+		return this.max;
+	}
+
+	public Number getSum() {
+    if (this.type.getCode() <= EvaluationResult.ResultType.LONG.getCode())
+      return new Long((long)this.sum);
+    return Double.valueOf(this.sum);
+  }
+
+	public Number getSumOfSquares() {
+    if (this.type.getCode() <= EvaluationResult.ResultType.LONG.getCode())
+      return new Long((long)this.sumOfSquares);
+    return Double.valueOf(this.sumOfSquares);
+  }
+
+	public long getCount() {
+		return this.count;
+	}
+
+	public long getMissing() {
+		return this.missing;
+	}
+
+	public EvaluationResult.ResultType getType() {
+		return this.type;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/TypeConversionException.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/TypeConversionException.java
new file mode 100644
index 0000000..9a0a2dd
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/TypeConversionException.java
@@ -0,0 +1,18 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+public class TypeConversionException extends EvaluationException {
+	/**
+	 * 
+	 */
+	private static final long serialVersionUID = 1L;
+
+	public TypeConversionException(Object obj, Class<?> expectedType) {
+		super("Could not get object: " + obj + " as type: "
+				+ expectedType.getName());
+	}
+
+	public TypeConversionException(String objectType, Class<?> expectedType) {
+		super("Could not convert type: " + objectType + " to type: "
+				+ expectedType.getName());
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/evaluation/ValueNotAvailableException.java b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/ValueNotAvailableException.java
new file mode 100644
index 0000000..59d7e65
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/evaluation/ValueNotAvailableException.java
@@ -0,0 +1,19 @@
+package org.apache.hadoop.hbase.expression.evaluation;
+
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class ValueNotAvailableException extends EvaluationException {
+	/**
+	 * 
+	 */
+	private static final long serialVersionUID = 1L;
+
+	public ValueNotAvailableException(String msg) {
+		super(msg);
+	}
+
+	public ValueNotAvailableException(byte[] family, byte[] column) {
+		super("Value of column: " + Bytes.toString(family) + ":"
+				+ Bytes.toString(column) + " is not available");
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/visitor/ColumnVisitor.java b/src/main/java/org/apache/hadoop/hbase/expression/visitor/ColumnVisitor.java
new file mode 100644
index 0000000..0938cfb
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/visitor/ColumnVisitor.java
@@ -0,0 +1,48 @@
+package org.apache.hadoop.hbase.expression.visitor;
+
+import java.util.Comparator;
+import java.util.Set;
+import java.util.TreeSet;
+import org.apache.hadoop.hbase.expression.ColumnValueExpression;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.ExpressionException;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Pair;
+
+public class ColumnVisitor implements ExpressionVisitor {
+	private Set<Pair<byte[], byte[]>> columnSet = new TreeSet<Pair<byte[], byte[]>>(
+			new Comparator<Pair<byte[], byte[]>>() {
+				public int compare(Pair<byte[], byte[]> left,
+						Pair<byte[], byte[]> right) {
+					int comp = Bytes.equals((byte[]) left.getFirst(),
+							(byte[]) right.getFirst()) ? 0
+							: Bytes.compareTo((byte[]) left.getFirst(),
+									(byte[]) right.getFirst());
+
+					if (comp == 0) {
+						comp = Bytes.equals((byte[]) left.getSecond(),
+								(byte[]) right.getSecond()) ? 0
+								: Bytes.compareTo((byte[]) left.getSecond(),
+										(byte[]) right.getSecond());
+					}
+
+					return comp;
+				}
+			});
+
+	public Set<Pair<byte[], byte[]>> getColumnSet() {
+		return this.columnSet;
+	}
+
+	public ExpressionVisitor.ReturnCode processExpression(Expression expression)
+			throws ExpressionException {
+		if ((expression instanceof ColumnValueExpression)) {
+			ColumnValueExpression columnValueExpr = (ColumnValueExpression) expression;
+			this.columnSet.add(new Pair<byte[], byte[]>(columnValueExpr.getFamily(),
+					columnValueExpr.getQualifier()));
+
+			return ExpressionVisitor.ReturnCode.SKIP_SUBTREE;
+		}
+		return ExpressionVisitor.ReturnCode.CONTINUE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionTraversal.java b/src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionTraversal.java
new file mode 100644
index 0000000..cba35c0
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionTraversal.java
@@ -0,0 +1,52 @@
+package org.apache.hadoop.hbase.expression.visitor;
+
+import java.lang.reflect.Field;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.ExpressionException;
+
+public class ExpressionTraversal {
+	public static void traverse(Expression expression, ExpressionVisitor visitor)
+			throws ExpressionException {
+		traverseInternal(expression, visitor);
+	}
+
+	private static ExpressionVisitor.ReturnCode traverseInternal(
+			Expression expression, ExpressionVisitor visitor)
+			throws ExpressionException {
+		ExpressionVisitor.ReturnCode code = visitor
+				.processExpression(expression);
+		if (code == ExpressionVisitor.ReturnCode.SKIP_SUBTREE)
+			return ExpressionVisitor.ReturnCode.CONTINUE;
+		if (code == ExpressionVisitor.ReturnCode.TERMINATE) {
+			return code;
+		}
+		List<Expression> containing = getContainingExpressions(expression);
+		for (Expression expr : containing) {
+			code = traverseInternal(expr, visitor);
+			if (code == ExpressionVisitor.ReturnCode.TERMINATE) {
+				return code;
+			}
+		}
+		return ExpressionVisitor.ReturnCode.CONTINUE;
+	}
+
+	private static List<Expression> getContainingExpressions(
+			Expression expression) {
+		List<Expression> ret = new ArrayList<Expression>();
+		Field[] fields = expression.getClass().getDeclaredFields();
+		for (Field field : fields) {
+			field.setAccessible(true);
+			if (!Expression.class.isAssignableFrom(field.getType()))
+				continue;
+			try {
+				ret.add((Expression) field.get(expression));
+			} catch (IllegalArgumentException ignored) {
+			} catch (IllegalAccessException ignored) {
+			}
+		}
+		return ret;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionVisitor.java b/src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionVisitor.java
new file mode 100644
index 0000000..20c87cf
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/visitor/ExpressionVisitor.java
@@ -0,0 +1,13 @@
+package org.apache.hadoop.hbase.expression.visitor;
+
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.ExpressionException;
+
+public abstract interface ExpressionVisitor {
+	public abstract ReturnCode processExpression(Expression paramExpression)
+			throws ExpressionException;
+
+	public static enum ReturnCode {
+		CONTINUE, SKIP_SUBTREE, TERMINATE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/expression/visitor/IsConstantVisitor.java b/src/main/java/org/apache/hadoop/hbase/expression/visitor/IsConstantVisitor.java
new file mode 100644
index 0000000..14ac0e0
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/expression/visitor/IsConstantVisitor.java
@@ -0,0 +1,25 @@
+package org.apache.hadoop.hbase.expression.visitor;
+
+import org.apache.hadoop.hbase.expression.ColumnValueExpression;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.ExpressionException;
+import org.apache.hadoop.hbase.expression.RowExpression;
+
+public class IsConstantVisitor implements ExpressionVisitor {
+	private boolean isConstant = true;
+
+	public boolean isConstant() {
+		return this.isConstant;
+	}
+
+	public ExpressionVisitor.ReturnCode processExpression(Expression expression)
+			throws ExpressionException {
+		if ((expression instanceof ColumnValueExpression))
+			this.isConstant = false;
+		else if ((expression instanceof RowExpression)) {
+			this.isConstant = false;
+		}
+		return this.isConstant ? ExpressionVisitor.ReturnCode.CONTINUE
+				: ExpressionVisitor.ReturnCode.TERMINATE;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/filter/BinaryPartialComparator.java b/src/main/java/org/apache/hadoop/hbase/filter/BinaryPartialComparator.java
new file mode 100644
index 0000000..73ca613
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/filter/BinaryPartialComparator.java
@@ -0,0 +1,42 @@
+package org.apache.hadoop.hbase.filter;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class BinaryPartialComparator extends WritableByteArrayComparable {
+	protected int offset;
+
+	public BinaryPartialComparator() {
+	}
+
+	public BinaryPartialComparator(byte[] value, int offset) {
+		this.value = value;
+		this.offset = offset;
+	}
+
+	public byte[] getValue() {
+		return this.value;
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.offset = in.readInt();
+		this.value = Bytes.readByteArray(in);
+	}
+
+	public void write(DataOutput out) throws IOException {
+		out.writeInt(this.offset);
+		Bytes.writeByteArray(out, this.value);
+	}
+
+	public int compareTo(byte[] value, int offset, int length) {
+		if (length <= this.offset) {
+			return 1;
+		}
+		return Bytes.compareTo(this.value, 0, this.value.length, value, offset
+				+ this.offset,
+				value.length <= this.value.length + this.offset ? length
+						- this.offset : this.value.length);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/filter/BinarySuffixComparator.java b/src/main/java/org/apache/hadoop/hbase/filter/BinarySuffixComparator.java
new file mode 100644
index 0000000..8ffdd99
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/filter/BinarySuffixComparator.java
@@ -0,0 +1,19 @@
+package org.apache.hadoop.hbase.filter;
+
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class BinarySuffixComparator extends WritableByteArrayComparable {
+	public BinarySuffixComparator() {
+	}
+
+	public BinarySuffixComparator(byte[] value) {
+		super(value);
+	}
+
+	public int compareTo(byte[] value, int offset, int length) {
+		int startPos = offset + length - this.value.length;
+		return Bytes.compareTo(this.value, 0, this.value.length, value,
+				startPos >= offset ? startPos : offset,
+				startPos >= offset ? this.value.length : length);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/filter/ExpressionFilter.java b/src/main/java/org/apache/hadoop/hbase/filter/ExpressionFilter.java
new file mode 100644
index 0000000..cfa1182
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/filter/ExpressionFilter.java
@@ -0,0 +1,68 @@
+package org.apache.hadoop.hbase.filter;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.expression.Expression;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationContext;
+import org.apache.hadoop.hbase.expression.evaluation.EvaluationResult;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+
+public class ExpressionFilter extends FilterBase {
+	protected Expression expression;
+	protected EvaluationContext context;
+	protected boolean filtered;
+
+	public ExpressionFilter() {
+		this(null);
+	}
+
+	public ExpressionFilter(Expression expression) {
+		this.expression = expression;
+		this.context = new EvaluationContext(HBaseConfiguration.create());
+		this.filtered = false;
+	}
+
+	public void reset() {
+		this.filtered = false;
+	}
+
+	public void filterRow(List<KeyValue> kvs) {
+		if (this.expression != null) {
+			this.context.setCurrentRow(kvs);
+			try {
+				EvaluationResult r = this.expression.evaluate(this.context);
+				if ((!r.isNullResult()) && (r.asBoolean().booleanValue())) {
+					this.filtered = false;
+					return;
+				}
+			} catch (Throwable t) {
+			}
+		}
+		this.filtered = true;
+	}
+
+	public boolean hasFilterRow() {
+		return true;
+	}
+
+	public boolean filterRow() {
+		return this.filtered;
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.expression = ((Expression) HbaseObjectWritable
+				.readObject(in, null));
+		this.context.clearAll();
+		reset();
+	}
+
+	public void write(DataOutput out) throws IOException {
+		HbaseObjectWritable.writeObject(out, this.expression,
+				this.expression.getClass(), null);
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/filter/InComparator.java b/src/main/java/org/apache/hadoop/hbase/filter/InComparator.java
new file mode 100644
index 0000000..3c99e07
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/filter/InComparator.java
@@ -0,0 +1,100 @@
+package org.apache.hadoop.hbase.filter;
+
+import java.io.ByteArrayOutputStream;
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.DataOutputStream;
+import java.io.File;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Scanner;
+import java.util.Set;
+import java.util.TreeSet;
+
+import org.apache.hadoop.hbase.util.ByteBloomFilter;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class InComparator extends WritableByteArrayComparable {
+	private ByteBloomFilter bloomFilter;
+	private ByteBuffer bloom;
+	private Set<byte[]> valueSet = new TreeSet<byte[]>(Bytes.BYTES_COMPARATOR);
+
+	public InComparator() {
+	}
+
+	public InComparator(byte[][] values) {
+		this.bloomFilter = new ByteBloomFilter(values.length,
+				0.009999999776482582D, 1, 0);
+		this.bloomFilter.allocBloom();
+
+		for (byte[] value : values) {
+			this.valueSet.add(value);
+			this.bloomFilter.add(value);
+		}
+
+		initBloom();
+	}
+
+	public InComparator(String fileName) throws IOException {
+		File file = new File(fileName);
+		if ((!file.exists()) || (!file.isFile())) {
+			throw new IOException("File does not exist.");
+		}
+		Scanner scanner = new Scanner(file);
+		List<byte[]> values = new ArrayList();
+		while (scanner.hasNext()) {
+			values.add(Bytes.toBytes(scanner.nextLine()));
+		}
+
+		this.bloomFilter = new ByteBloomFilter(values.size(),
+				0.009999999776482582D, 1, 0);
+		this.bloomFilter.allocBloom();
+
+		for (byte[] value : values) {
+			this.valueSet.add(value);
+			this.bloomFilter.add(value);
+		}
+
+		initBloom();
+	}
+
+	public void initBloom() {
+		ByteArrayOutputStream bOut = new ByteArrayOutputStream();
+		try {
+			this.bloomFilter.writeBloom(new DataOutputStream(bOut));
+		} catch (IOException e) {
+		}
+		this.bloom = ByteBuffer.wrap(bOut.toByteArray());
+	}
+
+	public void write(DataOutput out) throws IOException {
+		out.writeInt(this.valueSet.size());
+		for (byte[] value : this.valueSet)
+			Bytes.writeByteArray(out, value);
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		int numValues = in.readInt();
+		this.bloomFilter = new ByteBloomFilter(numValues,
+				0.009999999776482582D, 1, 0);
+		this.bloomFilter.allocBloom();
+		for (int i = 0; i < numValues; i++) {
+			byte[] value = Bytes.readByteArray(in);
+			this.valueSet.add(value);
+			this.bloomFilter.add(value);
+		}
+
+		initBloom();
+	}
+
+	public int compareTo(byte[] value, int offset, int length) {
+		if ((this.bloomFilter.contains(value, offset, length, this.bloom))
+				&& (this.valueSet.contains(value))) {
+			return 0;
+		}
+
+		return -1;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/filter/MultiRowRangeFilter.java b/src/main/java/org/apache/hadoop/hbase/filter/MultiRowRangeFilter.java
new file mode 100644
index 0000000..b6d5a31
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/filter/MultiRowRangeFilter.java
@@ -0,0 +1,396 @@
+package org.apache.hadoop.hbase.filter;
+
+import java.io.BufferedReader;
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.WeakHashMap;
+import java.util.regex.Pattern;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.Writable;
+
+public class MultiRowRangeFilter extends FilterBase {
+	private static final Log LOG = LogFactory.getLog(MultiRowRangeFilter.class);
+	private static final Pattern WHITESPACE_PATTERN = Pattern.compile("\\s+");
+	private static final char DEFAULT_DELIMITER = ' ';
+	private static WeakHashMap<String, RowKeyRangeList> rangesMap = new WeakHashMap();
+	private SourceType type;
+	private Path path;
+	private List<RowKeyRange> rangeList;
+	private String rangeKey;
+	private char delimiter = ' ';
+	private Pattern pattern = WHITESPACE_PATTERN;
+
+	private boolean done = false;
+	private boolean initialized = false;
+	private int index;
+	private RowKeyRange range;
+	private Filter.ReturnCode currentReturnCode;
+
+	public MultiRowRangeFilter() {
+	}
+
+	public MultiRowRangeFilter(List<RowKeyRange> list) throws IOException {
+		this.type = SourceType.LIST;
+		this.rangeList = list;
+		check(this.rangeList, true);
+	}
+
+	public MultiRowRangeFilter(Path path) throws IOException {
+		this(path, ' ', WHITESPACE_PATTERN);
+	}
+
+	public MultiRowRangeFilter(Path path, char delimiter) throws IOException {
+		this(path, delimiter, WHITESPACE_PATTERN);
+	}
+
+	public MultiRowRangeFilter(Path path, Pattern pattern) throws IOException {
+		this(path, ' ', pattern);
+	}
+
+	private MultiRowRangeFilter(Path path, char delimiter, Pattern pattern)
+			throws IOException {
+		this.type = SourceType.FILE;
+		this.path = path;
+		this.delimiter = delimiter;
+		this.pattern = pattern;
+		initRangesFromFile();
+		check(this.rangeList, true);
+	}
+
+	public boolean filterAllRemaining() {
+		return this.done;
+	}
+
+	public boolean filterRowKey(byte[] buffer, int offset, int length) {
+		if (this.rangeList.size() == 0) {
+			this.done = true;
+			this.currentReturnCode = Filter.ReturnCode.NEXT_ROW;
+			return false;
+		}
+
+		if ((!this.initialized)
+				|| (!this.range.contains(buffer, offset, length))) {
+			byte[] rowkey = new byte[length];
+			System.arraycopy(buffer, offset, rowkey, 0, length);
+			this.index = getNextRangeIndex(rowkey);
+			if (this.index >= this.rangeList.size()) {
+				this.done = true;
+				this.currentReturnCode = Filter.ReturnCode.NEXT_ROW;
+				return false;
+			}
+			this.range = ((RowKeyRange) this.rangeList.get(this.index));
+			this.initialized = true;
+		}
+
+		if (Bytes.compareTo(buffer, offset, length, this.range.startRow, 0,
+				this.range.startRow.length) < 0) {
+			this.currentReturnCode = Filter.ReturnCode.SEEK_NEXT_USING_HINT;
+		} else
+			this.currentReturnCode = Filter.ReturnCode.INCLUDE;
+
+		return false;
+	}
+
+	public Filter.ReturnCode filterKeyValue(KeyValue kv) {
+		return this.currentReturnCode;
+	}
+
+	public KeyValue getNextKeyHint(KeyValue currentKV) {
+		return KeyValue.createFirstOnRow(this.range.startRow);
+	}
+
+	public void readFields(DataInput in) throws IOException {
+		this.type = SourceType.valueOf(in.readUTF());
+		switch (this.type.ordinal()) {
+		case 1:
+			int length = in.readInt();
+			this.rangeList = new ArrayList(length);
+			for (int i = 0; i < length; i++) {
+				RowKeyRange range = new RowKeyRange();
+				range.readFields(in);
+				this.rangeList.add(range);
+			}
+			break;
+		case 2:
+			this.path = new Path(in.readUTF());
+			this.delimiter = in.readChar();
+			this.pattern = Pattern.compile(in.readUTF());
+			initRangesFromFile();
+		}
+	}
+
+	public void write(DataOutput out) throws IOException {
+		out.writeUTF(this.type.name());
+		switch (this.type.ordinal()) {
+		case 1:
+			out.writeInt(this.rangeList.size());
+			for (RowKeyRange range : this.rangeList) {
+				range.write(out);
+			}
+			break;
+		case 2:
+			out.writeUTF(this.path.toString());
+			out.writeChar(this.delimiter);
+			out.writeUTF(this.pattern.toString());
+		}
+	}
+
+	private int getNextRangeIndex(byte[] rowKey) {
+		RowKeyRange temp = new RowKeyRange(rowKey, null);
+		int index = Collections.binarySearch(this.rangeList, temp);
+		if (index < 0) {
+			int insertionPosition = -index - 1;
+
+			if ((insertionPosition != 0)
+					&& (((RowKeyRange) this.rangeList
+							.get(insertionPosition - 1)).contains(rowKey))) {
+				return insertionPosition - 1;
+			}
+			return insertionPosition;
+		}
+
+		return index;
+	}
+
+	private void initRangesFromFile() throws IOException {
+		FileSystem fs = this.path.getFileSystem(HBaseConfiguration.create());
+		FileStatus status = fs.getFileStatus(this.path);
+		long modTime = status.getModificationTime();
+		long size = status.getLen();
+		this.rangeKey = new StringBuilder().append(this.path.toString())
+				.append(size).append(modTime).append(this.delimiter)
+				.append(this.pattern.toString()).toString();
+		if (rangesMap.get(this.rangeKey) == null) {
+			synchronized (rangesMap) {
+				if (rangesMap.get(this.rangeKey) == null) {
+					rangesMap.put(this.rangeKey, new RowKeyRangeList(fs,
+							this.path));
+				}
+			}
+		}
+		this.rangeList = ((RowKeyRangeList) rangesMap.get(this.rangeKey))
+				.getRowKeyRangeList();
+	}
+
+	private void check(List<RowKeyRange> ranges, boolean details)
+			throws IOException {
+		if (ranges.size() == 0) {
+			throw new IOException("No ranges found.");
+		}
+		List<RowKeyRange> invalidRanges = new ArrayList();
+		List<Integer> overlaps = new ArrayList();
+
+		if (!((RowKeyRange) ranges.get(0)).isValid())
+			invalidRanges.add(ranges.get(0));
+		byte[] lastStopRow = ((RowKeyRange) ranges.get(0)).stopRow;
+
+		for (int i = 1; i < ranges.size(); i++) {
+			RowKeyRange range = (RowKeyRange) ranges.get(i);
+			if (!range.isValid()) {
+				invalidRanges.add(range);
+			}
+			if ((Bytes.equals(lastStopRow, HConstants.EMPTY_BYTE_ARRAY))
+					|| (Bytes.compareTo(lastStopRow, range.startRow) > 0)) {
+				overlaps.add(Integer.valueOf(i));
+			}
+			lastStopRow = range.stopRow;
+		}
+
+		if ((invalidRanges.size() != 0) || (overlaps.size() != 0)) {
+			StringBuilder sb = new StringBuilder();
+			sb.append(invalidRanges.size()).append(" invaild ranges.\n");
+			if (details) {
+				for (RowKeyRange range : invalidRanges) {
+					sb.append(
+							new StringBuilder()
+									.append("Invalid range: start row=>")
+									.append(Bytes.toString(range.startRow))
+									.append(", stop row => ")
+									.append(Bytes.toString(range.startRow))
+									.toString()).append('\n');
+				}
+
+			}
+
+			sb.append("There might be overlaps between rowkey ranges or the rowkey ranges are not arranged in ascending order.\n");
+			sb.append(overlaps.size()).append(
+					" overlap or unsorted row key range pairs.\n");
+			if (details) {
+				for (Integer over : overlaps) {
+					sb.append(
+							new StringBuilder()
+									.append("Overlap or unsorted range pair: start row=>")
+									.append(Bytes.toString(((RowKeyRange) ranges
+											.get(over.intValue() - 1)).startRow))
+									.append(", stop row => ")
+									.append(Bytes.toString(((RowKeyRange) ranges
+											.get(over.intValue() - 1)).stopRow))
+									.toString()).append('\n');
+
+					sb.append(
+							new StringBuilder()
+									.append("                           and  start row=>")
+									.append(Bytes.toString(((RowKeyRange) ranges
+											.get(over.intValue())).startRow))
+									.append(", stop row => ")
+									.append(Bytes.toString(((RowKeyRange) ranges
+											.get(over.intValue())).stopRow))
+									.toString()).append('\n');
+				}
+
+			}
+
+			throw new IOException(sb.toString());
+		}
+	}
+
+	public Path getPath() {
+		return this.path;
+	}
+
+	public char getDelimiter() {
+		return this.delimiter;
+	}
+
+	public Pattern getPattern() {
+		return this.pattern;
+	}
+
+	public class RowKeyRangeList {
+		private FileSystem fs;
+		private Path path;
+		private List<MultiRowRangeFilter.RowKeyRange> rowKeyRangeList;
+
+		public RowKeyRangeList(FileSystem fs, Path path) {
+			this.fs = fs;
+			this.path = path;
+		}
+
+		public synchronized List<MultiRowRangeFilter.RowKeyRange> getRowKeyRangeList()
+				throws IOException {
+			if (this.rowKeyRangeList == null) {
+				if (MultiRowRangeFilter.LOG.isDebugEnabled()) {
+					MultiRowRangeFilter.LOG
+							.debug("Initialize the row key ranges from file: "
+									+ this.path.toString());
+				}
+
+				this.rowKeyRangeList = new ArrayList();
+				FSDataInputStream input = null;
+				BufferedReader d = null;
+				try {
+					input = this.fs.open(this.path);
+					d = new BufferedReader(new InputStreamReader(input));
+					String line;
+					while ((line = d.readLine()) != null) {
+						if (line.trim().isEmpty())
+							continue;
+						String[] rowKeys = splitRangeLine(line,
+								MultiRowRangeFilter.this.delimiter);
+						if (rowKeys.length < 2) {
+							throw new IOException("Line: " + line
+									+ " cannot be splited.");
+						}
+						this.rowKeyRangeList
+								.add(new MultiRowRangeFilter.RowKeyRange(
+										rowKeys[0], rowKeys[1]));
+					}
+				} finally {
+					if (d != null) {
+						d.close();
+					}
+					if (input != null) {
+						input.close();
+					}
+				}
+			}
+			return this.rowKeyRangeList;
+		}
+
+		private String[] splitRangeLine(String line, char delim) {
+			if (delim == ' ') {
+				return MultiRowRangeFilter.this.pattern.split(line, 2);
+			}
+			int index = line.indexOf(delim);
+			return new String[] {
+					line.substring(0, index),
+					line.indexOf(delim) == -1 ? line : line
+							.substring(index + 1) };
+		}
+	}
+
+	public static class RowKeyRange implements Writable,
+			Comparable<RowKeyRange> {
+		private byte[] startRow;
+		private byte[] stopRow;
+		private int isScan = 0;
+
+		public RowKeyRange() {
+		}
+
+		public RowKeyRange(String startRow, String stopRow) {
+			this(
+					(startRow == null) || (startRow.isEmpty()) ? HConstants.EMPTY_BYTE_ARRAY
+							: Bytes.toBytes(startRow),
+					(stopRow == null) || (stopRow.isEmpty()) ? HConstants.EMPTY_BYTE_ARRAY
+							: Bytes.toBytes(stopRow));
+		}
+
+		public RowKeyRange(byte[] startRow, byte[] stopRow) {
+			this.startRow = startRow;
+			this.stopRow = stopRow;
+			this.isScan = (Bytes.equals(startRow, stopRow) ? 1 : 0);
+		}
+
+		public void readFields(DataInput in) throws IOException {
+			this.startRow = Bytes.readByteArray(in);
+			this.stopRow = Bytes.readByteArray(in);
+			this.isScan = (Bytes.equals(this.startRow, this.stopRow) ? 1 : 0);
+		}
+
+		public void write(DataOutput out) throws IOException {
+			Bytes.writeByteArray(out, this.startRow);
+			Bytes.writeByteArray(out, this.stopRow);
+		}
+
+		public boolean contains(byte[] row) {
+			return contains(row, 0, row.length);
+		}
+
+		public boolean contains(byte[] buffer, int offset, int length) {
+			return (Bytes.compareTo(buffer, offset, length, this.startRow, 0,
+					this.startRow.length) >= 0)
+					&& ((Bytes
+							.equals(this.stopRow, HConstants.EMPTY_BYTE_ARRAY)) || (Bytes
+							.compareTo(buffer, offset, length, this.stopRow, 0,
+									this.stopRow.length) < this.isScan));
+		}
+
+		public int compareTo(RowKeyRange other) {
+			return Bytes.compareTo(this.startRow, other.startRow);
+		}
+
+		public boolean isValid() {
+			return (Bytes.equals(this.stopRow, HConstants.EMPTY_BYTE_ARRAY))
+					|| (Bytes.compareTo(this.startRow, this.stopRow) <= 0);
+		}
+	}
+
+	public static enum SourceType {
+		FILE, LIST;
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/filter/ReferenceOnlyFilter.java b/src/main/java/org/apache/hadoop/hbase/filter/ReferenceOnlyFilter.java
new file mode 100644
index 0000000..872a582
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/filter/ReferenceOnlyFilter.java
@@ -0,0 +1,22 @@
+package org.apache.hadoop.hbase.filter;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.KeyValue.Type;
+
+public class ReferenceOnlyFilter extends FilterBase {
+	public Filter.ReturnCode filterKeyValue(KeyValue v) {
+		if ((null != v) && (v.getType() == KeyValue.Type.Reference.getCode())) {
+			return Filter.ReturnCode.INCLUDE;
+		}
+		return Filter.ReturnCode.SKIP;
+	}
+
+	public void write(DataOutput out) throws IOException {
+	}
+
+	public void readFields(DataInput in) throws IOException {
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java b/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
index 9886b3a..0a9e747 100644
--- a/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
+++ b/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
@@ -29,7 +29,6 @@ import org.apache.hadoop.hbase.HServerInfo;
 import org.apache.hadoop.hbase.NotServingRegionException;
 import org.apache.hadoop.hbase.Stoppable;
 import org.apache.hadoop.hbase.client.Append;
-import org.apache.hadoop.hbase.client.RowMutations;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Get;
 import org.apache.hadoop.hbase.client.Increment;
@@ -37,21 +36,23 @@ import org.apache.hadoop.hbase.client.MultiAction;
 import org.apache.hadoop.hbase.client.MultiResponse;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.RowMutations;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.coprocessor.Exec;
 import org.apache.hadoop.hbase.client.coprocessor.ExecResult;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExec;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecCall;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecResult;
 import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;
 import org.apache.hadoop.hbase.filter.WritableByteArrayComparable;
 import org.apache.hadoop.hbase.io.hfile.BlockCacheColumnFamilySummary;
 import org.apache.hadoop.hbase.regionserver.RegionOpeningState;
-import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest.CompactionState;
 import org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException;
 import org.apache.hadoop.hbase.regionserver.wal.HLog;
-import org.apache.hadoop.hbase.security.TokenInfo;
 import org.apache.hadoop.hbase.security.KerberosInfo;
+import org.apache.hadoop.hbase.security.TokenInfo;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.ipc.RemoteException;
-import org.apache.hadoop.hbase.ipc.VersionedProtocol;
 
 /**
  * Clients interact with HRegionServers using a handle to the HRegionInterface.
@@ -647,4 +648,9 @@ public interface HRegionInterface extends VersionedProtocol, Stoppable, Abortabl
 
   @Override
   public void stop(String why);
+  
+  public abstract <R> BatchExecResult execBatchCoprocessor(
+      String paramString, List<BatchExec> paramList,
+      BatchExecCall.ServerCallback<R> paramServerCallback)
+      throws IOException;
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
index 6d9a9b7..22173b4 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -97,6 +97,7 @@ import org.apache.hadoop.hbase.client.RowLock;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.coprocessor.Exec;
 import org.apache.hadoop.hbase.client.coprocessor.ExecResult;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExec;
 import org.apache.hadoop.hbase.errorhandling.ForeignExceptionSnare;
 import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;
 import org.apache.hadoop.hbase.filter.Filter;
@@ -5890,4 +5891,65 @@ public class HRegion implements HeapSize { // , Writable{
     void failedBulkLoad(byte[] family, String srcPath) throws IOException;
 
   }
+
+  public Object exec(BatchExec call) throws IOException {
+    Class<? extends CoprocessorProtocol> protocol = call.getProtocol();
+    if (protocol == null) {
+      String protocolName = call.getProtocolName();
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(new StringBuilder()
+            .append("Received dynamic protocol exec call with protocolName ")
+            .append(protocolName).toString());
+      }
+
+      protocol = this.protocolHandlerNames.get(protocolName);
+      if (protocol == null) {
+        throw new HBaseRPC.UnknownProtocolException(protocol,
+            new StringBuilder()
+                .append("No matching handler for protocol ")
+                .append(protocolName).append(" in region ")
+                .append(Bytes.toStringBinary(getRegionName()))
+                .toString());
+      }
+
+    }
+
+    if (!this.protocolHandlers.containsKey(protocol)) {
+      throw new HBaseRPC.UnknownProtocolException(protocol,
+          new StringBuilder()
+              .append("No matching handler for protocol ")
+              .append(protocol.getName()).append(" in region ")
+              .append(Bytes.toStringBinary(getRegionName()))
+              .toString());
+    }
+
+    CoprocessorProtocol handler = (CoprocessorProtocol) this.protocolHandlers
+        .getInstance(protocol);
+    Object value;
+    try {
+      Method method = protocol.getMethod(call.getMethodName(),
+          call.getParameterClasses());
+
+      method.setAccessible(true);
+
+      value = method.invoke(handler, call.getParameters());
+    } catch (InvocationTargetException e) {
+      Throwable target = e.getTargetException();
+      if ((target instanceof IOException)) {
+        throw ((IOException) target);
+      }
+      IOException ioe = new IOException(target.toString());
+      ioe.setStackTrace(target.getStackTrace());
+      throw ioe;
+    } catch (Throwable e) {
+      if (!(e instanceof IOException)) {
+        LOG.error("Unexpected throwable object ", e);
+      }
+      IOException ioe = new IOException(e.toString());
+      ioe.setStackTrace(e.getStackTrace());
+      throw ioe;
+    }
+
+    return value;
+  }
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 1d42fea..3142c7f 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -31,6 +31,7 @@ import java.lang.reflect.Method;
 import java.net.BindException;
 import java.net.InetSocketAddress;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Comparator;
@@ -45,8 +46,15 @@ import java.util.Set;
 import java.util.SortedMap;
 import java.util.TreeMap;
 import java.util.TreeSet;
+import java.util.concurrent.Callable;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentSkipListMap;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
@@ -66,15 +74,16 @@ import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HConstants.OperationStatusCode;
 import org.apache.hadoop.hbase.HDFSBlocksDistribution;
-import org.apache.hadoop.hbase.HealthCheckChore;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HServerAddress;
 import org.apache.hadoop.hbase.HServerInfo;
 import org.apache.hadoop.hbase.HServerLoad;
 import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.HealthCheckChore;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.MasterAddressTracker;
 import org.apache.hadoop.hbase.NotServingRegionException;
+import org.apache.hadoop.hbase.ProgressableCancellable;
 import org.apache.hadoop.hbase.RemoteExceptionHandler;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.Stoppable;
@@ -104,6 +113,9 @@ import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.coprocessor.Exec;
 import org.apache.hadoop.hbase.client.coprocessor.ExecResult;
 import org.apache.hadoop.hbase.coprocessor.CoprocessorHost;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExec;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecCall;
+import org.apache.hadoop.hbase.coprocessor.batch.BatchExecResult;
 import org.apache.hadoop.hbase.executor.EventHandler.EventType;
 import org.apache.hadoop.hbase.executor.ExecutorService;
 import org.apache.hadoop.hbase.executor.ExecutorService.ExecutorType;
@@ -172,7 +184,6 @@ import org.apache.hadoop.util.ReflectionUtils;
 import org.apache.hadoop.util.StringUtils;
 import org.apache.zookeeper.KeeperException;
 import org.codehaus.jackson.map.ObjectMapper;
-import org.joda.time.field.MillisDurationField;
 
 import com.google.common.base.Function;
 import com.google.common.collect.Lists;
@@ -2800,6 +2811,45 @@ public class HRegionServer implements HRegionInterface, HBaseRPCErrorHandler,
 
   Map<String, Integer> rowlocks = new ConcurrentHashMap<String, Integer>();
 
+  private Map<String, ProgressableCancellable[]> progressableCancellableMap = new ConcurrentHashMap<String, ProgressableCancellable[]>();
+
+  protected static java.util.concurrent.ExecutorService pool = new ThreadPoolExecutor(
+      1, 2147483647, 60L, TimeUnit.SECONDS, new SynchronousQueue(),
+      new DaemonThreadFactory());
+
+  static {
+    ((ThreadPoolExecutor) pool).allowCoreThreadTimeOut(true);
+  }
+
+  static class DaemonThreadFactory implements ThreadFactory {
+    static final AtomicInteger poolNumber = new AtomicInteger(1);
+    final ThreadGroup group;
+    final AtomicInteger threadNumber = new AtomicInteger(1);
+    final String namePrefix;
+
+    DaemonThreadFactory() {
+      SecurityManager s = System.getSecurityManager();
+      this.group = (s != null ? s.getThreadGroup() : Thread
+          .currentThread().getThreadGroup());
+
+      this.namePrefix = ("batch-coprocessor-pool"
+          + poolNumber.getAndIncrement() + "-thread-");
+    }
+
+    public Thread newThread(Runnable r) {
+      Thread t = new Thread(this.group, r, this.namePrefix
+          + this.threadNumber.getAndIncrement(), 0L);
+
+      if (!t.isDaemon()) {
+        t.setDaemon(true);
+      }
+      if (t.getPriority() != 5) {
+        t.setPriority(5);
+      }
+      return t;
+    }
+  }
+
   /**
    * Instantiated as a row lock lease. If the lease times out, the row lock is
    * released
@@ -3997,4 +4047,66 @@ public class HRegionServer implements HRegionInterface, HBaseRPCErrorHandler,
   public CompactSplitThread getCompactSplitThread() {
     return this.compactSplitThread;
   }
+
+  @Override
+  public <R> BatchExecResult execBatchCoprocessor(String id,
+      List<BatchExec> callList,
+      final BatchExecCall.ServerCallback<R> callback) throws IOException {
+    checkOpen();
+    this.requestCount.incrementAndGet();
+    List<ProgressableCancellable> progressableList = new ArrayList<ProgressableCancellable>();
+    for (BatchExec call : callList) {
+      progressableList.addAll(Arrays.asList(call
+          .getProgressableCancellableParameters()));
+    }
+    this.progressableCancellableMap.put(id,
+        (ProgressableCancellable[]) progressableList
+            .toArray(new ProgressableCancellable[progressableList
+                .size()]));
+    try {
+      if (callback != null) {
+        callback.init();
+      }
+      List<Pair<Future<R>,byte[]>> futureList = new ArrayList<Pair<Future<R>,byte[]>>();
+      List<byte[]> regionNames = new ArrayList<byte[]>();
+      for (final BatchExec call : callList) {
+        final byte[] regionName = call.getRegionName();
+        Future<R> future = pool.submit(new Callable<R>() {
+          public R call() throws Exception {
+            HRegion region = HRegionServer.this
+                .getRegion(regionName);
+            R result = (R) region.exec(call);
+            if (callback != null) {
+              callback.update(regionName, result);
+            }
+            return result;
+          }
+        });
+        futureList.add(new Pair<Future<R>,byte[]>(future, regionName));
+      }
+      for (Pair<Future<R>,byte[]> future : futureList) {
+        try {
+          ((Future<R>) future.getFirst()).get();
+          regionNames.add(future.getSecond());
+        } catch (ExecutionException ee) {
+          LOG.warn(
+              new StringBuilder()
+                  .append("Error executing for region ")
+                  .append(future.getSecond()).toString(), ee);
+          throw ee.getCause();
+        } catch (InterruptedException ie) {
+          throw new IOException(new StringBuilder()
+              .append("Interrupted executing for region ")
+              .append(future.getSecond()).toString(), ie);
+        }
+      }
+
+      return new BatchExecResult(regionNames, callback == null ? null
+          : callback.getResult());
+    } catch (Throwable t) {
+      throw convertThrowableToIOE(cleanup(t));
+    } finally {
+      this.progressableCancellableMap.remove(id);
+    }
+  }
 }
diff --git a/src/main/ruby/hbase.rb b/src/main/ruby/hbase.rb
index 4432225..e37a215 100644
--- a/src/main/ruby/hbase.rb
+++ b/src/main/ruby/hbase.rb
@@ -57,6 +57,8 @@ module HBaseConstants
   SPLITALGO = 'SPLITALGO'
   NUMREGIONS = 'NUMREGIONS'
   COLUMN_INTERPRETER="COLUMN_INTERPRETER"
+  KEY = "KEY"
+  SELECT = "SELECT"
 
   # Load constants from hbase java API
   def self.promote_constants(constants)
diff --git a/src/main/ruby/hbase/coprocessor.rb b/src/main/ruby/hbase/coprocessor.rb
index 47cf963..0c8fa84 100644
--- a/src/main/ruby/hbase/coprocessor.rb
+++ b/src/main/ruby/hbase/coprocessor.rb
@@ -30,6 +30,7 @@ module Hbase
 
     def initialize(configuration, formatter)
       @aClient = org.apache.hadoop.hbase.client.coprocessor.AggregationClient.new(configuration)
+      @groupByClient = org.apache.hadoop.hbase.client.coprocessor.GroupByClient.new(configuration)
       @formatter = formatter
     end
 
@@ -68,6 +69,13 @@ module Hbase
       @aClient.avg(table.to_s.to_java_bytes, ci, scan)
     end
 
+    def groupby(table, *args)
+      scan, groupby_keys, groupby_selects = parse_groupby_args(args)
+      scans = org.apache.hadoop.hbase.client.Scan[1].new
+      scans[0] = scan
+      return @groupByClient.groupBy(table.to_s.to_java_bytes, scans, groupby_keys, groupby_selects, nil)
+    end
+
     def parse_args(table, *args)
        # Fail if table name is not a string
       raise(ArgumentError, "Table name must be of type String") unless table.kind_of?(String)
@@ -112,6 +120,37 @@ module Hbase
       end
     end
 
+    def parse_groupby_args(args)
+      groupby_keys = ArrayList.new()
+      groupby_selects = ArrayList.new()
+      args = args.flatten.compact
+      raise(ArgumentError, "Table must have at least one KEY field and one SELECT field") if args.empty?
+      scan = org.apache.hadoop.hbase.client.Scan.new()
+      args.each do |arg|
+        unless arg.kind_of?(Hash)
+          raise(ArgumentError, "#{arg.class} of #{arg.inspect} is not of Hash or String type")
+        end
+        if arg.has_key?(KEY)
+          groupby_keys.add(arg[KEY])
+          next
+        end
+        if arg.has_key?(SELECT)
+          groupby_selects.add(arg[SELECT])
+          next
+        end
+
+        if arg.has_key?(STARTROW)
+          scan.setStartRow(arg[STARTROW].to_java_bytes)
+        end
+        if arg.has_key?(STOPROW)
+          scan.setStopRow(arg[STOPROW].to_java_bytes)
+        end
+        if arg.has_key?(FILTER)
+          scan.setFilter(arg[FILTER])
+        end
+      end
+      return scan, groupby_keys, groupby_selects
+    end
   end
 end
 
diff --git a/src/main/ruby/shell.rb b/src/main/ruby/shell.rb
index 57eac81..546183a 100644
--- a/src/main/ruby/shell.rb
+++ b/src/main/ruby/shell.rb
@@ -338,5 +338,6 @@ Shell.load_command_group(
   :comment => "In order to use these tools, hbase.coprocessor.region.classes must be set",
   :commands => %w[
     aggregate
+    groupby
   ]
 )
diff --git a/src/main/ruby/shell/commands/groupby.rb b/src/main/ruby/shell/commands/groupby.rb
new file mode 100644
index 0000000..423423b
--- /dev/null
+++ b/src/main/ruby/shell/commands/groupby.rb
@@ -0,0 +1,51 @@
+#
+# Copyright 2010 The Apache Software Foundation
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class Groupby < Command
+      def help
+        return <<-EOF
+Execute a Coprocessor groupby function; pass tablename, groupby key expression, select expression and optionally a dictionary of groupby specifications. Groupby specifications may include STARTROW, STOPROW and FILTER. Available expressions are add, subtract, multiply, divide, remainder, columnValue, eq, neq, lt, le, gt, ge, constant, sum, avg, count, min, max, stdDev, groupByKey, and, or, not, row, stringConcat, StringPart, subSequence, subString, ternary, toBigDecimal, toBoolean, toByte, toBytes, toDouble, toFloat, toInteger, toLong, toShort and toString. Be careful that the evalation result of the key expression must be byte array.
+
+Some examples:
+
+  hbase> groupby 't1',{KEY => Exp.constant(0)},{SELECT => Exp.count(Exp.columnValue('f','c2'))}
+  hbase> groupby 't1',{KEY => Exp.columnValue('f','c1')},{SELECT => Exp.groupByKey(Exp.columnValue('f','c1'))},{SELECT => Exp.sum(Exp.toLong(Exp.columnValue('f','c2')))}
+  hbase> groupby 't1',{KEY => Exp.constant(0)},{SELECT => Exp.count(Exp.columnValue('f','c2'))},{STARTROW => 'abc', STOPROW => 'def'}
+EOF
+      end
+
+      def command(table_name, *args)
+	now = Time.now
+        list = hbase_coprocessor.groupby(table_name, *args)
+        list.each do |results|
+          row = []
+          results.each do |result|
+             row.push(result.toString)
+          end
+          formatter.row(row)
+        end
+        formatter.footer(now, list.size)
+      end
+    end
+  end
+end
+
-- 
1.8.3.2

